# Kernel Benchmark Summary
| 算子 | best_score | 状态 |
| 1 | 1.26 | ✅ |
| 2_Standard_matrix_multiplication | 0 | ✅ |
| 3_Batched_matrix_multiplication | 1.45 | ✅ |
| 4_Matrix_vector_multiplication | 0 | ✅ |
| 5_Matrix_scalar_multiplication | 0 | ✅ |
| 6_Matmul_with_large_K_dimension | 0.91 | ✅ |
| 7_Matmul_with_small_K_dimension | 0 | ✅ |
| 8_Matmul_with_irregular_shapes | 0.04 | ✅ |
| 9_Tall_skinny_matrix_multiplication | 0 | ✅ |
| 10_3D_tensor_matrix_multiplication | 0.85 | ✅ |
| 11 | 0 | ✅ |
| 12_Matmul_with_diagonal_matrices | 0.98 | ✅ |
| 13_Matmul_for_symmetric_matrices | 0.43 | ✅ |
| 14_Matmul_for_upper_triangular_matrices | 0.2 | ✅ |
| 15_Matmul_for_lower_triangular_matrices | 1.05 | ✅ |
| 16_Matmul_with_transposed_A | 0 | ✅ |
| 17_Matmul_with_transposed_B | 0 | ✅ |
| 18_Matmul_with_transposed_both | 0 | ✅ |
| 19_ReLU | 0 | ✅ |
| 20_LeakyReLU | 0 | ✅ |
| 21_Sigmoid | 1.01 | ✅ |
| 22_Tanh | 0 | ✅ |
| 23_Softmax | 0 | ✅ |
| 24_LogSoftmax | 0.93 | ✅ |
| 25_Swish | 0 | ✅ |
| 26_GELU | 0 | ✅ |
| 27_SELU | 1.01 | ✅ |
| 28_HardSigmoid | 0.975 | ✅ |
| 29_Softplus | 1.05 | ✅ |
| 30_Softsign | 1.01 | ✅ |
| 31 | 0 | ✅ |
| 32 | 0 | ✅ |
| 33 | 0.305 | ✅ |
| 34 | 0 | ✅ |
| 35 | 0.6 | ✅ |
| 36 | 1.0 | ✅ |
| 37 | 0 | ✅ |
| 38 | 0 | ✅ |
| 39 | 0 | ✅ |
| 40_LayerNorm | 0 | ✅ |
| 41_Max_Pooling_1D | 0 | ✅ |
| 42_Max_Pooling_2D | 0 | ✅ |
| 43_Max_Pooling_3D | 0 | ✅ |
| 44 | 0 | ✅ |
| 45_Average_Pooling_2D | 0 | ✅ |
| 46_Average_Pooling_3D | 0 | ✅ |
| 47_Sum_reduction_over_a_dimension | 0 | ✅ |
| 48_Mean_reduction_over_a_dimension | 0 | ✅ |
| 49_Max_reduction_over_a_dimension | 0 | ✅ |
| 50_conv_standard_2D_square_input_square_kernel | 0 | ✅ |