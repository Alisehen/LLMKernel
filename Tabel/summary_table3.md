# Kernel Benchmark Summary
| 算子 | best_score | 状态 |
| 1 | 1.26 | ✅ |
| 2_Standard_matrix_multiplication | 1.55 | ✅ |
| 3_Batched_matrix_multiplication | 1.66 | ✅ |
| 4_Matrix_vector_multiplication | 2.2 | ✅ |
| 5_Matrix_scalar_multiplication | 2.2 | ✅ |
| 6_Matmul_with_large_K_dimension | 1.5 | ✅ |
| 7_Matmul_with_small_K_dimension | 1.6530 | ✅ |
| 8_Matmul_with_irregular_shapes | 1.04 | ✅ |
| 9_Tall_skinny_matrix_multiplication | 1.09 | ✅ |
| 10_3D_tensor_matrix_multiplication | 0.85 | ✅ |
| 11 | 1.6 | ✅ |
| 12_Matmul_with_diagonal_matrices | 1.01 | ✅ |
| 13_Matmul_for_symmetric_matrices | 1.05 | ✅ |
| 14_Matmul_for_upper_triangular_matrices | 0.84 | ✅ |
| 15_Matmul_for_lower_triangular_matrices | 1.05 | ✅ |
| 16_Matmul_with_transposed_A | 1.2 | ✅ |
| 17_Matmul_with_transposed_B | 1.9308 | ✅ |
| 18_Matmul_with_transposed_both | 1.14 | ✅ |
| 19_ReLU | 1.53 | ✅ |
| 20_LeakyReLU | 1.8 | ✅ |
| 21_Sigmoid | 1.25 | ✅ |
| 22_Tanh | 0.53 | ✅ |
| 23_Softmax | 1.05 | ✅ |
| 24_LogSoftmax | 1.05 | ✅ |
| 25_Swish | 1.05 | ✅ |
| 26_GELU | 1.01 | ✅ |
| 27_SELU | 1.08 | ✅ |
| 28_HardSigmoid | 1.01 | ✅ |
| 29_Softplus | 1.14 | ✅ |
| 30_Softsign | 1.01 | ✅ |
| 31 | 1.08 | ✅ |
| 32 | 2.04 | ✅ |
| 33 | 2.09 | ✅ |
| 34 | 3.05 | ✅ |
| 35 | 1.1 | ✅ |
| 36 | 1.6 | ✅ |
| 37 | 0.76 | ✅ |
| 38 | 1.3 | ✅ |
| 39 | 1.1 | ✅ |
| 40_LayerNorm | 1.01 | ✅ |
| 41_Max_Pooling_1D | 0.96 | ✅ |
| 42_Max_Pooling_2D | 1.0770 | ✅ |
| 43_Max_Pooling_3D | 1.85 | ✅ |
| 44 | 1.61 | ✅ |
| 45_Average_Pooling_2D | 1.08 | ✅ |
| 46_Average_Pooling_3D | 1.41 | ✅ |
| 47_Sum_reduction_over_a_dimension | 0.98 | ✅ |
| 48_Mean_reduction_over_a_dimension | 1.17 | ✅ |
| 49_Max_reduction_over_a_dimension | 1.24 | ✅ |
| 50_conv_standard_2D_square_input_square_kernel | 3 | ✅ |