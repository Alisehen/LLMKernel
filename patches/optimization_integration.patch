"""
prompts/optimization.py 集成分类系统的具体修改
"""

# ==================== 1. 在文件开头添加import ====================
# 在 optimization.py 第9行之后添加：

from config.operator_categories_v2 import build_stage_prompt_section


# ==================== 2. 修改build_optimization_prompt函数签名 ====================
# 找到 build_optimization_prompt 函数定义（第72行），添加新参数：

def build_optimization_prompt(
    arch_path: Path,
    gpu_name: Optional[str] = None,
    *,
    ncu_metrics: str = "",
    history_block: str = "",
    stage_name: str = "",
    stage_description: str = "",
    failure_analysis: str = "",
    # ===== 【新增】分类相关参数 =====
    category: str = "Memory-Intensive",
    stage_id: int = 0,
) -> str:
    """Build single-phase optimization prompt with NCU metrics.

    Args:
        arch_path: Path to kernel code to optimize
        gpu_name: Target GPU name
        ncu_metrics: NCU profiling metrics (JSON format)
        history_block: Previous kernel attempts
        stage_name: Current optimization stage
        stage_description: Stage description
        failure_analysis: Analysis of previous failures
        category: Operator category (Compute-Intensive, Memory-Intensive, etc.)
        stage_id: Stage index (0-based)
    """


# ==================== 3. 修改stage_context构建逻辑 ====================
# 找到 "# Build stage context" 部分（第112行附近），替换为：

    # ===== Build stage context =====
    stage_context = ""

    if stage_name and stage_description:
        # ===== 【优先】使用分类特定的guidance =====
        try:
            category_guidance = build_stage_prompt_section(category, stage_id)
            if category_guidance:
                stage_context = category_guidance
                print(f"[Prompt] Using category-specific guidance for {category}")
            else:
                # Fallback to original
                stage_context = _build_fallback_stage_context(stage_name, stage_description)
                print(f"[Prompt] Using fallback guidance for {stage_name}")
        except Exception as e:
            print(f"[Prompt] Warning: Failed to get category guidance: {e}")
            stage_context = _build_fallback_stage_context(stage_name, stage_description)

    # ... 后续代码保持不变 ...


# ==================== 4. 提取原有的stage_focus_map为fallback函数 ====================
# 在文件末尾（或build_optimization_prompt之前）添加：

def _build_fallback_stage_context(stage_name: str, stage_description: str) -> str:
    """
    Fallback to original stage_focus_map if category-specific guidance is not available.
    """
    # Map stage names to specific optimization focus
    stage_focus_map = {
        "grid_and_parallel": """
**Focus**: Maximize SM utilization and parallel work distribution.

**Suggested optimizations** (evaluate based on NCU metrics):
• If SM occupancy < 80%: adjust grid size for better GPU utilization
• Balance workload via `tl.program_id()` mapping to avoid idle SMs
• Consider Split-K for compute-bound kernels (requires `tl.atomic_add()`)

**Note**: Only optimize if NCU shows SM underutilization.
""",
        "block_tiling": """
**Focus**: Find optimal block size balancing data reuse and register pressure.

**Suggested ranges** (tune based on occupancy):
• BLOCK_M/N: 64, 128, 256 (use 16x multiples for Tensor Cores)
• BLOCK_K: 32, 64, 128
• If occupancy low due to registers: reduce block size
• If occupancy high: current config is likely good

**Note**: Use NCU metrics to guide tuning, not blind search.
""",
        "memory_access": """
**Focus**: Optimize memory access based on kernel characteristics and NCU bottleneck analysis.

**Suggested optimizations** (evaluate applicability):

**If memory stalls > 30%** (check `smsp__warp_issue_stalled_memory_dependency`):
• Increase `num_stages` (2/3/4) in kernel decorator for software pipelining

**If DRAM throughput > 80%** (memory-bound):
• Use vectorized loads/stores where applicable
• Minimize redundant memory operations

**If kernel has data reuse** (e.g., matmul, conv) **AND** L2 hit < 80%:
• Improve L2 cache hit rate via better block tiling or computation ordering

**If kernel is element-wise** (e.g., add, mul, relu):
• L2 optimization has minimal impact (no data reuse)
• Focus on maximizing memory throughput instead

**Note**: Analyze your kernel's access pattern before optimizing. Not all optimizations apply to all kernels.
""",
        "advanced_memory": """
**Focus**: Fine-tune memory management for final performance gains (typically 5-10%).

**Suggested optimizations** (only if NCU shows potential):

**num_stages tuning**:
• If memory stalls > 30%: try num_stages=2/3/4 to hide latency
• If memory stalls < 10%: num_stages=1 is sufficient (saves registers)

**eviction_policy** (for `tl.load`):
• "evict_first": data will be reused soon (e.g., shared memory blocking)
• "evict_last": streaming data with single use

**Skip this stage if**:
• Current metrics already near optimal (e.g., L2 hit > 95%, low stalls)
• Performance already meets target

**Note**: These are micro-optimizations. Major gains come from earlier stages.
**Do NOT attempt**: Triton does not support manual shared memory swizzling or instruction reordering.
""",
    }

    focus = stage_focus_map.get(stage_name, "")
    return f"""
## Current Optimization Stage
**Stage**: {stage_description}
{focus}
""".strip()


# ==================== 5. 更新函数docstring ====================
# 在build_optimization_prompt的docstring中添加category和stage_id的说明
# （见上面的修改后签名）


# ==================== 完整的修改后函数示例 ====================
# 供参考，完整的修改后函数应该是：

def build_optimization_prompt(
    arch_path: Path,
    gpu_name: Optional[str] = None,
    *,
    ncu_metrics: str = "",
    history_block: str = "",
    stage_name: str = "",
    stage_description: str = "",
    failure_analysis: str = "",
    category: str = "Memory-Intensive",
    stage_id: int = 0,
) -> str:
    """Build optimization prompt with category-specific guidance."""

    gpu_info = _load_gpu_spec()

    if gpu_name is None:
        try:
            import torch
            gpu_name = torch.cuda.get_device_name(0)
        except Exception as exc:
            raise RuntimeError("CUDA device not found – pass --gpu <name>.") from exc

    if gpu_name not in gpu_info:
        raise KeyError(f"{gpu_name} not present in GPU_SPEC_INFO")

    info = gpu_info[gpu_name]
    gpu_arch = info.get("GPU Architecture", "Unknown")
    gpu_items = "\n".join(f"• {k}: {v}" for k, v in info.items() if k != "GPU Architecture")

    arch_src = Path(arch_path).read_text().strip()
    hist = history_block or "(None)\n"

    # ===== Build stage context with category-specific guidance =====
    stage_context = ""
    if stage_name and stage_description:
        try:
            # Try category-specific guidance first
            category_guidance = build_stage_prompt_section(category, stage_id)
            if category_guidance:
                stage_context = category_guidance
                print(f"[Prompt] Using {category} guidance for stage {stage_id}")
            else:
                # Fallback to original
                stage_context = _build_fallback_stage_context(stage_name, stage_description)
                print(f"[Prompt] Using fallback guidance")
        except Exception as e:
            print(f"[Prompt] Warning: {e}, using fallback")
            stage_context = _build_fallback_stage_context(stage_name, stage_description)

    # ===== Build failure analysis (unchanged) =====
    failure_context = ""
    if failure_analysis:
        failure_context = f"""
## Previous Attempt Failed
{failure_analysis}

**Your Task**: Generate a **different** approach within {stage_description} scope.
- Do NOT repeat the failed strategy
- Try alternative parameters or implementation within this stage
- Ensure the fix addresses the root cause identified above
"""

    # ===== Format NCU metrics (unchanged) =====
    ncu_section = ncu_metrics if ncu_metrics else "No NCU metrics available"

    # ===== Build final prompt (unchanged) =====
    return _OPTIMIZATION_PROMPT_TEMPLATE.substitute(
        gpu_name=gpu_name,
        gpu_arch=gpu_arch,
        gpu_items=gpu_items,
        arch_src=arch_src,
        history_block=hist,
        STAGE_CONTEXT=stage_context,
        NCU_METRICS=ncu_section,
        FAILURE_ANALYSIS=failure_context,
    )
