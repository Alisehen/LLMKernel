# Prompt ç®€åŒ–æ€»ç»“

## ğŸ¯ ç›®æ ‡

è®© LLM ç”Ÿæˆ**æœ€ç®€å•ã€æœ€å¿«é€Ÿã€æœ€æ­£ç¡®**çš„ Triton kernelï¼Œé¿å…è¿‡åº¦å·¥ç¨‹åŒ–ã€‚

## ğŸ“‹ ä¿®æ”¹å†…å®¹

### 1. Seed Prompt (`prompts/generate_custom_cuda.py`)

**ä¹‹å‰çš„é—®é¢˜**ï¼š
- LLM ç”Ÿæˆå¤šä¸ª kernel å˜ä½“ï¼ˆFP8, INT8, etc.ï¼‰
- è¿‡å¤šçš„ autotune é…ç½®ï¼ˆ6+ configsï¼‰
- åŒ…å« `get_inputs()`, `get_init_inputs()` ç­‰æµ‹è¯•ä»£ç 
- æ·»åŠ ä¸å¿…è¦çš„ helper functions

**æ–°å¢è¦æ±‚**ï¼š
```
**CRITICAL REQUIREMENTS**:
1. **CORRECTNESS FIRST**: Your implementation MUST produce correct results. Speed is secondary.
2. **SIMPLICITY FIRST**: Generate the SIMPLEST possible working implementation. Do NOT add:
   - Multiple kernel variations (e.g., FP8, INT8 versions) - stick to ONE kernel
   - Excessive autotune configs - use AT MOST 2-3 simple configurations
   - Unnecessary features (dynamic shapes, edge cases, special dtypes)
   - Extra helper functions or wrappers beyond what's needed
3. **MINIMAL CODE**: Output ONLY what's required:
   - Necessary imports (torch, triton, triton.language)
   - ONE @triton.jit kernel function
   - ONE simple wrapper function
   - ONE ModelNew class that calls the wrapper
   - NO get_inputs(), NO get_init_inputs(), NO testing code
```

### 2. Optimization Prompt (`prompts/optimization.py`)

**ä¹‹å‰çš„é—®é¢˜**ï¼š
- ä¼˜åŒ–é˜¶æ®µä¹Ÿä¼šç”Ÿæˆå¤šä¸ª kernel å˜ä½“
- æ·»åŠ å¤æ‚çš„ autotune configs
- è¿‡åº¦ä¼˜åŒ–å¯¼è‡´ä»£ç å¤æ‚

**æ–°å¢è¦æ±‚**ï¼š
```
**CRITICAL REQUIREMENTS**:
1. **CORRECTNESS FIRST**: Your optimized code MUST produce correct results
2. **SIMPLICITY FIRST**: Make the SIMPLEST optimization that addresses the bottleneck
3. **ONE KERNEL ONLY**: Generate exactly ONE Triton kernel, not multiple variants
4. **MINIMAL CHANGES**: Only optimize what's necessary based on the failure analysis

**FORBIDDEN OPTIMIZATIONS**:
- Adding multiple kernel variants (FP8, INT8, etc.) - keep ONE kernel
- Adding complex autotune configs with >3 configurations
- Adding helper functions or utilities not strictly needed
- Adding get_inputs(), get_init_inputs(), or testing code
- Over-engineering or premature optimization
```

### 3. Repair Prompt (`main.py` + `prompts/error.py`)

**ç®€åŒ–å†…å®¹**ï¼š
- âŒ åˆ é™¤ä¸¤é˜¶æ®µä¿®å¤ï¼ˆè¯†åˆ«é—®é¢˜ + ç”Ÿæˆä¿®å¤ï¼‰
- âŒ åˆ é™¤é”™è¯¯å†å²è¿½è¸ª
- âŒ åˆ é™¤å¤æ‚çš„ JSON è§£æ
- âœ… ä¿ç•™å•é˜¶æ®µä¿®å¤ï¼šç›´æ¥ç”Ÿæˆä¿®å¤åçš„ kernel
- âœ… ä¿ç•™ Triton-specific é”™è¯¯æ£€æµ‹å’ŒæŒ‡å¯¼

**ä»£ç ç®€åŒ–**ï¼š
- `_repair_kernel_with_retries` ä» 200+ è¡Œå‡å°‘åˆ° 76 è¡Œ
- æ¯æ¬¡ä¿®å¤èŠ‚çœ ~50% tokenï¼ˆå°‘1æ¬¡ LLM è°ƒç”¨ï¼‰

## ğŸ¨ System Prompt æ›´æ–°

**æ–°çš„ system prompt**ï¼š
```
You are a senior GPU kernel optimization specialist with expertise in Triton.

**YOUR GOAL**: Generate SIMPLE, CORRECT, and FAST Triton kernels.

**PRIORITIES (in order)**:
1. CORRECTNESS - Code must compile and produce correct results
2. SIMPLICITY - Use the simplest implementation that works
3. SPEED - Optimize only after correctness is ensured

**FORBIDDEN**:
- Multiple kernel variants (FP8, INT8, etc.) - use ONE kernel only
- Complex autotune configs with >3 configurations
- Helper functions, utilities, or testing code
- get_inputs(), get_init_inputs(), or any test utilities
- Comments explaining basic Triton syntax (keep only critical comments)
```

## ğŸ“Š é¢„æœŸæ•ˆæœ

### ä¹‹å‰ç”Ÿæˆçš„ä»£ç ï¼ˆ213 è¡Œï¼‰ï¼š
```python
# ä¸¤ä¸ª kernel: matmul_kernel + matmul_fp8_kernel
@triton.autotune(configs=[...6 configs...])
@triton.jit
def matmul_kernel(...): ...

@triton.autotune(configs=[...3 configs...])
@triton.jit
def matmul_fp8_kernel(...): ...

def triton_matmul(a, b, use_fp8=False):
    if use_fp8:
        # FP8 conversion logic...
        a_fp8 = a.to(torch.float8_e4m3fn)
        # ...
    else:
        # Regular matmul...

class ModelNew(nn.Module):
    def __init__(self, use_fp8=False): ...

def get_inputs(): ...  # ä¸éœ€è¦
def get_init_inputs(): ...  # ä¸éœ€è¦
```

### é¢„æœŸçš„ç®€åŒ–ä»£ç ï¼ˆ~80 è¡Œï¼‰ï¼š
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl

@triton.autotune(
    configs=[
        triton.Config({'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 32}, num_warps=4),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 32}, num_warps=2),
    ],
    key=['M', 'N', 'K'],
)
@triton.jit
def matmul_kernel(
    a_ptr, b_ptr, c_ptr,
    M, N, K,
    stride_am, stride_ak,
    stride_bk, stride_bn,
    stride_cm, stride_cn,
    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,
):
    # Simple matmul implementation...
    pid = tl.program_id(0)
    # ... (æ ¸å¿ƒé€»è¾‘)

def matmul(a, b):
    M, K = a.shape
    K, N = b.shape
    c = torch.empty((M, N), device=a.device, dtype=a.dtype)

    grid = lambda meta: (
        triton.cdiv(M, meta['BLOCK_M']) * triton.cdiv(N, meta['BLOCK_N']),
    )

    matmul_kernel[grid](
        a, b, c,
        M, N, K,
        a.stride(0), a.stride(1),
        b.stride(0), b.stride(1),
        c.stride(0), c.stride(1),
    )
    return c

class ModelNew(nn.Module):
    def forward(self, A, B):
        return matmul(A, B)
```

## âœ… æ”¹è¿›æ€»ç»“

1. **ä»£ç é‡å‡å°‘**: 213 è¡Œ â†’ ~80 è¡Œï¼ˆ-62%ï¼‰
2. **Token èŠ‚çœ**:
   - Seed generation: å‡å°‘ ~40% token
   - Optimization: å‡å°‘ ~35% token
   - Repair: å‡å°‘ ~50% tokenï¼ˆå°‘1æ¬¡ LLM è°ƒç”¨ï¼‰
3. **æ›´å®¹æ˜“è°ƒè¯•**: ä»£ç ç®€å•ï¼Œé€»è¾‘æ¸…æ™°
4. **æ›´é«˜æˆåŠŸç‡**: å‡å°‘äº†å‡ºé”™çš„å¯èƒ½æ€§
5. **æ›´å¿«æ”¶æ•›**: ç›´æ¥ç”Ÿæˆæ­£ç¡®çš„ä»£ç ï¼Œè€Œä¸æ˜¯è¿‡åº¦å¤æ‚çš„ç‰ˆæœ¬

## ğŸ”§ æµ‹è¯•å»ºè®®

è¿è¡Œç®€åŒ–ç‰ˆæœ¬ï¼š
```bash
sudo -E env PATH="/home/hyc/miniconda3/envs/hyc/bin:$PATH" \
  /home/hyc/miniconda3/envs/hyc/bin/python main.py \
  ./KernelBench/level1/1_Square_matrix_multiplication_.py \
  --gpu "4090" \
  --server_type sglang \
  --server_port 8001 \
  --device 3 \
  --num_steps 4 \
  --max_repair_attempts 2
```

æ£€æŸ¥ç”Ÿæˆçš„ kernelï¼š
```bash
ls -lh run/*/code/kernel_*.py
cat run/*/code/kernel_*.py | wc -l  # åº”è¯¥ <100 è¡Œ
```

## ğŸ“ å…³é”®æ–‡ä»¶

1. **`prompts/generate_custom_cuda.py`** - Seed kernel ç”Ÿæˆ prompt
2. **`prompts/optimization.py`** - ä¼˜åŒ– prompt
3. **`prompts/error.py`** - é”™è¯¯ä¿®å¤ prompt æ¨¡æ¿
4. **`main.py`** - `_repair_kernel_with_retries` ç®€åŒ–é€»è¾‘

æ‰€æœ‰ä¿®æ”¹éƒ½å¼ºè°ƒï¼š**æ­£ç¡®æ€§ > ç®€å•æ€§ > é€Ÿåº¦**
