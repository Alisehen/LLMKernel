{
  "timestamp": "2025-12-15T05:01:56",
  "reference_file": "KernelBench/level2/39_Gemm_Scale_BatchNorm.py",
  "candidate_file": "/home/hyc/LLMKernel/run/20251215_024803_batch_range31to55_openai_deepseek/39_Gemm_Scale_BatchNorm/code/kernel_20251215_050149.py",
  "tolerance": 0.001,
  "max_abs_err": 0.008631706237792969,
  "mean_abs_err": 0.00014908127195667475,
  "ref_latency_ms": {
    "avg": 13.927212905883788,
    "min": 13.87827205657959,
    "max": 13.947711944580078,
    "all": [
      13.929471969604492,
      13.947711944580078,
      13.936832427978516,
      13.94377613067627,
      13.87827205657959
    ]
  },
  "test_latency_ms": {
    "avg": 11.065158271789551,
    "min": 10.902527809143066,
    "max": 11.461631774902344,
    "all": [
      11.461631774902344,
      11.034624099731445,
      11.018239974975586,
      10.902527809143066,
      10.908767700195312
    ]
  },
  "num_runs": 5,
  "model_init_args": [
    4096,
    4096,
    [
      4096
    ]
  ],
  "model_init_kwargs": {},
  "seed": 100,
  "align_stats": {
    "copied_same_shape": 8,
    "unique_shape_copied": 0,
    "mapped_shape": 0,
    "skipped": 0,
    "pair_aligner": 0,
    "pair_key": "Model->ModelNew"
  },
  "runnable": true,
  "phase": "stage3_memory_access",
  "pytorch_baseline_ms": 14.112601470947265,
  "score": 1.2754089118568799
}