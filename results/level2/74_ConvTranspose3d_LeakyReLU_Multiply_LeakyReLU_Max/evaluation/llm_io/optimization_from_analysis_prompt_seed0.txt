You are optimizing a Triton kernel based on algorithmic analysis.

# PyTorch Reference (Target Behavior)

```python
import torch
import torch.nn as nn

class Model(nn.Module):
    """
    Model that performs a 3D transposed convolution, applies LeakyReLU, multiplies by a learnable parameter, 
    applies LeakyReLU again, and performs a max pooling operation.
    """
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape):
        super(Model, self).__init__()
        self.conv_transpose = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding)
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)
        self.max_pool = nn.MaxPool3d(kernel_size=2)

    def forward(self, x):
        x = self.conv_transpose(x)
        x = self.leaky_relu(x)
        x = x * self.multiplier
        x = self.leaky_relu(x)
        x = self.max_pool(x)
        return x

batch_size = 16
in_channels = 16
out_channels = 32
depth, height, width = 16, 32, 32
kernel_size = 3
stride = 2
padding = 1
output_padding = 1
multiplier_shape = (out_channels, 1, 1, 1)

def get_inputs():
    return [torch.rand(batch_size, in_channels, depth, height, width)]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape]
```

**CRITICAL**: Study the PyTorch code carefully to understand:
- What does `forward()` return? (full output sequence vs final hidden state only)
- What is the computational pattern?
- What are the input/output shapes?

Your optimized kernel MUST match this exact behavior.

---

# Analysis Results

**Bottleneck**: ConvTranspose3d writes a 2× upsampled 3D volume in each spatial dimension, and the fused Triton kernel then reads this large tensor only to immediately downsample it with non‑overlapping MaxPool3d; this redundant IO dominates memory traffic and latency.

**Optimization Strategy**: Replace the current sequence ConvTranspose3d → LeakyReLU → channel-wise multiply → LeakyReLU → MaxPool3d(stride=2,kernel=2) with a single custom Triton kernel that performs a ‘pooled transposed convolution’: it computes, for each pooled output voxel, the 2×2×2 transposed‑conv outputs on the fly, applies the two LeakyReLUs and multiplier inline, and directly takes the max without ever materializing the high‑resolution intermediate.

**Implementation Plan**: Implement a Triton kernel that iterates over input (N, C_in, D, H, W) and weights to accumulate the eight transposed‑conv contributions corresponding to each 2×2×2 pooling window, applying the two LeakyReLUs and per‑channel scalar multiplier inside the accumulation loop and keeping only the running max per output voxel. Wire this kernel into ModelNew to replace both the PyTorch ConvTranspose3d and the current fused post‑conv Triton kernel, ensuring the output layout and numerical behavior remain identical. Once correct, tune block sizes/tiling for (N, C_out, D, H, W) to maximize cache reuse over input tiles and filters.

**Expected Speedup**: 20-30%

---

# Current Kernel (needs optimization)

```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.jit
def fused_leaky_relu_mul_maxpool3d_kernel(
    x_ptr, mul_ptr, y_ptr,
    N, C, D_out, H_out, W_out,
    stride_xn, stride_xc, stride_xd, stride_xh, stride_xw,
    stride_yn, stride_yc, stride_yd, stride_yh, stride_yw,
    total_elems,
    negative_slope,
    BLOCK: tl.constexpr,
):
    pid = tl.program_id(0)
    offs = pid * BLOCK + tl.arange(0, BLOCK)
    mask = offs < total_elems

    # Unravel linear index -> (n, c, d_out, h_out, w_out)
    w_out_idx = offs % W_out
    tmp = offs // W_out

    h_out_idx = tmp % H_out
    tmp = tmp // H_out

    d_out_idx = tmp % D_out
    nc_idx = tmp // D_out

    c_idx = nc_idx % C
    n_idx = nc_idx // C

    # MaxPool3d with kernel_size = stride = 2
    d0 = d_out_idx * 2
    h0 = h_out_idx * 2
    w0 = w_out_idx * 2

    # Base offset for the (0,0,0) corner of the pooling window
    base_offset = (
        n_idx * stride_xn
        + c_idx * stride_xc
        + d0 * stride_xd
        + h0 * stride_xh
        + w0 * stride_xw
    )

    # Load per-channel multiplier: mul_ptr has shape [C]
    m = tl.load(mul_ptr + c_idx, mask=mask, other=0.0)

    # Initialize max_val with a very small value of the correct shape and dtype
    max_val = tl.full(offs.shape, -1e30, m.dtype)

    # Iterate over the 2x2x2 pooling window
    for dd in range(2):
        d_off = base_offset + dd * stride_xd
        for hh in range(2):
            dh_off = d_off + hh * stride_xh
            for ww in range(2):
                offset = dh_off + ww * stride_xw
                x_vals = tl.load(x_ptr + offset, mask=mask, other=0.0)

                # First LeakyReLU
                x_vals = tl.where(x_vals >= 0, x_vals, negative_slope * x_vals)
                # Multiply by learnable parameter
                x_vals = x_vals * m
                # Second LeakyReLU
                x_vals = tl.where(x_vals >= 0, x_vals, negative_slope * x_vals)

                # Max over window
                max_val = tl.maximum(max_val, x_vals)

    # Store pooled result
    y_offset = (
        n_idx * stride_yn
        + c_idx * stride_yc
        + d_out_idx * stride_yd
        + h_out_idx * stride_yh
        + w_out_idx * stride_yw
    )
    tl.store(y_ptr + y_offset, max_val, mask=mask)


def fused_leaky_relu_mul_maxpool3d(x, multiplier, negative_slope=0.2):
    """
    Fuses:
      y = MaxPool3d( LeakyReLU( LeakyReLU(x) * multiplier ) )
    where:
      x: [N, C, D, H, W]
      multiplier: [C, 1, 1, 1] (broadcast over N, D, H, W)
      MaxPool3d: kernel_size=2, stride=2, padding=0
    """
    assert x.is_cuda and multiplier.is_cuda, "Inputs must be CUDA tensors"
    assert x.ndim == 5, "x must be [N, C, D, H, W]"
    N, C, D_in, H_in, W_in = x.shape

    # MaxPool3d with kernel_size=2, stride=2, padding=0
    D_out = D_in // 2
    H_out = H_in // 2
    W_out = W_in // 2

    y = torch.empty((N, C, D_out, H_out, W_out), device=x.device, dtype=x.dtype)

    # Flatten multiplier to [C] for fast channel-wise access
    mul_flat = multiplier.view(C).contiguous()

    total_elems = N * C * D_out * H_out * W_out
    BLOCK = 128  # power-of-two as required

    grid = lambda META: (max(1, triton.cdiv(total_elems, META["BLOCK"])),)

    fused_leaky_relu_mul_maxpool3d_kernel[grid](
        x, mul_flat, y,
        N, C, D_out, H_out, W_out,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3), x.stride(4),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3), y.stride(4),
        total_elems,
        negative_slope,
        BLOCK=BLOCK,
        num_warps=4,
    )
    return y


class ModelNew(nn.Module):
    """
    Model that performs a 3D transposed convolution, applies LeakyReLU, multiplies by a learnable parameter,
    applies LeakyReLU again, and performs a max pooling operation, with the last three ops fused in Triton.
    """
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels,
            out_channels,
            kernel_size,
            stride=stride,
            padding=padding,
            output_padding=output_padding,
        )
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.negative_slope = 0.2

    def forward(self, x):
        x = self.conv_transpose(x)
        x = fused_leaky_relu_mul_maxpool3d(x, self.multiplier, negative_slope=self.negative_slope)
        return x
```

---

# Your Task

Implement the optimization strategy above. Focus on the specific bottleneck identified.

## Key Requirements

1. **Preserve correctness**: Maintain the same input/output behavior
2. **Apply the optimization**: Follow the implementation plan exactly
3. **Use valid Triton syntax**:
   - Every kernel MUST have `@triton.jit` decorator
   - Grid size MUST be > 0: use `triton.cdiv(N, BLOCK)` or `max(1, N // BLOCK)`
   - BLOCK sizes MUST be power-of-2: 16, 32, 64, 128, 256
   - No `continue`, `break`, `return` inside kernels (use masking)
   - Prefer `tl.dot(a, b, allow_tf32=True)` for matmul operations

4. **CRITICAL for RNN/GRU/LSTM Persistent Kernels**:
   - Time loop MUST be inside @triton.jit kernel, NOT in Python forward()
   - **HYBRID computation strategy** (CRITICAL for performance):
     * Precompute input-side gates OUTSIDE kernel: `gates_x = (T*B, In) @ W_ih` (ONE large GEMM)
     * INSIDE kernel: only recurrent-side: `for t: gates_h = h @ W_hh` (T small GEMMs)
   - CORRECT (FAST - use this):
     ```python
     # Python forward():
     gates_x_all = x.reshape(T*B, In) @ W_ih + b_ih  # ONE large GEMM
     gates_x_all = gates_x_all.view(T, B, 3*H)
     gru_persistent_kernel[grid](gates_x_all, h0, W_hh, ...)  # Launch ONCE

     @triton.jit
     def gru_persistent_kernel(gates_x_ptr, h_ptr, W_hh_ptr, ...):
         for t in range(T):  # Inside kernel
             gates_x_t = tl.load(gates_x_ptr + t*...)  # Precomputed
             gates_h = h @ W_hh  # Only recurrent GEMM
             h = (1-z)*n + z*h   # Fuse and update
     ```

5. **Output format**:
   - Imports: `import torch, torch.nn as nn, triton, triton.language as tl`
   - `@triton.jit` kernel(s)
   - Wrapper function(s)
   - `class ModelNew(nn.Module)` — REQUIRED
   - NO testing code, NO `if __name__ == "__main__"`

---

Generate the optimized kernel now. Output ONLY the complete Python code.
