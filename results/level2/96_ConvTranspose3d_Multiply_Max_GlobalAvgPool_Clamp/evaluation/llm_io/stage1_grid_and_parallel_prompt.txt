You are a Triton kernel optimization specialist. Generate the FASTEST possible kernel.

# Target GPU
GPU Name: 4090
Architecture: Ada Lovelace
• Compute Capability: 8.9
• Number of SMs: 128
• Memory Bandwidth: 1008 GB/s
• TF32 Tensor Core TFLOPS: 82.6 with dense
• BFLOAT16 Tensor Core TFLOPS: 165.2 with dense
• FP16 Tensor Core TFLOPS: 165.2 with dense
• Maximum number of registers per thread: 255
• Maximum threads per block: 1024
• Maximum threads per SM: 1536
• Warp size: 32
• Maximum concurrent warps per SM: 48
• Shared memory capacity per SM: 100 KB
• Maximum shared memory per thread block: 99 KB
• L2 cache (global, all SM shared): 72 MB

[OPTIMIZATION STAGE]

## Current Optimization Stage

Focus: Grid layout & indexing for FUSED operations.

⚠️ FUSION EXCLUSIONS (do NOT apply fusion rules to these):
- Reduction ops (sum, mean, softmax along axis)
- Atomic operations
- Irregular/data-dependent access patterns
- Cross-block dependencies

Key Principle:
- All fused ops share the SAME grid AND the SAME (offsets, mask) tuple
- Grid covers OUTPUT tensor dimensions

Hard Rules:
- Every fused op MUST use identical offset calculation
- Every fused op MUST use identical boundary mask
- If broadcast needed: explicit `[None, :]` or `[:, None]`, NOT different offsets
- Element-wise: 1D grid, single `offs = pid * BLOCK + tl.arange(0, BLOCK)`
- Matmul fusion: 2D grid, `offs_m/offs_n` shared by bias add & activation

Verification:
- Check: all tl.load/tl.store use same `offsets` variable
- Check: all masks derived from same boundary condition
- If ANY op needs different indexing → do NOT fuse, split kernel



[CURRENT CODE]
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.jit
def fused_post_ops_kernel(
    x_ptr,                 # Input tensor pointer
    out_ptr,               # Output tensor pointer
    N, C, D, H, W,         # Input dimensions
    scale,                 # Scalar multiplier
    K,                     # MaxPool kernel size
    stride_xn, stride_xc, stride_xd, stride_xh, stride_xw,
    stride_on, stride_oc, stride_od, stride_oh, stride_ow,
    BLOCK_C: tl.constexpr,
):
    """Fused kernel: Scale + MaxPool3d + GlobalAvgPool + Clamp"""
    pid_n = tl.program_id(0)  # Batch index
    pid_c = tl.program_id(1)  # Channel index (handles BLOCK_C channels)
    
    # Early exit for out-of-bounds programs
    if pid_n >= N:
        return
    
    # Process BLOCK_C channels (or remaining ones)
    channel_base = pid_c * BLOCK_C
    channel_offsets = tl.arange(0, BLOCK_C)
    channel_mask = channel_base + channel_offsets < C
    
    # Compute max pooling output dimensions
    D_out = D // K
    H_out = H // K
    W_out = W // K
    total_windows = D_out * H_out * W_out
    
    # Initialize accumulators for global average pooling
    gap_acc = tl.zeros((BLOCK_C,), dtype=tl.float32)
    valid_counts = tl.zeros((BLOCK_C,), dtype=tl.float32)
    
    # Loop over max pooling output windows
    for window_idx in range(total_windows):
        d_out = window_idx // (H_out * W_out)
        h_out = (window_idx % (H_out * W_out)) // W_out
        w_out = window_idx % W_out
        
        # Initialize max values for this window
        max_vals = tl.full((BLOCK_C,), -float('inf'), dtype=tl.float32)
        window_has_valid = tl.zeros((BLOCK_C,), dtype=tl.int32)
        
        # Compute max over K³ window
        for kd in range(K):
            for kh in range(K):
                for kw in range(K):
                    d_in = d_out * K + kd
                    h_in = h_out * K + kh
                    w_in = w_out * K + kw
                    
                    # Check if this position is within bounds
                    in_bounds = (d_in < D) & (h_in < H) & (w_in < W)
                    
                    if in_bounds:
                        # Load input values for all channels in block
                        c_indices = channel_base + channel_offsets
                        x_ptrs = (
                            x_ptr + pid_n * stride_xn + 
                            c_indices * stride_xc + 
                            d_in * stride_xd + h_in * stride_xh + w_in * stride_xw
                        )
                        # Load with channel mask
                        x_vals = tl.load(x_ptrs, mask=channel_mask, other=0.0)
                        x_vals = x_vals * scale
                        
                        # Update max values directly (no tl.load/tl.store on tensors)
                        max_vals = tl.where(x_vals > max_vals, x_vals, max_vals)
                        
                        # Mark channels with valid data
                        window_has_valid = tl.where(channel_mask, 1, window_has_valid)
        
        # Accumulate max values for valid windows
        valid_mask = (window_has_valid == 1) & channel_mask
        gap_acc = tl.where(valid_mask, gap_acc + max_vals, gap_acc)
        valid_counts = tl.where(valid_mask, valid_counts + 1.0, valid_counts)
    
    # Compute global average and clamp for all channels in block (vectorized)
    # Avoid division by zero
    avg_vals = tl.where(valid_counts > 0, gap_acc / valid_counts, 0.0)
    # Clamp between 0 and 1
    avg_vals = tl.minimum(tl.maximum(avg_vals, 0.0), 1.0)
    
    # Store results (expand to [C, 1, 1, 1] shape)
    c_indices = channel_base + channel_offsets
    out_ptrs = (
        out_ptr + pid_n * stride_on + 
        c_indices * stride_oc
    )
    tl.store(out_ptrs, avg_vals, mask=channel_mask)


def fused_post_convtranspose(x, scale, maxpool_kernel_size):
    """
    Fused operations: Scale + MaxPool3d + GlobalAvgPool + Clamp
    Input: [N, C, D, H, W] -> Output: [N, C, 1, 1, 1]
    """
    N, C, D, H, W = x.shape
    K = maxpool_kernel_size
    
    # Output tensor: [N, C, 1, 1, 1]
    out = torch.empty((N, C, 1, 1, 1), device=x.device, dtype=x.dtype)
    
    # Choose block size for channels (power of 2)
    BLOCK_C = min(triton.next_power_of_2(C), 16)
    
    # Grid configuration
    grid = (N, triton.cdiv(C, BLOCK_C))
    
    # Launch kernel
    fused_post_ops_kernel[grid](
        x, out,
        N, C, D, H, W,
        scale, K,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3), x.stride(4),
        out.stride(0), out.stride(1), out.stride(2), out.stride(3), out.stride(4),
        BLOCK_C=BLOCK_C,
    )
    
    return out


class ModelNew(nn.Module):
    """
    ConvTranspose3d (PyTorch native) + Fused post-ops (Triton)
    Uses PyTorch's ConvTranspose3d and fuses Scale + MaxPool3d + GlobalAvgPool + Clamp
    """
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size):
        super(ModelNew, self).__init__()
        # Keep ConvTranspose3d as PyTorch native - DO NOT reimplement in Triton
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels, out_channels, kernel_size,
            stride=stride, padding=padding
        )
        self.scale = scale
        self.maxpool_kernel_size = maxpool_kernel_size
        
    def forward(self, x):
        # Step 1: PyTorch native ConvTranspose3d
        x = self.conv_transpose(x)
        # Step 2: Fused post-ops in Triton
        x = fused_post_convtranspose(x, self.scale, self.maxpool_kernel_size)
        return x
```

[NCU PROFILING METRICS]
{
  "fused_post_ops_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 8.2,
    "launch__grid_size": 128,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 8.33,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 4.27,
    "lts__t_sector_hit_rate.pct": 0.13
  }
}

**Task**: Analyze the NCU metrics and current code, then generate optimized code that maximizes performance.

TRITON API CONSTRAINTS (CRITICAL):
- Triton has NO: tl.tanh, tl.sigmoid, tl.gelu, tl.silu, tl.softmax, tl.mish

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <optimized Triton code>
```
