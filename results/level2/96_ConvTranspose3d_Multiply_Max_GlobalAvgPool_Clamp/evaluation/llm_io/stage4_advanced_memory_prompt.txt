You are a Triton kernel optimization specialist. Generate the FASTEST possible kernel.

# Target GPU
GPU Name: 4090
Architecture: Ada Lovelace
• Compute Capability: 8.9
• Number of SMs: 128
• Memory Bandwidth: 1008 GB/s
• TF32 Tensor Core TFLOPS: 82.6 with dense
• BFLOAT16 Tensor Core TFLOPS: 165.2 with dense
• FP16 Tensor Core TFLOPS: 165.2 with dense
• Maximum number of registers per thread: 255
• Maximum threads per block: 1024
• Maximum threads per SM: 1536
• Warp size: 32
• Maximum concurrent warps per SM: 48
• Shared memory capacity per SM: 100 KB
• Maximum shared memory per thread block: 99 KB
• L2 cache (global, all SM shared): 72 MB

[OPTIMIZATION STAGE]

## Current Optimization Stage

Focus: Fine-tuning fused kernel parameters.

Params:
- num_warps ∈ {4, 8}
- num_stages ∈ {2, 3}

Conditional Rules (NOT one-size-fits-all):

IF register pressure LOW (regs < 96, no spill):
  - Try num_warps=8 for compute-bound fusion
  - num_stages=3 may help hide latency

IF register pressure HIGH (regs > 128 or occupancy_limit_registers):
  - Use num_warps=4 (fewer warps = more registers per warp)
  - Keep num_stages=2 (higher stages need more registers)

IF multi-input fusion (3+ distinct loads):
  - num_stages=2 preferred (each stage buffers all inputs)
  - num_warps=4 often better than 8

Autotune:
- Max 2-3 configs to reduce compilation time
- Always include conservative baseline (num_warps=4, num_stages=2)
- Test before/after: revert if gain < 2%



[CURRENT CODE]
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.jit
def scale_maxpool3d_kernel(
    x_ptr,                 # Input tensor pointer
    out_ptr,              # Output tensor pointer (maxpooled)
    N, C, D, H, W,        # Input dimensions
    D_out, H_out, W_out,  # Output dimensions
    scale,                # Scalar multiplier
    K,                    # MaxPool kernel size
    stride_xn, stride_xc, stride_xd, stride_xh, stride_xw,
    stride_on, stride_oc, stride_od, stride_oh, stride_ow,
    BLOCK_C: tl.constexpr,
):
    """Scale + MaxPool3d: Output shape [N, C, D_out, H_out, W_out]"""
    pid_n = tl.program_id(0)
    pid_c = tl.program_id(1)
    pid_w = tl.program_id(2)
    
    if pid_n >= N:
        return
    
    # Reconstruct 3D window index from linearized pid_w
    total_windows = D_out * H_out * W_out
    if pid_w >= total_windows:
        return
    
    d_out = pid_w // (H_out * W_out)
    h_out = (pid_w % (H_out * W_out)) // W_out
    w_out = pid_w % W_out
    
    # Channel block processing
    channel_base = pid_c * BLOCK_C
    channel_offsets = tl.arange(0, BLOCK_C)
    channel_mask = channel_base + channel_offsets < C
    
    # Initialize max values for all channels in block
    max_vals = tl.full((BLOCK_C,), -float('inf'), dtype=tl.float32)
    
    # Compute max over K³ window (unrolled loops for better performance)
    # Precompute base strides to avoid repeated computation
    base_n_offset = pid_n * stride_xn
    base_d_offset = d_out * K * stride_xd
    base_h_offset = h_out * K * stride_xh
    base_w_offset = w_out * K * stride_xw
    
    # Unroll the innermost loops for better performance
    for kd in range(K):
        d_in_offset = base_d_offset + kd * stride_xd
        for kh in range(K):
            h_in_offset = base_h_offset + kh * stride_xh
            for kw in range(K):
                w_in_offset = base_w_offset + kw * stride_xw
                
                # Load input values for all channels in block
                c_indices = channel_base + channel_offsets
                x_ptrs = (
                    x_ptr + base_n_offset + 
                    c_indices * stride_xc + 
                    d_in_offset + h_in_offset + w_in_offset
                )
                x_vals = tl.load(x_ptrs, mask=channel_mask, other=-float('inf'))
                x_vals = x_vals * scale  # Apply scaling
                max_vals = tl.maximum(max_vals, x_vals)
    
    # Store max values to intermediate tensor
    c_indices = channel_base + channel_offsets
    out_ptrs = (
        out_ptr + pid_n * stride_on + 
        c_indices * stride_oc + 
        d_out * stride_od + h_out * stride_oh + w_out * stride_ow
    )
    tl.store(out_ptrs, max_vals, mask=channel_mask)


@triton.jit
def global_avg_pool_clamp_kernel(
    x_ptr,                 # Input tensor pointer (maxpooled output)
    out_ptr,              # Output tensor pointer
    N, C, D, H, W,        # Input dimensions (maxpooled tensor)
    stride_xn, stride_xc, stride_xd, stride_xh, stride_xw,
    stride_on, stride_oc, stride_od, stride_oh, stride_ow,
    BLOCK_C: tl.constexpr,
    BLOCK_W: tl.constexpr,  # Number of windows per thread
):
    """GlobalAvgPool + Clamp: Output shape [N, C, 1, 1, 1]"""
    pid_n = tl.program_id(0)
    pid_c = tl.program_id(1)
    
    if pid_n >= N:
        return
    
    # Channel block processing
    channel_base = pid_c * BLOCK_C
    channel_offsets = tl.arange(0, BLOCK_C)
    channel_mask = channel_base + channel_offsets < C
    
    # Initialize accumulators
    sum_acc = tl.zeros((BLOCK_C,), dtype=tl.float32)
    count_acc = tl.zeros((BLOCK_C,), dtype=tl.float32)
    
    # Total number of elements to reduce (spatial dimensions)
    total_elements = D * H * W
    
    # Each program processes BLOCK_W elements
    for block_start in range(0, total_elements, BLOCK_W):
        elem_offsets = block_start + tl.arange(0, BLOCK_W)
        elem_mask = elem_offsets < total_elements
        
        if tl.sum(elem_mask) > 0:
            # Convert linear index to 3D indices
            d_idx = elem_offsets // (H * W)
            h_idx = (elem_offsets % (H * W)) // W
            w_idx = elem_offsets % W
            
            # Load input values for all channels and current batch of elements
            # We use broadcasting: [BLOCK_C, 1] * [1, BLOCK_W] -> [BLOCK_C, BLOCK_W]
            c_indices = channel_base + channel_offsets[:, None]
            d_indices = d_idx[None, :]
            h_indices = h_idx[None, :]
            w_indices = w_idx[None, :]
            
            # Compute pointer offsets using broadcasting
            ptr_offsets = (
                pid_n * stride_xn +
                c_indices * stride_xc +
                d_indices * stride_xd +
                h_indices * stride_xh +
                w_indices * stride_xw
            )
            
            x_ptrs = x_ptr + ptr_offsets
            # Load with combined mask (channel AND element)
            load_mask = channel_mask[:, None] & elem_mask[None, :]
            x_vals = tl.load(x_ptrs, mask=load_mask, other=0.0)
            
            # Accumulate sum and count
            sum_acc += tl.sum(x_vals, axis=1)
            count_acc += tl.sum(load_mask.to(tl.float32), axis=1)
    
    # Compute average and clamp
    avg_vals = tl.where(count_acc > 0, sum_acc / count_acc, 0.0)
    avg_vals = tl.minimum(tl.maximum(avg_vals, 0.0), 1.0)
    
    # Store results
    c_indices = channel_base + channel_offsets
    out_ptrs = (
        out_ptr + pid_n * stride_on + 
        c_indices * stride_oc
    )
    tl.store(out_ptrs, avg_vals, mask=channel_mask)


def fused_post_convtranspose(x, scale, maxpool_kernel_size):
    """
    Optimized fused operations using two kernels:
    1. Scale + MaxPool3d
    2. GlobalAvgPool + Clamp
    """
    N, C, D, H, W = x.shape
    K = maxpool_kernel_size
    
    # MaxPool3d output dimensions
    D_out = D // K
    H_out = H // K
    W_out = W // K
    
    # Intermediate tensor for maxpool output
    maxpool_out = torch.empty((N, C, D_out, H_out, W_out), 
                              device=x.device, dtype=x.dtype)
    
    # Kernel 1: Scale + MaxPool3d
    BLOCK_C1 = min(triton.next_power_of_2(C), 64)  # Increased for better utilization
    total_windows = D_out * H_out * W_out
    
    grid1 = (N, triton.cdiv(C, BLOCK_C1), total_windows)
    scale_maxpool3d_kernel[grid1](
        x, maxpool_out,
        N, C, D, H, W,
        D_out, H_out, W_out,
        scale, K,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3), x.stride(4),
        maxpool_out.stride(0), maxpool_out.stride(1), maxpool_out.stride(2),
        maxpool_out.stride(3), maxpool_out.stride(4),
        BLOCK_C=BLOCK_C1,
    )
    
    # Kernel 2: GlobalAvgPool + Clamp
    out = torch.empty((N, C, 1, 1, 1), device=x.device, dtype=x.dtype)
    BLOCK_C2 = min(triton.next_power_of_2(C), 32)
    BLOCK_W = 128  # Elements per thread
    
    grid2 = (N, triton.cdiv(C, BLOCK_C2))
    global_avg_pool_clamp_kernel[grid2](
        maxpool_out, out,
        N, C, D_out, H_out, W_out,
        maxpool_out.stride(0), maxpool_out.stride(1), maxpool_out.stride(2),
        maxpool_out.stride(3), maxpool_out.stride(4),
        out.stride(0), out.stride(1), out.stride(2), out.stride(3), out.stride(4),
        BLOCK_C=BLOCK_C2,
        BLOCK_W=BLOCK_W,
    )
    
    return out


class ModelNew(nn.Module):
    """
    ConvTranspose3d (PyTorch native) + Optimized fused post-ops (Triton)
    Uses two optimized kernels for better parallelism and memory access patterns
    """
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, scale, maxpool_kernel_size):
        super(ModelNew, self).__init__()
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels, out_channels, kernel_size,
            stride=stride, padding=padding
        )
        self.scale = scale
        self.maxpool_kernel_size = maxpool_kernel_size
        
    def forward(self, x):
        # Step 1: PyTorch native ConvTranspose3d
        x = self.conv_transpose(x)
        # Step 2: Optimized fused post-ops in Triton (two kernels)
        x = fused_post_convtranspose(x, self.scale, self.maxpool_kernel_size)
        return x
```

[NCU PROFILING METRICS]
{
  "scale_maxpool3d_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 38.55,
    "launch__grid_size": 1845120,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 95.72,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 22.45,
    "lts__t_sector_hit_rate.pct": 81.31
  },
  "global_avg_pool_clamp_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 14.45,
    "launch__grid_size": 128,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 8.33,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 38.48,
    "lts__t_sector_hit_rate.pct": 0.4
  }
}

**Task**: Analyze the NCU metrics and current code, then generate optimized code that maximizes performance.

TRITON API CONSTRAINTS (CRITICAL):
- Triton has NO: tl.tanh, tl.sigmoid, tl.gelu, tl.silu, tl.softmax, tl.mish

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <optimized Triton code>
```
