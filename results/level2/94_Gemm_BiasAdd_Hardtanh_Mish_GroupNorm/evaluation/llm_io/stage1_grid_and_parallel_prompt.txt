You are a Triton kernel optimization specialist. Generate the FASTEST possible kernel.

# Target GPU
GPU Name: 4090
Architecture: Ada Lovelace
• Compute Capability: 8.9
• Number of SMs: 128
• Memory Bandwidth: 1008 GB/s
• TF32 Tensor Core TFLOPS: 82.6 with dense
• BFLOAT16 Tensor Core TFLOPS: 165.2 with dense
• FP16 Tensor Core TFLOPS: 165.2 with dense
• Maximum number of registers per thread: 255
• Maximum threads per block: 1024
• Maximum threads per SM: 1536
• Warp size: 32
• Maximum concurrent warps per SM: 48
• Shared memory capacity per SM: 100 KB
• Maximum shared memory per thread block: 99 KB
• L2 cache (global, all SM shared): 72 MB

[OPTIMIZATION STAGE]

## Current Optimization Stage

Focus: Grid layout & indexing for FUSED operations.

⚠️ FUSION EXCLUSIONS (do NOT apply fusion rules to these):
- Reduction ops (sum, mean, softmax along axis)
- Atomic operations
- Irregular/data-dependent access patterns
- Cross-block dependencies

Key Principle:
- All fused ops share the SAME grid AND the SAME (offsets, mask) tuple
- Grid covers OUTPUT tensor dimensions

Hard Rules:
- Every fused op MUST use identical offset calculation
- Every fused op MUST use identical boundary mask
- If broadcast needed: explicit `[None, :]` or `[:, None]`, NOT different offsets
- Element-wise: 1D grid, single `offs = pid * BLOCK + tl.arange(0, BLOCK)`
- Matmul fusion: 2D grid, `offs_m/offs_n` shared by bias add & activation

Verification:
- Check: all tl.load/tl.store use same `offsets` variable
- Check: all masks derived from same boundary condition
- If ANY op needs different indexing → do NOT fuse, split kernel



[CURRENT CODE]
```python
# <complete ModelNew code with optimized Triton kernels>

import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.jit
def gemm_bias_hardtanh_mish_kernel(
    a_ptr, b_ptr,
    bias0_ptr, bias1_ptr,
    c_ptr,
    M, N, K,
    stride_am, stride_ak,
    stride_bk, stride_bn,
    stride_cm, stride_cn,
    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,
):
    """
    Fused kernel:
      C = mish(hardtanh(A @ B + bias0 + bias1))

    A: [M, K]
    B: [K, N]  (transposed weight)
    bias0: [N]  (linear bias)
    bias1: [N]  (extra bias added in the model)
    C: [M, N]
    """

    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
    offs_k = tl.arange(0, BLOCK_K)

    a_ptrs = a_ptr + offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak
    b_ptrs = b_ptr + offs_k[:, None] * stride_bk + offs_n[None, :] * stride_bn

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    for k in range(0, K, BLOCK_K):
        a = tl.load(
            a_ptrs,
            mask=(offs_m[:, None] < M) & (offs_k[None, :] < K - k),
            other=0.0,
        )
        b = tl.load(
            b_ptrs,
            mask=(offs_k[:, None] < K - k) & (offs_n[None, :] < N),
            other=0.0,
        )
        # Disable TF32 to match full FP32 PyTorch reference numerics
        acc += tl.dot(a, b, allow_tf32=False)

        a_ptrs += BLOCK_K * stride_ak
        b_ptrs += BLOCK_K * stride_bk

    # Add biases: bias0 (linear bias) + bias1 (extra bias)
    bias0 = tl.load(bias0_ptr + offs_n, mask=offs_n < N, other=0.0)
    bias1 = tl.load(bias1_ptr + offs_n, mask=offs_n < N, other=0.0)
    acc += (bias0 + bias1)[None, :]

    # Hardtanh: clamp to [-1, 1]
    acc = tl.minimum(tl.maximum(acc, -1.0), 1.0)

    # Mish: x * tanh(softplus(x)), with stable softplus
    abs_x = tl.abs(acc)
    softplus = tl.maximum(acc, 0.0) + tl.log(1.0 + tl.exp(-abs_x))

    e2 = tl.exp(2.0 * softplus)
    tanh_sp = (e2 - 1.0) / (e2 + 1.0)

    acc = acc * tanh_sp

    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn
    tl.store(
        c_ptrs,
        acc,
        mask=(offs_m[:, None] < M) & (offs_n[None, :] < N),
    )


def fused_gemm_bias_hardtanh_mish(x, weight, bias_linear, bias_extra):
    """
    x: [M, K]
    weight: [N, K]
    bias_linear: [N]
    bias_extra: [N]
    returns: [M, N]
    """
    assert x.is_cuda and weight.is_cuda
    M, K = x.shape
    N, K_w = weight.shape
    assert K == K_w, "in_features mismatch"

    c = torch.empty((M, N), device=x.device, dtype=x.dtype)

    # Use transposed weight for better memory access: [K, N]
    b = weight.t().contiguous()

    def grid(meta):
        return (
            triton.cdiv(M, meta["BLOCK_M"]),
            triton.cdiv(N, meta["BLOCK_N"]),
        )

    gemm_bias_hardtanh_mish_kernel[grid](
        x, b,
        bias_linear, bias_extra,
        c,
        M, N, K,
        x.stride(0), x.stride(1),
        b.stride(0), b.stride(1),
        c.stride(0), c.stride(1),
        BLOCK_M=64,
        BLOCK_N=128,
        BLOCK_K=32,
        num_warps=4,
        num_stages=2,
    )
    return c


@triton.jit
def groupnorm_kernel(
    x_ptr, gamma_ptr, beta_ptr, y_ptr,
    N, C, G,
    stride_xn, stride_xc,
    stride_yn, stride_yc,
    eps,
    GROUP_SIZE: tl.constexpr,
    BLOCK_SIZE: tl.constexpr,
):
    """
    GroupNorm over (N, C) with G groups, group size = GROUP_SIZE = C // G.

    For each (n, g):
      - Compute mean / var over channels [g*GROUP_SIZE : (g+1)*GROUP_SIZE]
      - y[n, c] = gamma[c] * (x[n, c] - mean) / sqrt(var + eps) + beta[c]
    """

    pid_n = tl.program_id(0)
    pid_g = tl.program_id(1)

    n = pid_n
    g = pid_g

    c_start = g * GROUP_SIZE

    # First pass: compute sum and sum of squares
    mean = 0.0
    m2 = 0.0

    for off in range(0, GROUP_SIZE, BLOCK_SIZE):
        offs = off + tl.arange(0, BLOCK_SIZE)
        mask = (n < N) & (g < G) & (offs < GROUP_SIZE)
        c = c_start + offs

        x_ptrs = x_ptr + n * stride_xn + c * stride_xc
        x = tl.load(x_ptrs, mask=mask, other=0.0)

        mean += tl.sum(x, axis=0)
        m2 += tl.sum(x * x, axis=0)

    inv_size = 1.0 / GROUP_SIZE
    mean = mean * inv_size
    var = m2 * inv_size - mean * mean
    var = tl.maximum(var, 0.0)
    rstd = 1.0 / tl.sqrt(var + eps)

    # Second pass: normalize, scale, shift
    for off in range(0, GROUP_SIZE, BLOCK_SIZE):
        offs = off + tl.arange(0, BLOCK_SIZE)
        mask = (n < N) & (g < G) & (offs < GROUP_SIZE)
        c = c_start + offs

        x_ptrs = x_ptr + n * stride_xn + c * stride_xc
        y_ptrs = y_ptr + n * stride_yn + c * stride_yc

        x = tl.load(x_ptrs, mask=mask, other=0.0)
        gamma = tl.load(gamma_ptr + c, mask=mask, other=1.0)
        beta = tl.load(beta_ptr + c, mask=mask, other=0.0)

        y = (x - mean) * rstd
        y = y * gamma + beta

        tl.store(y_ptrs, y, mask=mask)


def groupnorm_triton(x, weight, bias, num_groups, eps=1e-5):
    """
    x: [N, C] (contiguous)
    weight: [C]
    bias: [C]
    """
    assert x.is_cuda and weight.is_cuda and bias.is_cuda
    assert x.ndim == 2
    N, C = x.shape
    assert C % num_groups == 0, "num_channels must be divisible by num_groups"
    group_size = C // num_groups

    x_contig = x.contiguous()
    y = torch.empty_like(x_contig)

    def grid(meta):
        return (N, num_groups)

    groupnorm_kernel[grid](
        x_contig, weight, bias, y,
        N, C, num_groups,
        x_contig.stride(0), x_contig.stride(1),
        y.stride(0), y.stride(1),
        eps,
        GROUP_SIZE=group_size,
        BLOCK_SIZE=128,
        num_warps=4,
    )

    return y


class ModelNew(nn.Module):
    """
    Triton-optimized replacement for the reference model:

      x -> Linear -> +bias -> Hardtanh -> Mish -> GroupNorm

    The parameter/module structure mirrors the reference:
      - self.linear: nn.Linear(in_features, out_features)
      - self.bias:   nn.Parameter(bias_shape)
      - self.norm:   nn.GroupNorm(num_groups, out_features)
    """

    def __init__(self, in_features, out_features, bias_shape, num_groups):
        super(ModelNew, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.num_groups = num_groups
        self.eps = 1e-5

        # Match reference: use real nn.Linear / nn.GroupNorm modules
        self.linear = nn.Linear(in_features, out_features, bias=True)
        self.bias = nn.Parameter(torch.empty(bias_shape))
        self.norm = nn.GroupNorm(num_groups, out_features, eps=self.eps, affine=True)

    def forward(self, x):
        # Use Triton fused GEMM + bias + Hardtanh + Mish
        y = fused_gemm_bias_hardtanh_mish(
            x,
            self.linear.weight,
            self.linear.bias,
            self.bias,
        )
        # Use Triton GroupNorm with the exact same affine params as nn.GroupNorm
        y = groupnorm_triton(
            y,
            self.norm.weight,
            self.norm.bias,
            self.num_groups,
            self.eps,
        )
        return y
```

[NCU PROFILING METRICS]
{
  "gemm_bias_hardtanh_mish_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 71.52,
    "launch__grid_size": 1024,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 16.47,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 13.92,
    "lts__t_sector_hit_rate.pct": 93.9
  },
  "groupnorm_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 91.57,
    "launch__grid_size": 262144,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 82.3,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 17.64,
    "lts__t_sector_hit_rate.pct": 55.65
  }
}

**Task**: Analyze the NCU metrics and current code, then generate optimized code that maximizes performance.

TRITON API CONSTRAINTS (CRITICAL):
- Triton has NO: tl.tanh, tl.sigmoid, tl.gelu, tl.silu, tl.softmax, tl.mish

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <optimized Triton code>
```
