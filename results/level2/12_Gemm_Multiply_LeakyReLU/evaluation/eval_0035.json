{
  "timestamp": "2025-12-14T14:52:01",
  "reference_file": "KernelBench/level2/12_Gemm_Multiply_LeakyReLU.py",
  "candidate_file": "/home/hyc/LLMKernel/run/20251214_114625_batch_range6to24_deepseek_deepseek/12_Gemm_Multiply_LeakyReLU/code/kernel_20251214_145156.py",
  "tolerance": 0.001,
  "max_abs_err": 0.0212249755859375,
  "mean_abs_err": 0.00022767524933442473,
  "ref_latency_ms": {
    "avg": 3.182329607009888,
    "min": 3.171328067779541,
    "max": 3.194688081741333,
    "all": [
      3.194688081741333,
      3.180543899536133,
      3.171328067779541,
      3.1795198917388916,
      3.18556809425354
    ]
  },
  "test_latency_ms": {
    "avg": 3.7355520248413088,
    "min": 3.7068800926208496,
    "max": 3.778559923171997,
    "all": [
      3.778559923171997,
      3.7703680992126465,
      3.707904100418091,
      3.7068800926208496,
      3.714047908782959
    ]
  },
  "num_runs": 5,
  "model_init_args": [
    8192,
    8192,
    2.0,
    0.1
  ],
  "model_init_kwargs": {},
  "seed": 100,
  "align_stats": {
    "copied_same_shape": 0,
    "unique_shape_copied": 2,
    "mapped_shape": 0,
    "skipped": 0,
    "pair_aligner": 0,
    "pair_key": "Model->ModelNew"
  },
  "runnable": true,
  "phase": "stage4_advanced_memory",
  "pytorch_baseline_ms": 3.1479615688323976,
  "score": 0.8427031795832444
}