Fix the Triton kernel errors. Generate correct, high-performance code.

Current Error Log:
Traceback (most recent call last):
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 626, in compare_and_bench
    raise ValueError(
ValueError: Outputs are not close (atol=0.001, rtol=0.01). max_abs_err=3.125e+07, mean_abs_err=3.125e+07

Main Critical Problem Analysis:
Problem Analysis (from expert diagnosis):
critical_issue: ModelNew defines its own weight/bias parameters instead of using the Conv2d module’s parameters, so it does not share weights with the reference Model.
why_it_matters: The reference and Triton models run with different convolution weights and biases, making their outputs fundamentally different and producing huge absolute errors across all samples.
minimal_fix_hint: Use the same nn.Conv2d module as the reference or explicitly copy conv.weight and conv.bias into ModelNew’s parameters before running the Triton kernels.

Focus your fix on addressing the identified critical issue.


Broken Code:
```python
# <complete ModelNew code with optimized Triton kernels>
import torch
import torch.nn as nn
import triton
import triton.language as tl


# ============================
# Conv2D forward kernel
# ============================

@triton.autotune(
    configs=[
        triton.Config(
            {'BLOCK_M': 32, 'BLOCK_N': 32},
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {'BLOCK_M': 64, 'BLOCK_N': 32},
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {'BLOCK_M': 32, 'BLOCK_N': 64},
            num_warps=4,
            num_stages=2,
        ),
    ],
    key=['H_out', 'W_out', 'C_out'],
)
@triton.jit
def conv2d_forward_kernel(
    x_ptr, w_ptr, b_ptr, y_ptr,
    N, H, W, H_out, W_out, C_out,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_wn, stride_wc, stride_wh, stride_ww,
    stride_yn, stride_yc, stride_yh, stride_yw,
    C_IN: tl.constexpr, K: tl.constexpr,
    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr,
):
    # pid_m: flattened output positions (n, oh, ow)
    # pid_n: output channels
    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)

    P = N * H_out * W_out

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    mask_m = offs_m < P
    mask_n = offs_n < C_out

    # Decode flattened index -> (n, oh, ow)
    HW_out = H_out * W_out
    n_idx = offs_m // HW_out
    rem = offs_m % HW_out
    oh_idx = rem // W_out
    ow_idx = rem % W_out

    # Precompute base input offsets (top-left of receptive field for each output)
    # x[n, ic, oh + kh, ow + kw] index = base + ic*stride_xc + kh*stride_xh + kw*stride_xw
    x_base_offsets = (
        n_idx * stride_xn +
        oh_idx * stride_xh +
        ow_idx * stride_xw
    )

    # Accumulator in fp32
    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    # Convolution: sum over input channels and kernel window
    # Inner loops kept small; BLOCK_M/BLOCK_N autotuned to keep register pressure in check.
    for ic in range(0, C_IN):
        ic_offset = ic * stride_xc
        for kh in tl.static_range(0, K):
            kh_offset = kh * stride_xh
            for kw in tl.static_range(0, K):
                kw_offset = kw * stride_xw

                # Input pointers: shape [BLOCK_M]
                x_offsets = x_base_offsets + ic_offset + kh_offset + kw_offset
                x_ptrs = x_ptr + x_offsets
                x_vals = tl.load(x_ptrs, mask=mask_m, other=0.0).to(tl.float32)

                # Weight pointers: shape [BLOCK_N]
                w_offsets = (
                    offs_n * stride_wn +
                    ic * stride_wc +
                    kh * stride_wh +
                    kw * stride_ww
                )
                w_ptrs = w_ptr + w_offsets
                w_vals = tl.load(w_ptrs, mask=mask_n, other=0.0).to(tl.float32)

                # Outer product update
                acc += x_vals[:, None] * w_vals[None, :]

    # Add bias (fused, uses same offs_n/masks)
    bias_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0).to(tl.float32)
    acc += bias_vals[None, :]

    # Store result
    y_ptrs = (
        y_ptr +
        n_idx[:, None] * stride_yn +
        offs_n[None, :] * stride_yc +
        oh_idx[:, None] * stride_yh +
        ow_idx[:, None] * stride_yw
    )
    out_mask = mask_m[:, None] & mask_n[None, :]
    tl.store(y_ptrs, acc, mask=out_mask)


# ============================
# AvgPool + Sigmoid + Sum kernel
# ============================

@triton.autotune(
    configs=[
        triton.Config(
            {'BLOCK_HW': 64, 'BLOCK_C': 4},
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {'BLOCK_HW': 128, 'BLOCK_C': 4},
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {'BLOCK_HW': 64, 'BLOCK_C': 8},
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {'BLOCK_HW': 32, 'BLOCK_C': 4},  # conservative fallback for high register pressure
            num_warps=2,
            num_stages=2,
        ),
    ],
    key=['H_out', 'W_out', 'C_OUT', 'POOL_K'],
)
@triton.jit
def avgpool_sigmoid_sum_kernel(
    x_ptr, out_ptr,
    N, H_out, W_out, Hp, Wp,
    total_hw,
    stride_xn, stride_xc, stride_xh, stride_xw,
    C_OUT: tl.constexpr, POOL_K: tl.constexpr,
    BLOCK_HW: tl.constexpr, BLOCK_C: tl.constexpr,
):
    """
    Layout:
      - 3D grid: [pooled_hw_tiles, channel_tiles, batch]
      - Tile over pooled spatial positions (HW) and channels (C).
      - One atomic_add per (n, tile_hw, tile_c) program.
    """
    pid_hw = tl.program_id(0)  # tile over pooled H*W
    pid_c = tl.program_id(1)   # tile over channels
    pid_n = tl.program_id(2)   # batch index

    # Tiled pooled spatial indices
    offs_hw = pid_hw * BLOCK_HW + tl.arange(0, BLOCK_HW)
    hw_mask = offs_hw < total_hw

    # Decode flattened pooled index -> (ohp, owp) in pooled space
    ohp = offs_hw // Wp
    owp = offs_hw % Wp

    # Tiled channels
    offs_c = pid_c * BLOCK_C + tl.arange(0, BLOCK_C)
    c_mask = offs_c < C_OUT

    # Accumulate pooled values for this (n, tile_hw, tile_c)
    acc = tl.zeros((BLOCK_HW, BLOCK_C), dtype=tl.float32)

    base_n = pid_n * stride_xn

    for ph in tl.static_range(0, POOL_K):
        for pw in tl.static_range(0, POOL_K):
            ih = ohp * POOL_K + ph  # [BLOCK_HW]
            iw = owp * POOL_K + pw  # [BLOCK_HW]

            x_offsets = (
                base_n +
                ih[:, None] * stride_xh +
                iw[:, None] * stride_xw +
                offs_c[None, :] * stride_xc
            )
            mask = hw_mask[:, None] & c_mask[None, :]
            x_vals = tl.load(
                x_ptr + x_offsets,
                mask=mask,
                other=0.0,
            ).to(tl.float32)
            acc += x_vals

    # Average pooling
    pool_area = 1.0 / (POOL_K * POOL_K)
    acc = acc * pool_area

    # Sigmoid: 1 / (1 + exp(-x))
    exp_neg = tl.exp(-acc)
    sig = 1.0 / (1.0 + exp_neg)

    # Zero-out inactive lanes (to avoid polluting reduction)
    mask = hw_mask[:, None] & c_mask[None, :]
    sig = sig * mask.to(sig.dtype)

    # Reduce over tile (HW, C) -> scalar contribution for this (n)
    tile_sum = tl.sum(sig, axis=0)
    tile_sum = tl.sum(tile_sum, axis=0)

    # Atomic add into output[n]
    tl.atomic_add(out_ptr + pid_n, tile_sum)


# ============================
# Wrapper functions
# ============================

def conv2d_triton(x, weight, bias, kernel_size: int):
    """
    x:      [N, C_in, H, W]
    weight: [C_out, C_in, K, K]
    bias:   [C_out]
    """
    assert x.ndim == 4
    assert weight.ndim == 4
    assert bias.ndim == 1

    N, C_in, H, W = x.shape
    C_out, C_in_w, K, K_w = weight.shape
    assert C_in_w == C_in and K_w == kernel_size and K == kernel_size
    assert bias.shape[0] == C_out

    # Valid conv2d (stride=1, padding=0)
    H_out = H - kernel_size + 1
    W_out = W - kernel_size + 1
    assert H_out > 0 and W_out > 0

    x_contig = x.contiguous()
    w_contig = weight.contiguous()
    b_contig = bias.contiguous()

    y = torch.empty((N, C_out, H_out, W_out), device=x.device, dtype=x.dtype)

    P = N * H_out * W_out

    def grid(meta):
        return (
            triton.cdiv(P, meta['BLOCK_M']),
            triton.cdiv(C_out, meta['BLOCK_N']),
        )

    conv2d_forward_kernel[grid](
        x_contig, w_contig, b_contig, y,
        N, H, W, H_out, W_out, C_out,
        x_contig.stride(0), x_contig.stride(1),
        x_contig.stride(2), x_contig.stride(3),
        w_contig.stride(0), w_contig.stride(1),
        w_contig.stride(2), w_contig.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        C_IN=C_in,
        K=kernel_size,
    )

    return y


def avgpool_sigmoid_sum_triton(conv_out, pool_kernel_size: int):
    """
    conv_out: [N, C_out, H_out, W_out]
    Returns:  [N] (sum over channels and spatial dims of sigmoid(avg_pool(conv_out)))
    """
    assert conv_out.ndim == 4
    N, C_out, H_out, W_out = conv_out.shape

    stride = pool_kernel_size
    Hp = (H_out - pool_kernel_size) // stride + 1
    Wp = (W_out - pool_kernel_size) // stride + 1
    assert Hp > 0 and Wp > 0

    x_contig = conv_out.contiguous()
    out = torch.zeros((N,), device=conv_out.device, dtype=conv_out.dtype)

    total_hw = Hp * Wp

    def grid(meta):
        return (
            triton.cdiv(total_hw, meta['BLOCK_HW']),  # pooled H*W tiles
            triton.cdiv(C_out, meta['BLOCK_C']),      # channel tiles
            N,                                        # batch dimension
        )

    avgpool_sigmoid_sum_kernel[grid](
        x_contig,
        out,
        N, H_out, W_out, Hp, Wp,
        total_hw,
        x_contig.stride(0), x_contig.stride(1),
        x_contig.stride(2), x_contig.stride(3),
        C_OUT=C_out,
        POOL_K=pool_kernel_size,
    )

    return out


# ============================
# Model wrapper
# ============================

class ModelNew(nn.Module):
    """
    Triton implementation of:
      Conv2d -> AvgPool2d -> Sigmoid -> Sum over [C, H, W]
    """

    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):
        super(ModelNew, self).__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.pool_kernel_size = pool_kernel_size

        # Match PyTorch Conv2d parameter shapes (bias enabled)
        self.weight = nn.Parameter(
            torch.randn(out_channels, in_channels, kernel_size, kernel_size)
        )
        self.bias = nn.Parameter(torch.randn(out_channels))

    def forward(self, x):
        # x: [N, C_in, H, W]
        y_conv = conv2d_triton(x, self.weight, self.bias, self.kernel_size)
        out = avgpool_sigmoid_sum_triton(y_conv, self.pool_kernel_size)
        return out
```

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl, AND any other modules used (e.g., import math if using math.sqrt)
   2. @triton.jit decorated kernel function(s) — NO continue/break/return inside loops (use masking)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels — THIS CLASS IS REQUIRED
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs
3. Learn from previous repair attempts to avoid repeating the same mistakes
4. Ensure ALL imports are included at the top (common mistake: forgetting `import math`)

```python
# <corrected code>
```
