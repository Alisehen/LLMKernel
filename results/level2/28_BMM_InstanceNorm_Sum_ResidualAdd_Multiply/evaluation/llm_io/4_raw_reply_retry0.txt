```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


# ---------------------------------------------------------------
# 1. GEMM (Linear) Kernel:  C = A @ B + bias
#    A: [M, K], B: [K, N], bias: [N], C: [M, N]
#    Aggressively tuned for RTX 4090 (Ada, SM 8.9)
#
#    Notes:
#      - Tensor-Core-friendly tl.dot with allow_tf32=True
#      - Autotune with 3 configs, including conservative baseline
#        (num_warps=4, num_stages=2) to keep register pressure in check.
# ---------------------------------------------------------------

@triton.autotune(
    configs=[
        # Conservative baseline: good occupancy, low register pressure
        triton.Config(
            {'BLOCK_M': 128, 'BLOCK_N': 128, 'BLOCK_K': 32},
            num_warps=4,
            num_stages=2,
        ),
        # Slightly more aggressive N tile, still 4 warps / 2 stages
        triton.Config(
            {'BLOCK_M': 64, 'BLOCK_N': 256, 'BLOCK_K': 32},
            num_warps=4,
            num_stages=2,
        ),
        # High-throughput config if register pressure allows it
        triton.Config(
            {'BLOCK_M': 128, 'BLOCK_N': 256, 'BLOCK_K': 32},
            num_warps=8,
            num_stages=3,
        ),
    ],
    key=['M', 'N', 'K'],
)
@triton.jit
def linear_gemm_kernel(
    a_ptr,      # [M, K]
    b_ptr,      # [K, N]
    bias_ptr,   # [N]
    c_ptr,      # [M, N]
    M, N, K,
    stride_am, stride_ak,   # A strides
    stride_bk, stride_bn,   # B strides
    stride_cm, stride_cn,   # C strides
    BLOCK_M: tl.constexpr,
    BLOCK_N: tl.constexpr,
    BLOCK_K: tl.constexpr,
):
    # 2D grid of tiles covering C = [M, N]
    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
    offs_k = tl.arange(0, BLOCK_K)

    tl.multiple_of(offs_m, BLOCK_M)
    tl.multiple_of(offs_n, BLOCK_N)
    tl.multiple_of(offs_k, BLOCK_K)

    mask_m = offs_m < M
    mask_n = offs_n < N

    # Pointers to first K-tile for this C-tile
    a_ptrs = a_ptr + (offs_m[:, None] * stride_am + offs_k[None, :] * stride_ak)
    b_ptrs = b_ptr + (offs_k[:, None] * stride_bk + offs_n[None, :] * stride_bn)

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    k = 0
    while k < K:
        k_mask = (offs_k + k) < K

        a = tl.load(
            a_ptrs,
            mask=mask_m[:, None] & k_mask[None, :],
            other=0.0,
        )
        b = tl.load(
            b_ptrs,
            mask=k_mask[:, None] & mask_n[None, :],
            other=0.0,
        )

        # Tensor-Core-friendly dot (TF32 for FP32 inputs on Ada)
        acc += tl.dot(a, b, allow_tf32=True)

        a_ptrs += BLOCK_K * stride_ak
        b_ptrs += BLOCK_K * stride_bk
        k += BLOCK_K

    # Fused bias add (broadcast over M)
    bias = tl.load(bias_ptr + offs_n, mask=mask_n, other=0.0)
    acc += bias[None, :]

    # Final store for C
    c_ptrs = c_ptr + (offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn)
    mask = mask_m[:, None] & mask_n[None, :]
    tl.store(c_ptrs, acc, mask=mask)


# ---------------------------------------------------------------
# 2. Fused Instance-Norm + Residual Kernel (Row-wise)
#    Input:
#      x_ptr  : [B, N]  (linear output)
#      y_ptr  : [B, N]  (residual input)
#    Output:
#      out_ptr: [B, N]
#
#    Per row b:
#      mean_b = sum_n x[b,n] / N
#      var_b  = sum_n x[b,n]^2 / N - mean_b^2
#      rstd_b = 1 / sqrt(var_b + eps)
#      out[b,n] = ((x[b,n] - mean_b) * rstd_b + y[b,n]) * y[b,n]
#
#    Implementation:
#      - 1 program per row (grid = [B])
#      - Two streaming passes over x:
#          pass 1: compute mean/var (in registers)
#          pass 2: normalize + residual + final store
#      - Only ONE tl.store per element (final output)
#
#    Autotune:
#      - Baseline: num_warps=4, num_stages=2
#      - Aggressive: num_warps=8, num_stages=3
# ---------------------------------------------------------------

@triton.autotune(
    configs=[
        triton.Config(
            {'BLOCK_N': 256},
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {'BLOCK_N': 256},
            num_warps=8,
            num_stages=3,
        ),
    ],
    key=['N'],
)
@triton.jit
def fused_instancenorm_residual_kernel(
    x_ptr,        # [B, N]
    y_ptr,        # [B, N]
    out_ptr,      # [B, N]
    B, N,
    stride_xm, stride_xn,
    stride_ym, stride_yn,
    stride_om, stride_on,
    eps,
    invN,         # 1.0 / N (float32)
    BLOCK_N: tl.constexpr,
):
    row = tl.program_id(0)
    offs_n = tl.arange(0, BLOCK_N)
    tl.multiple_of(offs_n, BLOCK_N)

    # Base pointers for this row (grid = [B], so row is always valid)
    x_row_ptr = x_ptr + row * stride_xm
    y_row_ptr = y_ptr + row * stride_ym
    o_row_ptr = out_ptr + row * stride_om

    # -----------------------
    # Pass 1: compute mean/var
    # -----------------------
    sum_val = tl.zeros((), dtype=tl.float32)
    sum_sq_val = tl.zeros((), dtype=tl.float32)

    col = 0
    while col < N:
        cols = col + offs_n
        mask = cols < N
        x = tl.load(
            x_row_ptr + cols * stride_xn,
            mask=mask,
            other=0.0,
        )
        sum_val += tl.sum(x, axis=0)
        sum_sq_val += tl.sum(x * x, axis=0)
        col += BLOCK_N

    mean = sum_val * invN
    var = sum_sq_val * invN - mean * mean
    rstd = 1.0 / tl.sqrt(var + eps)

    # -----------------------
    # Pass 2: normalize + residual + final store
    # -----------------------
    col = 0
    while col < N:
        cols = col + offs_n
        mask = cols < N

        x = tl.load(
            x_row_ptr + cols * stride_xn,
            mask=mask,
            other=0.0,
        )
        y = tl.load(
            y_row_ptr + cols * stride_yn,
            mask=mask,
            other=0.0,
        )

        x_norm = (x - mean) * rstd
        out = (x_norm + y) * y

        tl.store(
            o_row_ptr + cols * stride_on,
            out,
            mask=mask,
        )

        col += BLOCK_N


# ---------------------------------------------------------------
# 3. Python Wrappers
# ---------------------------------------------------------------

def launch_linear_gemm(a, b_t, bias, out):
    """
    Launches optimized GEMM:
        out = a @ b_t + bias
    Shapes:
        a   : [M, K]
        b_t : [K, N]
        bias: [N]
        out : [M, N]
    """
    M, K = a.shape
    K_b, N = b_t.shape
    assert K_b == K
    assert out.shape == (M, N)

    grid = lambda META: (
        triton.cdiv(M, META['BLOCK_M']),
        triton.cdiv(N, META['BLOCK_N']),
    )

    linear_gemm_kernel[grid](
        a, b_t, bias, out,
        M, N, K,
        a.stride(0), a.stride(1),
        b_t.stride(0), b_t.stride(1),
        out.stride(0), out.stride(1),
    )


def launch_fused_instancenorm_residual(x, y, out, eps: float):
    """
    Fused row-wise mean/var + instance-like normalization + residual:
        mean_b = mean_n x[b,n]
        var_b  = var_n  x[b,n]
        out[b,n] = ((x[b,n] - mean_b) / sqrt(var_b + eps) + y[b,n]) * y[b,n]

    x,y,out: [B, N], contiguous row-major.
    """
    B, N = x.shape
    assert y.shape == (B, N)
    assert out.shape == (B, N)

    grid = (B,)

    invN = 1.0 / float(N)

    fused_instancenorm_residual_kernel[grid](
        x,
        y,
        out,
        B,
        N,
        x.stride(0),
        x.stride(1),
        y.stride(0),
        y.stride(1),
        out.stride(0),
        out.stride(1),
        eps,
        invN,
    )


def fused_linear_instance_norm_residual(x, y, weight, bias, eps: float):
    """
    High-performance fused pipeline:
      1) Linear:   lin = x @ weight.T + bias
      2) Row-wise instance-like norm over features of `lin`
      3) Residual: out = ((norm(lin) + y) * y)

    x      : [B, in_features]   (float32)
    y      : [B, out_features]  (float32)
    weight : [out_features, in_features]
    bias   : [out_features]
    returns: [B, out_features]
    """
    assert x.is_cuda and y.is_cuda and weight.is_cuda and bias.is_cuda
    assert x.dtype == torch.float32
    assert y.dtype == torch.float32
    assert weight.dtype == torch.float32
    assert bias.dtype == torch.float32

    # Ensure optimal memory layout
    x = x.contiguous()
    y = y.contiguous()
    weight = weight.contiguous()
    bias = bias.contiguous()

    B, K = x.shape
    out_features, K_w = weight.shape
    assert K_w == K
    assert y.shape[0] == B and y.shape[1] == out_features

    # GEMM: x @ weight.T + bias
    w_t = weight.t().contiguous()  # [K, out_features]
    out_lin = torch.empty((B, out_features), device=x.device, dtype=x.dtype)

    launch_linear_gemm(x, w_t, bias, out_lin)

    # Fused instance-norm + residual over rows of out_lin
    out = torch.empty_like(out_lin)
    launch_fused_instancenorm_residual(out_lin, y, out, eps)

    return out


# ---------------------------------------------------------------
# 4. nn.Module Wrapper
# ---------------------------------------------------------------

class ModelNew(nn.Module):
    """
    Triton-optimized module performing:
      - Linear:      x -> x @ weight.T + bias
      - Row-wise instance-like normalization over features
      - Residual:    out = ((norm(x) + y) * y)
    """
    def __init__(self, in_features, out_features, eps=1e-5, momentum=0.1):
        super(ModelNew, self).__init__()
        self.weight = nn.Parameter(torch.empty(out_features, in_features))
        self.bias = nn.Parameter(torch.empty(out_features))
        self.eps = eps
        self.momentum = momentum  # kept for API parity, not used

        # Initialize like nn.Linear
        nn.init.kaiming_uniform_(self.weight, a=5 ** 0.5)
        fan_in = self.weight.size(1)
        bound = 1.0 / (fan_in ** 0.5)
        nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, x, y):
        return fused_linear_instance_norm_residual(
            x, y, self.weight, self.bias, self.eps
        )
```