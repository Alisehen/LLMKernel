You are a Triton kernel debugging expert. Analyze the error and identify the root cause.

## ERROR LOG
```
Traceback (most recent call last):
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 538, in compare_and_bench
    test_out, _ = _run_once(test_model, inp, dev)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 132, in _run_once
    out = model(*inp)
          ^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/run/20251215_024803_batch_range31to55_openai_deepseek/31_Conv2d_Min_Add_Multiply/code/kernel_20251215_025032.py", line 275, in forward
    return conv2d_min_bias_scale_triton(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/run/20251215_024803_batch_range31to55_openai_deepseek/31_Conv2d_Min_Add_Multiply/code/kernel_20251215_025032.py", line 196, in conv2d_min_bias_scale_triton
    conv2d_min_bias_scale_kernel[grid](
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 347, in <lambda>
    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 569, in run
    kernel = self.compile(src, target=target, options=options.__dict__)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py", line 278, in compile
    module = src.make_ir(options, codegen_fns, module_map, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py", line 81, in make_ir
    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
triton.compiler.errors.CompilationError: at 64:4:
    # Implicit GEMM over K = C_in * K_H * K_W
    #   X_im2col: [P, K]
    #   W       : [C_out, K]
    #   Out     : [P, C_out]
    # We compute tiles: [BLOCK_M, BLOCK_K] x [BLOCK_K, BLOCK_N] -> [BLOCK_M,BLOCK_N]
    # -------------------------------------------------------------------------
    K_TOTAL = C_in * K_H * K_W
    KH_KW = K_H * K_W

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    for k0 in tl.static_range(0, K_TOTAL, BLOCK_K):
    ^
AssertionError('int32[] used as tl.static_range end value is not a constexpr')
```

## Expected Behavior (PyTorch Reference)
```python
import torch
import torch.nn as nn

class Model(nn.Module):
    """
    Simple model that performs a convolution, takes the minimum with a constant, adds a bias term, and multiplies by a scaling factor.
    """
    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):
        super(Model, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.constant_value = constant_value
        self.bias = nn.Parameter(torch.randn(bias_shape))
        self.scaling_factor = scaling_factor

    def forward(self, x):
        x = self.conv(x)
        x = torch.min(x, torch.tensor(self.constant_value))
        x = x + self.bias
        x = x * self.scaling_factor
        return x

batch_size = 128
in_channels = 64
out_channels = 128
height = width = 128
kernel_size = 3
constant_value = 0.5
bias_shape = (out_channels, 1, 1)
scaling_factor = 2.0

def get_inputs():
    return [torch.rand(batch_size, in_channels, height, width)]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor]
```

## Current Implementation (Broken Triton Kernel)
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.jit
def conv2d_min_bias_scale_kernel(
    x_ptr,            # [N, C_in, H_in, W_in]
    w_ptr,            # [C_out, C_in, K_H, K_W]
    conv_bias_ptr,    # [C_out]
    extra_bias_ptr,   # [C_out, 1, 1]
    out_ptr,          # [N, C_out, H_out, W_out]
    N,                # batch size
    H_in, W_in,
    C_out,
    H_out, W_out,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_wo, stride_wc, stride_wkh, stride_wkw,
    stride_cb0,
    stride_eb0,
    stride_on, stride_oc, stride_oh, stride_ow,
    const_val,        # scalar (float32)
    scaling,          # scalar (float32)
    C_in: tl.constexpr,
    K_H: tl.constexpr,
    K_W: tl.constexpr,
    BLOCK_M: tl.constexpr,
    BLOCK_N: tl.constexpr,
    BLOCK_K: tl.constexpr,
):
    # -------------------------------------------------------------------------
    # 2D matmul-style grid over output:
    #   M axis: P = N * H_out * W_out
    #   N axis: C_out
    # Fused ops (bias, min, extra_bias, scale) use the SAME offs_m/offs_n & mask
    # -------------------------------------------------------------------------
    pid_m = tl.program_id(0)  # along P = N * H_out * W_out
    pid_n = tl.program_id(1)  # along C_out

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    P = N * H_out * W_out
    valid_m = offs_m < P
    valid_n = offs_n < C_out

    # Hint for better codegen
    tl.multiple_of(offs_m, BLOCK_M)
    tl.multiple_of(offs_n, BLOCK_N)

    # Decode offs_m -> (n, oh, ow) once per program
    DHW = H_out * W_out
    n_idx = offs_m // DHW
    rem = offs_m % DHW
    oh_idx = rem // W_out
    ow_idx = rem % W_out

    # -------------------------------------------------------------------------
    # Implicit GEMM over K = C_in * K_H * K_W
    #   X_im2col: [P, K]
    #   W       : [C_out, K]
    #   Out     : [P, C_out]
    # We compute tiles: [BLOCK_M, BLOCK_K] x [BLOCK_K, BLOCK_N] -> [BLOCK_M,BLOCK_N]
    # -------------------------------------------------------------------------
    K_TOTAL = C_in * K_H * K_W
    KH_KW = K_H * K_W

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    for k0 in tl.static_range(0, K_TOTAL, BLOCK_K):
        offs_k = k0 + tl.arange(0, BLOCK_K)
        k_mask = offs_k < K_TOTAL

        # Map K index -> (ic, kh, kw)
        ic_idx = offs_k // KH_KW
        remk = offs_k % KH_KW
        kh_idx = remk // K_W
        kw_idx = remk % K_W

        # ---------------------------------------------------------------------
        # Load X tile: shape [BLOCK_M, BLOCK_K]
        # X[n, ic, oh+kh, ow+kw]
        # ---------------------------------------------------------------------
        ih = oh_idx[:, None] + kh_idx[None, :]
        iw = ow_idx[:, None] + kw_idx[None, :]

        x_ptrs = (
            x_ptr
            + n_idx[:, None] * stride_xn
            + ic_idx[None, :] * stride_xc
            + ih * stride_xh
            + iw * stride_xw
        )
        x_mask = valid_m[:, None] & k_mask[None, :]
        x_vals = tl.load(x_ptrs, mask=x_mask, other=0.0)

        # ---------------------------------------------------------------------
        # Load W tile: shape [BLOCK_K, BLOCK_N]
        # W[oc, ic, kh, kw]
        # ---------------------------------------------------------------------
        w_ptrs = (
            w_ptr
            + offs_n[None, :] * stride_wo
            + ic_idx[:, None] * stride_wc
            + kh_idx[:, None] * stride_wkh
            + kw_idx[:, None] * stride_wkw
        )
        w_mask = k_mask[:, None] & valid_n[None, :]
        w_vals = tl.load(w_ptrs, mask=w_mask, other=0.0)

        # ---------------------------------------------------------------------
        # Matrix multiply accumulate on the tile
        # Uses Tensor Cores when x/w are fp16/bf16, falls back to FMA otherwise.
        # ---------------------------------------------------------------------
        acc += tl.dot(x_vals, w_vals, out_dtype=tl.float32)

    # -------------------------------------------------------------------------
    # Fused post-ops: bias -> min(const) -> extra_bias -> scale
    # All ops share SAME offs_n (channels) and SAME masks (valid_n, valid_m).
    # -------------------------------------------------------------------------
    # conv bias: [C_out] -> broadcast over BLOCK_M
    cb_ptrs = conv_bias_ptr + offs_n * stride_cb0
    cb = tl.load(cb_ptrs, mask=valid_n, other=0.0).to(tl.float32)
    acc += cb[None, :]

    # elementwise min with constant
    acc = tl.where(acc < const_val, acc, const_val)

    # extra bias: [C_out,1,1] with stride along dim0
    eb_ptrs = extra_bias_ptr + offs_n * stride_eb0
    eb = tl.load(eb_ptrs, mask=valid_n, other=0.0).to(tl.float32)
    acc += eb[None, :]

    # scale
    acc = acc * scaling

    # -------------------------------------------------------------------------
    # Store output: [N, C_out, H_out, W_out]
    # Uses the SAME (offs_m, offs_n) decoding and boundary masks.
    # -------------------------------------------------------------------------
    out_ptrs = (
        out_ptr
        + n_idx[:, None] * stride_on
        + offs_n[None, :] * stride_oc
        + oh_idx[:, None] * stride_oh
        + ow_idx[:, None] * stride_ow
    )
    store_mask = valid_m[:, None] & valid_n[None, :]
    tl.store(out_ptrs, acc, mask=store_mask)


def conv2d_min_bias_scale_triton(x, weight, conv_bias, extra_bias, constant_value, scaling_factor):
    """
    x          : [N, C_in, H_in, W_in]
    weight     : [C_out, C_in, K_H, K_W]
    conv_bias  : [C_out]
    extra_bias : [C_out, 1, 1]
    """
    assert x.is_cuda, "Input must be on CUDA device for Triton kernel"
    assert x.ndim == 4 and weight.ndim == 4
    assert conv_bias.ndim == 1
    assert extra_bias.ndim == 3

    N, C_in, H_in, W_in = x.shape
    C_out, C_in_w, K_H, K_W = weight.shape
    assert C_in_w == C_in, "Weight C_in mismatch with input"

    # Assume stride=1, padding=0, dilation=1, groups=1
    H_out = H_in - K_H + 1
    W_out = W_in - K_W + 1
    assert H_out > 0 and W_out > 0

    out = torch.empty((N, C_out, H_out, W_out), device=x.device, dtype=x.dtype)

    # Use existing strides; layout-agnostic
    sx0, sx1, sx2, sx3 = x.stride()
    sw0, sw1, sw2, sw3 = weight.stride()
    scb0 = conv_bias.stride(0)
    seb0 = extra_bias.stride(0)
    so0, so1, so2, so3 = out.stride()

    # Grid over P = N * H_out * W_out and C_out
    P = N * H_out * W_out

    # Tuned tile sizes for Ada / 4090; good balance of occupancy & reuse
    BLOCK_M = 64
    BLOCK_N = 64
    BLOCK_K = 32

    grid = (
        triton.cdiv(P, BLOCK_M),
        triton.cdiv(C_out, BLOCK_N),
    )

    conv2d_min_bias_scale_kernel[grid](
        x,
        weight,
        conv_bias,
        extra_bias,
        out,
        N,
        H_in,
        W_in,
        C_out,
        H_out,
        W_out,
        sx0,
        sx1,
        sx2,
        sx3,
        sw0,
        sw1,
        sw2,
        sw3,
        scb0,
        seb0,
        so0,
        so1,
        so2,
        so3,
        float(constant_value),
        float(scaling_factor),
        C_in=C_in,
        K_H=K_H,
        K_W=K_W,
        BLOCK_M=BLOCK_M,
        BLOCK_N=BLOCK_N,
        BLOCK_K=BLOCK_K,
        num_warps=4,
        num_stages=3,
    )
    return out


class ModelNew(nn.Module):
    """
    Triton-accelerated version of:

        x = conv2d(x)
        x = min(x, constant_value)
        x = x + bias
        x = x * scaling_factor

    where conv2d has its own bias term.
    """

    def __init__(self, in_channels, out_channels, kernel_size, constant_value, bias_shape, scaling_factor):
        super(ModelNew, self).__init__()
        if isinstance(kernel_size, int):
            k_h = k_w = kernel_size
        else:
            k_h, k_w = kernel_size
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = (k_h, k_w)

        # Conv2d-like parameters (weight + conv bias)
        self.weight = nn.Parameter(
            torch.randn(out_channels, in_channels, k_h, k_w)
        )
        self.conv_bias = nn.Parameter(
            torch.randn(out_channels)
        )

        # Extra bias added after min, broadcast over spatial
        self.bias = nn.Parameter(torch.randn(*bias_shape))

        # Scalars
        self.constant_value = float(constant_value)
        self.scaling_factor = float(scaling_factor)

    def forward(self, x):
        # x is assumed to be [N, C_in, H, W], typically on CUDA
        return conv2d_min_bias_scale_triton(
            x,
            self.weight,
            self.conv_bias,
            self.bias,
            self.constant_value,
            self.scaling_factor,
        )
```

---

## Your Task

Identify the **single most critical issue** that causes the error above.

### Analysis Guidelines

1. **Focus on root cause**, not symptoms
   - Bad: "Output is wrong"
   - Good: "BLOCK_K loop missing, only processes first 32 elements of K dimension"

2. **Be specific about WHAT and WHERE**
   - Bad: "Memory access issue"
   - Good: "Line 45: tl.atomic_add(c_block_ptr, acc) - atomic_add requires scalar pointer, not block_ptr"

3. **Prioritize by impact**
   - Correctness bugs > Performance issues > Style problems
   - Algorithm errors > Implementation details

### Output Format

**CRITICAL: You MUST output ONLY valid JSON. No other text allowed.**

```json
{
  "critical_issue": "<Concise description of THE root cause, max 30 words>",
  "why_it_matters": "<Why this causes the observed error, max 35 words>",
  "minimal_fix_hint": "<What needs to change (not how), max 30 words>"
}
```

**Remember**: Output ONLY the JSON block. No explanations, no commentary, no additional text.
