```python
import torch, torch.nn as nn, triton, triton.language as tl


@triton.jit
def conv2d_kernel(
    x_ptr, w_ptr, bias_ptr, y_ptr,
    N, C_out,
    H_in, W_in,
    H_out, W_out,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_wn, stride_wc, stride_wh, stride_ww,
    stride_yn, stride_yc, stride_yh, stride_yw,
    C_in: tl.constexpr,   # reduction over input channels
    K_h: tl.constexpr,    # kernel height
    K_w: tl.constexpr,    # kernel width
    BLOCK_M: tl.constexpr,  # tiles over N * H_out * W_out
    BLOCK_N: tl.constexpr,  # kept for interface, not used in indexing
):
    # program ids:
    #  - pid_m: tile over flattened (n, h_out, w_out)
    #  - pid_co: single output channel index
    pid_m = tl.program_id(0)
    pid_co = tl.program_id(1)

    # flattened M dimension = N * H_out * W_out
    M = N * H_out * W_out
    HW_out = H_out * W_out

    # offsets for this block over M
    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    mask_m = offs_m < M

    # decode offs_m -> (n, h_out, w_out)
    n = offs_m // HW_out
    rem = offs_m % HW_out
    h_out_idx = rem // W_out
    w_out_idx = rem % W_out

    # scalar output channel index
    co = pid_co
    mask_co = co < C_out

    # accumulator for this (block of M) x (single co)
    acc = tl.zeros((BLOCK_M,), dtype=tl.float32)

    # explicit reduction over input channels and kernel window
    for c in tl.static_range(0, C_in):
        for kh in tl.static_range(0, K_h):
            h_in_idx = h_out_idx + kh
            for kw in tl.static_range(0, K_w):
                w_in_idx = w_out_idx + kw

                # x[n, c, h_in_idx, w_in_idx]
                x_ptrs = (
                    x_ptr
                    + n * stride_xn
                    + c * stride_xc
                    + h_in_idx * stride_xh
                    + w_in_idx * stride_xw
                )
                x_vals = tl.load(x_ptrs, mask=mask_m, other=0.0).to(tl.float32)

                # w[co, c, kh, kw] - scalar
                w_offset = (
                    co * stride_wn
                    + c * stride_wc
                    + kh * stride_wh
                    + kw * stride_ww
                )
                w_val = tl.load(w_ptr + w_offset, mask=mask_co, other=0.0).to(tl.float32)

                acc += x_vals * w_val

    # add bias per output channel
    b = tl.load(bias_ptr + co, mask=mask_co, other=0.0).to(tl.float32)
    acc = acc + b

    # store to y[n, co, h_out_idx, w_out_idx]
    y_ptrs = (
        y_ptr
        + n * stride_yn
        + co * stride_yc
        + h_out_idx * stride_yh
        + w_out_idx * stride_yw
    )
    tl.store(y_ptrs, acc, mask=mask_m & mask_co)


def fused_conv_bn_scale(
    x: torch.Tensor,
    weight: torch.Tensor,
    bias: torch.Tensor,
    bn_weight: torch.Tensor,
    bn_bias: torch.Tensor,
    running_mean: torch.Tensor,
    running_var: torch.Tensor,
    eps: float,
    scaling_factor: float,
):
    # x: [N, C_in, H_in, W_in]
    x = x.contiguous()
    weight = weight.contiguous()
    if bias is not None:
        bias = bias.contiguous()
    else:
        bias = torch.zeros(weight.size(0), device=x.device, dtype=x.dtype)

    N, C_in, H_in, W_in = x.shape
    C_out, C_w_in, K_h, K_w = weight.shape
    assert C_w_in == C_in, "Conv weight in_channels mismatch"

    # Valid convolution: padding=0, stride=1, dilation=1
    H_out = H_in - K_h + 1
    W_out = W_in - K_w + 1

    # Allocate output for conv(x) + bias
    z = torch.empty((N, C_out, H_out, W_out), device=x.device, dtype=x.dtype)

    # Launch Triton conv2d kernel
    M = N * H_out * W_out

    def grid(META):
        return (
            triton.cdiv(M, META["BLOCK_M"]),  # over N*H_out*W_out
            C_out,                            # one program per output channel
        )

    conv2d_kernel[grid](
        x, weight, bias, z,
        N, C_out,
        H_in, W_in,
        H_out, W_out,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        weight.stride(0), weight.stride(1), weight.stride(2), weight.stride(3),
        z.stride(0), z.stride(1), z.stride(2), z.stride(3),
        C_in=C_in,
        K_h=K_h,
        K_w=K_w,
        BLOCK_M=64,
        BLOCK_N=64,  # kept for interface; not used in indexing
        num_warps=4,
        num_stages=2,
    )

    # BatchNorm (inference-style) + global scaling:
    # y = scaling_factor * [ bn_weight * (z - running_mean) / sqrt(running_var + eps) + bn_bias ]
    inv_std = torch.rsqrt(running_var + eps)  # [C_out]

    # Reshape for broadcasting over N, H_out, W_out
    bn_w = bn_weight.view(1, -1, 1, 1)
    bn_b = bn_bias.view(1, -1, 1, 1)
    mean = running_mean.view(1, -1, 1, 1)
    inv_std_b = inv_std.view(1, -1, 1, 1)

    y = scaling_factor * (bn_w * (z - mean) * inv_std_b + bn_b)
    return y


class ModelNew(nn.Module):
    """
    Triton-accelerated model:
    Conv2d + BatchNorm2d (inference-style) + scaling.
    Convolution is computed in a Triton kernel; BN + scale in PyTorch for
    numerical correctness matching nn.Conv2d + nn.BatchNorm2d + scalar multiply.
    """
    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor):
        super(ModelNew, self).__init__()
        if isinstance(kernel_size, int):
            k_h = k_w = kernel_size
        else:
            k_h, k_w = kernel_size

        # Conv parameters
        self.weight = nn.Parameter(
            torch.randn(out_channels, in_channels, k_h, k_w)
        )
        self.bias = nn.Parameter(torch.randn(out_channels))

        # BatchNorm-like parameters (inference behavior)
        self.bn_weight = nn.Parameter(torch.ones(out_channels))
        self.bn_bias = nn.Parameter(torch.zeros(out_channels))
        self.register_buffer("running_mean", torch.zeros(out_channels))
        self.register_buffer("running_var", torch.ones(out_channels))
        self.bn_eps = 1e-5

        # Final scaling factor
        self.scaling_factor = float(scaling_factor)

    def forward(self, x):
        return fused_conv_bn_scale(
            x,
            self.weight,
            self.bias,
            self.bn_weight,
            self.bn_bias,
            self.running_mean,
            self.running_var,
            self.bn_eps,
            self.scaling_factor,
        )
```