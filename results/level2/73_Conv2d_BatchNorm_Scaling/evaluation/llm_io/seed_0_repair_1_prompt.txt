Fix the Triton kernel errors. Generate correct code.

## ERROR LOG
```
Traceback (most recent call last):
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 644, in compare_and_bench
    raise ValueError(
ValueError: Outputs are not close (atol=1, rtol=1). max_abs_err=3.595e+00, mean_abs_err=1.744e+00
```

## Broken Code
```python
import torch, torch.nn as nn, triton, triton.language as tl


@triton.jit
def conv2d_bn_scale_kernel(
    x_ptr, w_ptr,
    scale_ptr, shift_ptr,
    y_ptr,
    N, C_in, H_in, W_in,
    C_out, K_h, K_w,
    H_out, W_out,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_wn, stride_wc, stride_wh, stride_ww,
    stride_yn, stride_yc, stride_yh, stride_yw,
    BLOCK_M: tl.constexpr,  # rows: N * H_out * W_out
    BLOCK_N: tl.constexpr,  # columns: C_out
    BLOCK_K: tl.constexpr,  # reduction: C_in * K_h * K_w
):
    # Program IDs for tiles along M and N dimensions
    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)

    # Offsets in the output "matrix" representation:
    # M dimension corresponds to (n, h_out, w_out)
    # N dimension corresponds to output channels (C_out)
    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    M = N * H_out * W_out
    K_total = C_in * K_h * K_w
    HW_out = H_out * W_out

    mask_m = offs_m < M
    mask_n = offs_n < C_out

    # Map M-index to (n, h_out, w_out)
    offs_m_b = offs_m[:, None]  # (BLOCK_M, 1)
    n = offs_m_b // HW_out
    rem = offs_m_b % HW_out
    h_out = rem // W_out
    w_out = rem % W_out

    # Accumulator in fp32
    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    K_hw = K_h * K_w

    # Reduction over K = C_in * K_h * K_w
    for k_start in range(0, K_total, BLOCK_K):
        offs_k = k_start + tl.arange(0, BLOCK_K)
        offs_k_b = offs_k[None, :]      # (1, BLOCK_K)
        offs_k_bk = offs_k[:, None]     # (BLOCK_K, 1)

        # ---- Input X: compute (c_in, k_h, k_w) from K index for each column ----
        c_in = offs_k_b // K_hw
        rem2 = offs_k_b % K_hw
        k_h = rem2 // K_w
        k_w = rem2 % K_w

        # Spatial positions in input
        h_in = h_out + k_h  # (BLOCK_M, BLOCK_K)
        w_in = w_out + k_w  # (BLOCK_M, BLOCK_K)

        # Pointers for X
        x_ptrs = (
            x_ptr
            + n * stride_xn
            + c_in * stride_xc
            + h_in * stride_xh
            + w_in * stride_xw
        )

        mask_a = (
            mask_m[:, None]
            & (offs_k_b < K_total)
            & (h_in >= 0)
            & (h_in < H_in)
            & (w_in >= 0)
            & (w_in < W_in)
        )

        a = tl.load(x_ptrs, mask=mask_a, other=0.0)

        # ---- Weights W: compute (c_in, k_h, k_w) from K index for each row ----
        c_in_k = offs_k_bk // K_hw
        rem2_k = offs_k_bk % K_hw
        k_h_k = rem2_k // K_w
        k_w_k = rem2_k % K_w

        offs_n_b = offs_n[None, :]  # (1, BLOCK_N)

        w_ptrs = (
            w_ptr
            + offs_n_b * stride_wn
            + c_in_k * stride_wc
            + k_h_k * stride_wh
            + k_w_k * stride_ww
        )

        mask_b = (offs_k_bk < K_total) & (offs_n_b < C_out)

        b = tl.load(w_ptrs, mask=mask_b, other=0.0)

        # Matrix multiply-accumulate
        acc += tl.dot(a, b, allow_tf32=True)

    # Apply fused per-channel scale & shift (includes BatchNorm + global scaling)
    scale = tl.load(scale_ptr + offs_n, mask=mask_n, other=0.0)  # (BLOCK_N,)
    shift = tl.load(shift_ptr + offs_n, mask=mask_n, other=0.0)  # (BLOCK_N,)

    acc = acc * scale[None, :] + shift[None, :]

    # Map back to output tensor indices and store
    n_b = n           # (BLOCK_M, 1)
    h_b = h_out
    w_b = w_out
    co_b = offs_n[None, :]  # (1, BLOCK_N)

    y_ptrs = (
        y_ptr
        + n_b * stride_yn
        + co_b * stride_yc
        + h_b * stride_yh
        + w_b * stride_yw
    )

    mask_y = (
        mask_m[:, None]
        & mask_n[None, :]
        & (h_b >= 0)
        & (h_b < H_out)
        & (w_b >= 0)
        & (w_b < W_out)
    )

    tl.store(y_ptrs, acc, mask=mask_y)


def fused_conv_bn_scale(
    x: torch.Tensor,
    weight: torch.Tensor,
    bias: torch.Tensor,
    bn_weight: torch.Tensor,
    bn_bias: torch.Tensor,
    running_mean: torch.Tensor,
    running_var: torch.Tensor,
    eps: float,
    scaling_factor: float,
):
    # x: [N, C_in, H_in, W_in]
    x = x.contiguous()
    weight = weight.contiguous()
    if bias is not None:
        bias = bias.contiguous()

    N, C_in, H_in, W_in = x.shape
    C_out, C_w_in, K_h, K_w = weight.shape
    assert C_w_in == C_in, "Conv weight in_channels mismatch"

    # Valid convolution: no padding, stride=1, dilation=1
    H_out = H_in - K_h + 1
    W_out = W_in - K_w + 1

    # Compute fused per-channel scale and shift for:
    # y = scaling_factor * BN(conv(x))
    # BN(y) = bn_weight * (y - running_mean) / sqrt(running_var + eps) + bn_bias
    inv_std = torch.rsqrt(running_var + eps)
    bn_scale = bn_weight * inv_std  # per-channel

    if bias is not None:
        shift_term = bn_scale * (bias - running_mean)
    else:
        shift_term = bn_scale * (-running_mean)

    scale = scaling_factor * bn_scale
    shift = scaling_factor * (shift_term + bn_bias)

    scale = scale.contiguous()
    shift = shift.contiguous()

    y = torch.empty((N, C_out, H_out, W_out), device=x.device, dtype=x.dtype)

    grid = lambda META: (
        triton.cdiv(N * H_out * W_out, META["BLOCK_M"]),
        triton.cdiv(C_out, META["BLOCK_N"]),
    )

    conv2d_bn_scale_kernel[grid](
        x, weight,
        scale, shift,
        y,
        N, C_in, H_in, W_in,
        C_out, K_h, K_w,
        H_out, W_out,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        weight.stride(0), weight.stride(1), weight.stride(2), weight.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        BLOCK_M=64,
        BLOCK_N=64,
        BLOCK_K=32,
        num_warps=4,
        num_stages=2,
    )
    return y


class ModelNew(nn.Module):
    """
    Triton-optimized model:
    Fuses Conv2d + BatchNorm2d (inference-style) + scaling into a single kernel.
    """
    def __init__(self, in_channels, out_channels, kernel_size, scaling_factor):
        super(ModelNew, self).__init__()
        if isinstance(kernel_size, int):
            k_h = k_w = kernel_size
        else:
            k_h, k_w = kernel_size

        # Conv parameters
        self.weight = nn.Parameter(
            torch.randn(out_channels, in_channels, k_h, k_w)
        )
        self.bias = nn.Parameter(torch.randn(out_channels))

        # BatchNorm-like parameters (inference behavior)
        self.bn_weight = nn.Parameter(torch.ones(out_channels))
        self.bn_bias = nn.Parameter(torch.zeros(out_channels))
        self.register_buffer("running_mean", torch.zeros(out_channels))
        self.register_buffer("running_var", torch.ones(out_channels))
        self.bn_eps = 1e-5

        # Final scaling factor
        self.scaling_factor = float(scaling_factor)

    def forward(self, x):
        return fused_conv_bn_scale(
            x,
            self.weight,
            self.bias,
            self.bn_weight,
            self.bn_bias,
            self.running_mean,
            self.running_var,
            self.bn_eps,
            self.scaling_factor,
        )
```

## CRITICAL — These cause 60%+ of failures:
1. EVERY kernel function MUST have `@triton.jit` decorator — MANDATORY
2. Grid size MUST be > 0: use `triton.cdiv(N, BLOCK)` or `max(1, N // BLOCK)`
3. BLOCK sizes MUST be power-of-2: 16, 32, 64, 128, 256
4. `tl.program_id(axis)` only supports axis = 0, 1, 2
5. No `continue`, `break`, `return` inside loops — use masking
6. No tensor indexing with loop vars: `x[:, i]` is INVALID
7. mask shape MUST match data shape in tl.load/tl.store

## Missing Triton Functions (implement manually):
- tl.tanh, tl.sigmoid, tl.gelu, tl.silu, tl.softmax, tl.mish

## OUTPUT FORMAT (STRICT):
1. Imports: torch, torch.nn, triton, triton.language as tl (and math if needed)
2. @triton.jit decorated kernel function(s)
3. Wrapper function(s) for grid calculation and kernel launch
4. class ModelNew(nn.Module) — REQUIRED

Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <corrected code>
```
