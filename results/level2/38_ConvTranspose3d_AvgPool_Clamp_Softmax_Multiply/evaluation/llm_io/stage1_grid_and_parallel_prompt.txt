You are a Triton kernel optimization specialist. Generate the FASTEST possible kernel.

# Target GPU
GPU Name: 4090
Architecture: Ada Lovelace
• Compute Capability: 8.9
• Number of SMs: 128
• Memory Bandwidth: 1008 GB/s
• TF32 Tensor Core TFLOPS: 82.6 with dense
• BFLOAT16 Tensor Core TFLOPS: 165.2 with dense
• FP16 Tensor Core TFLOPS: 165.2 with dense
• Maximum number of registers per thread: 255
• Maximum threads per block: 1024
• Maximum threads per SM: 1536
• Warp size: 32
• Maximum concurrent warps per SM: 48
• Shared memory capacity per SM: 100 KB
• Maximum shared memory per thread block: 99 KB
• L2 cache (global, all SM shared): 72 MB

[OPTIMIZATION STAGE]

## Current Optimization Stage

Focus: Grid layout & indexing for FUSED operations.

⚠️ FUSION EXCLUSIONS (do NOT apply fusion rules to these):
- Reduction ops (sum, mean, softmax along axis)
- Atomic operations
- Irregular/data-dependent access patterns
- Cross-block dependencies

Key Principle:
- All fused ops share the SAME grid AND the SAME (offsets, mask) tuple
- Grid covers OUTPUT tensor dimensions

Hard Rules:
- Every fused op MUST use identical offset calculation
- Every fused op MUST use identical boundary mask
- If broadcast needed: explicit `[None, :]` or `[:, None]`, NOT different offsets
- Element-wise: 1D grid, single `offs = pid * BLOCK + tl.arange(0, BLOCK)`
- Matmul fusion: 2D grid, `offs_m/offs_n` shared by bias add & activation

Verification:
- Check: all tl.load/tl.store use same `offsets` variable
- Check: all masks derived from same boundary condition
- If ANY op needs different indexing → do NOT fuse, split kernel



[CURRENT CODE]
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.jit
def clamp_softmax_scale_kernel(
    x_ptr, scale_ptr, out_ptr,
    B, C, L,
    stride_xb, stride_xc, stride_xl,
    stride_ob, stride_oc, stride_ol,
    clamp_min, clamp_max,
    BLOCK_L: tl.constexpr,
):
    """
    Fused kernel over x of shape [B, C, L]:

    1) Clamp: y = clamp(x, clamp_min, clamp_max)
    2) Softmax over the last dimension L (spatial dim flattened)
    3) Multiply by per-channel scale: scale[c]

    Each program instance processes one (b, c) row of length L.
    """
    pid = tl.program_id(0)
    n_rows = B * C
    if pid >= n_rows:
        return

    # Decode (b, c) from linear row index
    b = pid // C
    c = pid % C

    # Row base pointers
    row_x_ptr = x_ptr + b * stride_xb + c * stride_xc
    row_out_ptr = out_ptr + b * stride_ob + c * stride_oc

    # Per-channel scale
    scale_val = tl.load(scale_ptr + c)

    # First pass: compute max over clamped values for numerical stability
    max_val = tl.full((), -float("inf"), tl.float32)

    for start in range(0, L, BLOCK_L):
        offs_l = start + tl.arange(0, BLOCK_L)
        mask = offs_l < L

        x = tl.load(row_x_ptr + offs_l * stride_xl, mask=mask, other=clamp_min)
        # Clamp
        x = tl.maximum(x, clamp_min)
        x = tl.minimum(x, clamp_max)

        block_max = tl.max(x, axis=0)
        max_val = tl.maximum(max_val, block_max)

    # Second pass: compute sum of exp(x - max_val)
    sum_exp = tl.zeros((), dtype=tl.float32)

    for start in range(0, L, BLOCK_L):
        offs_l = start + tl.arange(0, BLOCK_L)
        mask = offs_l < L

        x = tl.load(row_x_ptr + offs_l * stride_xl, mask=mask, other=clamp_min)
        x = tl.maximum(x, clamp_min)
        x = tl.minimum(x, clamp_max)

        exp_x = tl.exp(x - max_val)
        # Zero out contributions from out-of-bounds elements
        exp_x = exp_x * mask
        sum_exp += tl.sum(exp_x, axis=0)

    inv_sum = 1.0 / sum_exp

    # Third pass: write normalized softmax * scale
    for start in range(0, L, BLOCK_L):
        offs_l = start + tl.arange(0, BLOCK_L)
        mask = offs_l < L

        x = tl.load(row_x_ptr + offs_l * stride_xl, mask=mask, other=clamp_min)
        x = tl.maximum(x, clamp_min)
        x = tl.minimum(x, clamp_max)

        exp_x = tl.exp(x - max_val) * inv_sum * scale_val
        tl.store(row_out_ptr + offs_l * stride_ol, exp_x, mask=mask)


def fused_clamp_softmax_scale(x, scale, clamp_min, clamp_max):
    """
    x:     [B, C, D, H, W]
    scale: [1, C, 1, 1, 1] or [C]
    Returns:
        y: [B, C, D, H, W]
        with y = softmax(clamp(x)) over spatial dims, then * scale (per-channel).
    """
    assert x.is_cuda, "Input must be on CUDA for Triton kernel"

    B, C, D, H, W = x.shape
    L = D * H * W

    # Flatten spatial dimensions: [B, C, L]
    x_flat = x.view(B, C, L)
    out_flat = torch.empty_like(x_flat)

    # Per-channel scale as 1D: [C]
    scale_1d = scale.view(-1)

    stride_xb, stride_xc, stride_xl = x_flat.stride()
    stride_ob, stride_oc, stride_ol = out_flat.stride()

    BLOCK_L = 1024  # power-of-2, constexpr

    grid = (B * C,)

    clamp_softmax_scale_kernel[grid](
        x_flat, scale_1d, out_flat,
        B, C, L,
        stride_xb, stride_xc, stride_xl,
        stride_ob, stride_oc, stride_ol,
        clamp_min, clamp_max,
        BLOCK_L=BLOCK_L,
    )

    return out_flat.view(B, C, D, H, W)


class ModelNew(nn.Module):
    """
    Model that performs:
      AvgPool3d (PyTorch) ->
      ConvTranspose3d (PyTorch) ->
      Clamp + Spatial Softmax + Per-channel Scale (Triton fused)
    """
    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size,
        stride,
        padding,
        output_padding,
        pool_kernel_size,
        clamp_min,
        clamp_max,
    ):
        super(ModelNew, self).__init__()
        self.avg_pool = nn.AvgPool3d(pool_kernel_size)
        # Keep ConvTranspose3d as PyTorch native (per instructions)
        self.conv_transpose = nn.ConvTranspose3d(
            in_channels,
            out_channels,
            kernel_size,
            stride=stride,
            padding=padding,
            output_padding=output_padding,
        )
        self.clamp_min = clamp_min
        self.clamp_max = clamp_max
        # Per-channel learnable scale
        self.scale = nn.Parameter(torch.ones(1, out_channels, 1, 1, 1))

    def forward(self, x):
        """
        x: [B, in_channels, D, H, W]
        returns: [B, out_channels, D_out, H_out, W_out]
        """
        x = self.avg_pool(x)
        x = self.conv_transpose(x)
        x = fused_clamp_softmax_scale(x, self.scale, self.clamp_min, self.clamp_max)
        return x
```

[NCU PROFILING METRICS]
{
  "clamp_softmax_scale_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 5.79,
    "launch__grid_size": 2048,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 82.53,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 92.35,
    "lts__t_sector_hit_rate.pct": 25.01
  }
}

**Task**: Analyze the NCU metrics and current code, then generate optimized code that maximizes performance.

TRITON API CONSTRAINTS (CRITICAL):
- Triton has NO: tl.tanh, tl.sigmoid, tl.gelu, tl.silu, tl.softmax, tl.mish

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <optimized Triton code>
```
