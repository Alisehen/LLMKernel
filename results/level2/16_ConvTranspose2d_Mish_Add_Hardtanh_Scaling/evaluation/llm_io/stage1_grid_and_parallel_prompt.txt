You are a Triton kernel optimization specialist. Generate the FASTEST possible kernel.

# Target GPU
GPU Name: 4090
Architecture: Ada Lovelace
• Compute Capability: 8.9
• Number of SMs: 128
• Memory Bandwidth: 1008 GB/s
• TF32 Tensor Core TFLOPS: 82.6 with dense
• BFLOAT16 Tensor Core TFLOPS: 165.2 with dense
• FP16 Tensor Core TFLOPS: 165.2 with dense
• Maximum number of registers per thread: 255
• Maximum threads per block: 1024
• Maximum threads per SM: 1536
• Warp size: 32
• Maximum concurrent warps per SM: 48
• Shared memory capacity per SM: 100 KB
• Maximum shared memory per thread block: 99 KB
• L2 cache (global, all SM shared): 72 MB

[OPTIMIZATION STAGE]

## Current Optimization Stage

Focus: Grid layout & indexing for FUSED operations.

⚠️ FUSION EXCLUSIONS (do NOT apply fusion rules to these):
- Reduction ops (sum, mean, softmax along axis)
- Atomic operations
- Irregular/data-dependent access patterns
- Cross-block dependencies

Key Principle:
- All fused ops share the SAME grid AND the SAME (offsets, mask) tuple
- Grid covers OUTPUT tensor dimensions

Hard Rules:
- Every fused op MUST use identical offset calculation
- Every fused op MUST use identical boundary mask
- If broadcast needed: explicit `[None, :]` or `[:, None]`, NOT different offsets
- Element-wise: 1D grid, single `offs = pid * BLOCK + tl.arange(0, BLOCK)`
- Matmul fusion: 2D grid, `offs_m/offs_n` shared by bias add & activation

Verification:
- Check: all tl.load/tl.store use same `offsets` variable
- Check: all masks derived from same boundary condition
- If ANY op needs different indexing → do NOT fuse, split kernel



[CURRENT CODE]
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl
import math


@triton.jit
def fused_mish_add_hardtanh_scale_kernel(
    x_ptr,
    out_ptr,
    N, C, H, W,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_on, stride_oc, stride_oh, stride_ow,
    add_value,
    scale,
    BLOCK_C: tl.constexpr,
    BLOCK_H: tl.constexpr,
    BLOCK_W: tl.constexpr,
):
    """
    Fused kernel: Mish + Add + Hardtanh + Scale
    Input: [N, C, H, W] -> Output: [N, C, H, W]
    """
    pid_n = tl.program_id(0)
    pid_c = tl.program_id(1)
    pid_h = tl.program_id(2)

    # Compute base pointers for this block
    x_base = x_ptr + pid_n * stride_xn + pid_c * stride_xc + pid_h * stride_xh
    out_base = out_ptr + pid_n * stride_on + pid_c * stride_oc + pid_h * stride_oh

    # Create masks for W dimension
    w_offsets = tl.arange(0, BLOCK_W)
    w_mask = w_offsets < W

    # Load block of data
    x_ptrs = x_base + w_offsets * stride_xw
    x_vals = tl.load(x_ptrs, mask=w_mask, other=0.0)

    # Step 1: Mish activation
    # Mish(x) = x * tanh(softplus(x))
    # softplus(x) = log(1 + exp(x))
    # We compute stable version to avoid overflow
    
    # Compute softplus(x) = log(1 + exp(x))
    # For numerical stability: log(1 + exp(x)) = max(x, 0) + log(1 + exp(-|x|))
    abs_x = tl.abs(x_vals)
    max_zero_x = tl.where(x_vals > 0, x_vals, 0.0)
    softplus = max_zero_x + tl.log(1.0 + tl.exp(-abs_x))
    
    # Compute tanh(softplus)
    exp_pos = tl.exp(softplus)
    exp_neg = tl.exp(-softplus)
    tanh_softplus = (exp_pos - exp_neg) / (exp_pos + exp_neg + 1e-8)
    
    # Mish(x) = x * tanh(softplus(x))
    mish_vals = x_vals * tanh_softplus

    # Step 2: Add value
    add_vals = mish_vals + add_value

    # Step 3: Hardtanh activation (clamp to [-1, 1])
    # Hardtanh: min(max(x, -1), 1)
    hardtanh_vals = tl.where(add_vals < -1.0, -1.0, add_vals)
    hardtanh_vals = tl.where(hardtanh_vals > 1.0, 1.0, hardtanh_vals)

    # Step 4: Scale
    scaled_vals = hardtanh_vals * scale

    # Store results
    out_ptrs = out_base + w_offsets * stride_ow
    tl.store(out_ptrs, scaled_vals, mask=w_mask)


@triton.jit
def fused_mish_add_hardtanh_scale_kernel_2d(
    x_ptr,
    out_ptr,
    N, C, H, W,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_on, stride_oc, stride_oh, stride_ow,
    add_value,
    scale,
    BLOCK_C: tl.constexpr,
    BLOCK_HW: tl.constexpr,
):
    """
    Alternative 2D blocking kernel for better memory coalescing
    Input: [N, C, H, W] -> Output: [N, C, H, W]
    Each block processes BLOCK_C channels and BLOCK_HW spatial positions
    FIXED: Now processes all channels by adding channel dimension to grid
    """
    pid_n = tl.program_id(0)
    pid_c_chunk = tl.program_id(1)  # Channel chunk index
    pid_hw_chunk = tl.program_id(2)  # Spatial chunk index

    # Calculate channel offsets for this chunk
    c_offsets = pid_c_chunk * BLOCK_C + tl.arange(0, BLOCK_C)
    
    # Calculate spatial offsets for this chunk
    hw_offsets = pid_hw_chunk * BLOCK_HW + tl.arange(0, BLOCK_HW)
    
    # Compute spatial index safely
    hw_idx = hw_offsets
    valid_hw_mask = hw_idx < (H * W)
    
    # For invalid indices, set to 0 to avoid out-of-bounds memory access
    # The mask will prevent actual loading/storing for these positions
    hw_idx_safe = tl.where(valid_hw_mask, hw_idx, 0)
    
    # Compute h and w indices from the safe flattened index
    h_idx = hw_idx_safe // W
    w_idx = hw_idx_safe % W
    
    # Create masks for both dimensions
    c_mask = c_offsets[:, None] < C
    spatial_mask = valid_hw_mask[None, :]
    
    # Combine masks
    mask = c_mask & spatial_mask

    # Compute pointers for all positions in the block
    x_ptrs = (
        x_ptr + 
        pid_n * stride_xn + 
        c_offsets[:, None] * stride_xc + 
        h_idx[None, :] * stride_xh + 
        w_idx[None, :] * stride_xw
    )
    
    # Load data
    x_vals = tl.load(x_ptrs, mask=mask, other=0.0)

    # Mish activation
    abs_x = tl.abs(x_vals)
    max_zero_x = tl.where(x_vals > 0, x_vals, 0.0)
    softplus = max_zero_x + tl.log(1.0 + tl.exp(-abs_x))
    exp_pos = tl.exp(softplus)
    exp_neg = tl.exp(-softplus)
    tanh_softplus = (exp_pos - exp_neg) / (exp_pos + exp_neg + 1e-8)
    mish_vals = x_vals * tanh_softplus

    # Add value
    add_vals = mish_vals + add_value

    # Hardtanh activation
    hardtanh_vals = tl.where(add_vals < -1.0, -1.0, add_vals)
    hardtanh_vals = tl.where(hardtanh_vals > 1.0, 1.0, hardtanh_vals)

    # Scale
    scaled_vals = hardtanh_vals * scale

    # Store results
    out_ptrs = (
        out_ptr + 
        pid_n * stride_on + 
        c_offsets[:, None] * stride_oc + 
        h_idx[None, :] * stride_oh + 
        w_idx[None, :] * stride_ow
    )
    tl.store(out_ptrs, scaled_vals, mask=mask)


def fused_post_convtranspose(x, add_value, scale, use_2d_kernel=True):
    """
    Fused: Mish + Add + Hardtanh + Scale
    """
    N, C, H, W = x.shape
    out = torch.empty_like(x)
    
    if use_2d_kernel:
        # Use 2D kernel with better memory coalescing
        # FIXED: Add channel dimension to grid to process all channels
        BLOCK_C = 16
        BLOCK_HW = 64
        
        # Calculate number of chunks for both dimensions
        channel_chunks = triton.cdiv(C, BLOCK_C)
        spatial_chunks = triton.cdiv(H * W, BLOCK_HW)
        
        grid = (
            N,  # batch dimension
            channel_chunks,  # channel chunks - FIXED: now processes all channels
            spatial_chunks,  # spatial chunks
        )
        
        fused_mish_add_hardtanh_scale_kernel_2d[grid](
            x, out,
            N, C, H, W,
            x.stride(0), x.stride(1), x.stride(2), x.stride(3),
            out.stride(0), out.stride(1), out.stride(2), out.stride(3),
            add_value, scale,
            BLOCK_C=BLOCK_C,
            BLOCK_HW=BLOCK_HW,
            num_warps=4,
        )
    else:
        # Use 3D kernel for simpler control
        BLOCK_C = min(triton.next_power_of_2(C), 16)
        BLOCK_H = min(triton.next_power_of_2(H), 64)
        BLOCK_W = min(triton.next_power_of_2(W), 64)
        
        grid = (
            N,  # batch dimension
            triton.cdiv(C, BLOCK_C),  # channel dimension
            triton.cdiv(H, BLOCK_H),  # height dimension
        )
        
        fused_mish_add_hardtanh_scale_kernel[grid](
            x, out,
            N, C, H, W,
            x.stride(0), x.stride(1), x.stride(2), x.stride(3),
            out.stride(0), out.stride(1), out.stride(2), out.stride(3),
            add_value, scale,
            BLOCK_C=BLOCK_C,
            BLOCK_H=BLOCK_H,
            BLOCK_W=BLOCK_W,
            num_warps=4,
        )
    
    return out


class ModelNew(nn.Module):
    """
    ConvTranspose2d (PyTorch native) + Fused Mish + Add + Hardtanh + Scale (Triton)
    """
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, add_value, scale):
        super(ModelNew, self).__init__()
        # Keep ConvTranspose as PyTorch native - DO NOT reimplement in Triton
        self.conv_transpose = nn.ConvTranspose2d(
            in_channels, out_channels, kernel_size, 
            stride, padding, output_padding
        )
        self.add_value = add_value
        self.scale = scale
        
    def forward(self, x):
        # Step 1: PyTorch native ConvTranspose2d
        x = self.conv_transpose(x)
        
        # Step 2: Fused post-ops in Triton
        x = fused_post_convtranspose(x, self.add_value, self.scale, use_2d_kernel=True)
        return x
```

[NCU PROFILING METRICS]
{
  "fused_mish_add_hardtanh_scale_kernel_2d": [
    {
      "sm__throughput.avg.pct_of_peak_sustained_elapsed": 13.52,
      "launch__grid_size": 524288,
      "sm__warps_active.avg.pct_of_peak_sustained_active": 89.57,
      "dram__throughput.avg.pct_of_peak_sustained_elapsed": 43.5,
      "lts__t_sector_hit_rate.pct": 78.59
    },
    {
      "sm__throughput.avg.pct_of_peak_sustained_elapsed": 13.52,
      "launch__grid_size": 524288,
      "sm__warps_active.avg.pct_of_peak_sustained_active": 89.57,
      "dram__throughput.avg.pct_of_peak_sustained_elapsed": 43.5,
      "lts__t_sector_hit_rate.pct": 78.59
    }
  ]
}

**Task**: Analyze the NCU metrics and current code, then generate optimized code that maximizes performance.

TRITON API CONSTRAINTS (CRITICAL):
- Triton has NO: tl.tanh, tl.sigmoid, tl.gelu, tl.silu, tl.softmax, tl.mish

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <optimized Triton code>
```
