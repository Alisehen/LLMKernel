{
  "timestamp": "2025-12-15T03:42:28",
  "reference_file": "KernelBench/level2/64_Gemm_LogSumExp_LeakyReLU_LeakyReLU_GELU_GELU.py",
  "candidate_file": "/home/hyc/LLMKernel/run/20251215_024837_batch_range56to88_openai_deepseek/64_Gemm_LogSumExp_LeakyReLU_LeakyReLU_GELU_GELU/code/kernel_20251215_034222.py",
  "tolerance": 0.001,
  "max_abs_err": 0.010959625244140625,
  "mean_abs_err": 0.010069223120808601,
  "ref_latency_ms": {
    "avg": 3.2493632316589354,
    "min": 3.2389121055603027,
    "max": 3.264512062072754,
    "all": [
      3.264512062072754,
      3.251199960708618,
      3.2389121055603027,
      3.247040033340454,
      3.245151996612549
    ]
  },
  "test_latency_ms": {
    "avg": 3.87423357963562,
    "min": 3.6280319690704346,
    "max": 3.945631980895996,
    "all": [
      3.945631980895996,
      3.9383039474487305,
      3.940351963043213,
      3.9188480377197266,
      3.6280319690704346
    ]
  },
  "num_runs": 5,
  "model_init_args": [
    8192,
    8192
  ],
  "model_init_kwargs": {},
  "seed": 100,
  "align_stats": {
    "copied_same_shape": 0,
    "unique_shape_copied": 2,
    "mapped_shape": 0,
    "skipped": 0,
    "pair_aligner": 0,
    "pair_key": "Model->ModelNew"
  },
  "runnable": true,
  "phase": "stage1_repair",
  "pytorch_baseline_ms": 3.2409472465515137,
  "score": 0.8365389385882953
}