{
  "timestamp": "2025-12-15T03:44:09",
  "reference_file": "KernelBench/level2/64_Gemm_LogSumExp_LeakyReLU_LeakyReLU_GELU_GELU.py",
  "candidate_file": "/home/hyc/LLMKernel/run/20251215_024837_batch_range56to88_openai_deepseek/64_Gemm_LogSumExp_LeakyReLU_LeakyReLU_GELU_GELU/code/kernel_20251215_034403.py",
  "tolerance": 0.001,
  "max_abs_err": 0.010959625244140625,
  "mean_abs_err": 0.010069220326840878,
  "ref_latency_ms": {
    "avg": 3.291699171066284,
    "min": 3.2829439640045166,
    "max": 3.321727991104126,
    "all": [
      3.321727991104126,
      3.286911964416504,
      3.2829439640045166,
      3.2829439640045166,
      3.283967971801758
    ]
  },
  "test_latency_ms": {
    "avg": 3.935795211791992,
    "min": 3.872767925262451,
    "max": 3.9587841033935547,
    "all": [
      3.9587841033935547,
      3.951616048812866,
      3.9485440254211426,
      3.9472639560699463,
      3.872767925262451
    ]
  },
  "num_runs": 5,
  "model_init_args": [
    8192,
    8192
  ],
  "model_init_kwargs": {},
  "seed": 100,
  "align_stats": {
    "copied_same_shape": 0,
    "unique_shape_copied": 2,
    "mapped_shape": 0,
    "skipped": 0,
    "pair_aligner": 0,
    "pair_key": "Model->ModelNew"
  },
  "runnable": true,
  "phase": "stage2_repair",
  "pytorch_baseline_ms": 3.2409472465515137,
  "score": 0.8234542378732886
}