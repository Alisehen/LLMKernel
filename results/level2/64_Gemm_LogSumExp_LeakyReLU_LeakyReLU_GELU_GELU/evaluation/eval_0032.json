{
  "timestamp": "2025-12-15T03:40:36",
  "reference_file": "KernelBench/level2/64_Gemm_LogSumExp_LeakyReLU_LeakyReLU_GELU_GELU.py",
  "candidate_file": "/home/hyc/LLMKernel/run/20251215_024837_batch_range56to88_openai_deepseek/64_Gemm_LogSumExp_LeakyReLU_LeakyReLU_GELU_GELU/code/kernel_20251215_034030.py",
  "tolerance": 0.001,
  "max_abs_err": 0.010959625244140625,
  "mean_abs_err": 0.010069223120808601,
  "ref_latency_ms": {
    "avg": 3.2409472465515137,
    "min": 3.2317440509796143,
    "max": 3.259200096130371,
    "all": [
      3.259200096130371,
      3.2327680587768555,
      3.2359681129455566,
      3.2317440509796143,
      3.245055913925171
    ]
  },
  "test_latency_ms": {
    "avg": 3.5209792137145994,
    "min": 3.5146560668945312,
    "max": 3.533888101577759,
    "all": [
      3.5146560668945312,
      3.5153920650482178,
      3.533888101577759,
      3.518399953842163,
      3.522559881210327
    ]
  },
  "num_runs": 5,
  "model_init_args": [
    8192,
    8192
  ],
  "model_init_kwargs": {},
  "seed": 100,
  "align_stats": {
    "copied_same_shape": 0,
    "unique_shape_copied": 2,
    "mapped_shape": 0,
    "skipped": 0,
    "pair_aligner": 0,
    "pair_key": "Model->ModelNew"
  },
  "runnable": true,
  "phase": "seed_repair",
  "score": 0.9204675886547894
}