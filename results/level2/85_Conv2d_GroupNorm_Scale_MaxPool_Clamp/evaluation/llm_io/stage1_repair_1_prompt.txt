Fix the Triton kernel errors. Generate correct, high-performance code.

Current Error Log:
Traceback (most recent call last):
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 538, in compare_and_bench
    test_out, _ = _run_once(test_model, inp, dev)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 132, in _run_once
    out = model(*inp)
          ^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/run/20251215_024837_batch_range56to88_openai_deepseek/85_Conv2d_GroupNorm_Scale_MaxPool_Clamp/code/kernel_20251215_044904.py", line 445, in forward
    x = conv2d_triton(x, self.weight, self.bias)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/run/20251215_024837_batch_range56to88_openai_deepseek/85_Conv2d_GroupNorm_Scale_MaxPool_Clamp/code/kernel_20251215_044904.py", line 143, in conv2d_triton
    conv2d_nchw_kernel[grid](
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 347, in <lambda>
    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/autotuner.py", line 192, in run
    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/autotuner.py", line 192, in <dictcomp>
    timings = {config: self._bench(*args, config=config, **kwargs) for config in pruned_configs}
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/autotuner.py", line 170, in _bench
    return self.do_bench(kernel_call, quantiles=(0.5, 0.2, 0.8))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/testing.py", line 145, in do_bench
    fn()
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/autotuner.py", line 156, in kernel_call
    self.fn.run(
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 537, in run
    bound_args, specialization, options = binder(*args, **kwargs)
                                          ^^^^^^^^^^^^^^^^^^^^^^^
TypeError: dynamic_func() got multiple values for argument 'N'

Main Critical Problem Analysis:
Problem Analysis (from expert diagnosis):
critical_issue: conv2d_nchw_kernel is called with argument 'N' both positionally and as keyword (N=N), causing duplicate binding.
why_it_matters: Triton’s JIT binder sees two values for parameter 'N' in dynamic_func, raising TypeError: dynamic_func() got multiple values for argument 'N'.
minimal_fix_hint: Remove the keyword arguments N=..., C_in=..., C_out=..., H_out=..., W_out=... from the conv2d_nchw_kernel launch.

Focus your fix on addressing the identified critical issue.


Broken Code:
```python
# <optimized Triton code>

import torch
import torch.nn as nn
import triton
import triton.language as tl
import math


# -----------------------------
# 1. Optimized Conv2d (NCHW)
#    stride=1, padding=0, dilation=1
#    Grid: 2D over (P = N*H_out*W_out, C_out)
#    Fused bias-add uses same (offs_m, offs_n, mask_m, mask_n)
# -----------------------------

@triton.autotune(
    configs=[
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 32}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64}, num_warps=4, num_stages=2),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64}, num_warps=8, num_stages=2),
    ],
    key=['N', 'C_in', 'C_out', 'H_out', 'W_out'],
)
@triton.jit
def conv2d_nchw_kernel(
    x_ptr, w_ptr, b_ptr, y_ptr,
    N, C_in, H_in, W_in,
    C_out, K_H, K_W,
    H_out, W_out,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_wo, stride_wi, stride_wkh, stride_wkw,
    stride_yn, stride_yc, stride_yh, stride_yw,
    # meta-parameters
    BLOCK_M: tl.constexpr,  # over P = N * H_out * W_out
    BLOCK_N: tl.constexpr,  # over C_out
):
    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)

    P = N * H_out * W_out
    HW_out = H_out * W_out

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    mask_m = offs_m < P
    mask_n = offs_n < C_out

    # Decode flattened output index -> (n, oh, ow)
    n_idx = offs_m // HW_out
    rem = offs_m % HW_out
    oh_idx = rem // W_out
    ow_idx = rem % W_out

    # Accumulator in FP32
    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    # We assume: stride=1, padding=0, dilation=1
    # => all (oh_idx + kh, ow_idx + kw) are in-bounds for offsm < P
    # So the only necessary masks are mask_m / mask_n (for tail blocks).

    # Loop order is (kh, kw, ic) to reduce pointer arithmetic
    for kh in range(0, K_H):
        h_in = oh_idx + kh
        x_base_kh = (
            n_idx * stride_xn
            + h_in * stride_xh
            + ow_idx * stride_xw
        )  # [BLOCK_M]
        w_base_kh = (
            offs_n * stride_wo
            + kh * stride_wkh
        )  # [BLOCK_N]
        for kw in range(0, K_W):
            w_base_hw = w_base_kh + kw * stride_wkw  # [BLOCK_N]
            x_base_hw = x_base_kh + kw * stride_xw   # [BLOCK_M]

            # Initialize per-(kh, kw) pointers at ic=0, then walk channels with +stride_xc / +stride_wi
            x_ptrs = x_base_hw
            w_ptrs = w_base_hw

            # ic loop is dynamic; use simple range
            for ic in range(0, C_in):
                x_vals = tl.load(x_ptrs, mask=mask_m, other=0.0).to(tl.float32)  # [BLOCK_M]
                w_vals = tl.load(w_ptrs, mask=mask_n, other=0.0).to(tl.float32)  # [BLOCK_N]

                acc += x_vals[:, None] * w_vals[None, :]

                x_ptrs += stride_xc
                w_ptrs += stride_wi

    # Fused bias add (same offs_n / mask_n)
    b_vals = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0).to(tl.float32)
    acc += b_vals[None, :]

    # Store output (same offsets/masks as main conv)
    y_ptrs = y_ptr + (
        n_idx[:, None] * stride_yn
        + offs_n[None, :] * stride_yc
        + oh_idx[:, None] * stride_yh
        + ow_idx[:, None] * stride_yw
    )
    tl.store(y_ptrs, acc, mask=mask_m[:, None] & mask_n[None, :])


def conv2d_triton(x, weight, bias):
    """
    NCHW conv2d with stride=1, padding=0, dilation=1 implemented in Triton.
    Args:
        x:      (N, C_in, H_in, W_in)
        weight: (C_out, C_in, K_H, K_W)
        bias:   (C_out,)
    Returns:
        y: (N, C_out, H_out, W_out)
    """
    assert x.ndim == 4 and weight.ndim == 4
    N, C_in, H_in, W_in = x.shape
    C_out, C_in_w, K_H, K_W = weight.shape
    assert C_in == C_in_w, "Input channels mismatch between x and weight"

    # Valid conv (no padding)
    H_out = H_in - K_H + 1
    W_out = W_in - K_W + 1
    assert H_out > 0 and W_out > 0, "Invalid conv output size"

    x_contig = x.contiguous()
    w_contig = weight.contiguous()
    if bias is None:
        b_contig = torch.zeros(C_out, device=x.device, dtype=x.dtype)
    else:
        b_contig = bias.contiguous()

    y = torch.empty((N, C_out, H_out, W_out), device=x.device, dtype=x.dtype)

    def grid(meta):
        return (
            triton.cdiv(N * H_out * W_out, meta["BLOCK_M"]),
            triton.cdiv(C_out, meta["BLOCK_N"]),
        )

    conv2d_nchw_kernel[grid](
        x_contig, w_contig, b_contig, y,
        N, C_in, H_in, W_in,
        C_out, K_H, K_W,
        H_out, W_out,
        x_contig.stride(0), x_contig.stride(1), x_contig.stride(2), x_contig.stride(3),
        w_contig.stride(0), w_contig.stride(1), w_contig.stride(2), w_contig.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        N=N, C_in=C_in, C_out=C_out, H_out=H_out, W_out=W_out,
    )
    return y


# -----------------------------
# 2. Optimized GroupNorm + per-channel scale
#    Grid: 1D over (N * num_groups)
#    Two-pass Welford-like reduction; memory-bound
#    Fused scale in host to cut one global load
# -----------------------------

@triton.jit
def groupnorm_scale_kernel(
    x_ptr, gamma_ptr, beta_ptr, y_ptr,
    N, C, H, W,
    num_groups, group_size,
    HW, group_elems,
    eps,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_yn, stride_yc, stride_yh, stride_yw,
    BLOCK: tl.constexpr,
):
    pid = tl.program_id(0)  # over N * num_groups
    n = pid // num_groups
    g = pid % num_groups

    # This kernel is launched with grid = N * num_groups
    # => n is always < N, so no need for additional valid_group mask.
    c0 = g * group_size

    mean = tl.zeros((), dtype=tl.float32)
    m2 = tl.zeros((), dtype=tl.float32)

    # First pass: compute mean and variance for this (n, group)
    offs_base = tl.arange(0, BLOCK)
    for offset in range(0, group_elems, BLOCK):
        offs = offset + offs_base
        mask = offs < group_elems

        c_off = offs // HW
        rem = offs % HW
        h = rem // W
        w = rem % W
        c = c0 + c_off

        x_ptrs = x_ptr + (
            n * stride_xn
            + c * stride_xc
            + h * stride_xh
            + w * stride_xw
        )
        vals = tl.load(x_ptrs, mask=mask, other=0.0).to(tl.float32)

        block_sum = tl.sum(vals, axis=0)
        block_sumsq = tl.sum(vals * vals, axis=0)
        mean += block_sum
        m2 += block_sumsq

    L_f = tl.full((), group_elems, dtype=tl.float32)
    mean = mean / L_f
    var = m2 / L_f - mean * mean
    inv_std = 1.0 / tl.sqrt(var + eps)

    # Second pass: normalize + affine (GroupNorm) + fused extra scale (pre-applied on host)
    for offset in range(0, group_elems, BLOCK):
        offs = offset + offs_base
        mask = offs < group_elems

        c_off = offs // HW
        rem = offs % HW
        h = rem // W
        w = rem % W
        c = c0 + c_off

        x_ptrs = x_ptr + (
            n * stride_xn
            + c * stride_xc
            + h * stride_xh
            + w * stride_xw
        )
        vals = tl.load(x_ptrs, mask=mask, other=0.0).to(tl.float32)

        gamma = tl.load(gamma_ptr + c, mask=mask, other=1.0).to(tl.float32)
        beta = tl.load(beta_ptr + c, mask=mask, other=0.0).to(tl.float32)

        norm = (vals - mean) * inv_std
        y_vals = norm * gamma + beta

        y_ptrs = y_ptr + (
            n * stride_yn
            + c * stride_yc
            + h * stride_yh
            + w * stride_yw
        )
        tl.store(y_ptrs, y_vals, mask=mask)


def groupnorm_scale_triton(x, num_groups, weight, bias, scale, eps=1e-5):
    """
    GroupNorm followed by channel-wise scale in Triton.

    Args:
        x:         (N, C, H, W)
        num_groups: int
        weight:    (C,)  GroupNorm gamma
        bias:      (C,)  GroupNorm beta
        scale:     (C, 1, 1) or broadcastable to (C, H, W)
    """
    assert x.ndim == 4
    N, C, H, W = x.shape
    assert C % num_groups == 0
    group_size = C // num_groups
    HW = H * W
    group_elems = group_size * HW

    x_contig = x.contiguous()
    gamma = weight.contiguous().view(C)
    beta = bias.contiguous().view(C)
    scale_flat = scale.contiguous().view(C)

    # Fuse extra per-channel scale into gamma on host side
    gamma_eff = gamma * scale_flat

    y = torch.empty_like(x_contig)

    def grid(meta):
        return (N * num_groups,)

    groupnorm_scale_kernel[grid](
        x_contig, gamma_eff, beta, y,
        N, C, H, W,
        num_groups, group_size,
        HW, group_elems,
        eps,
        x_contig.stride(0), x_contig.stride(1), x_contig.stride(2), x_contig.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        BLOCK=256,  # larger block for better memory coalescing
    )
    return y


# -----------------------------
# 3. Optimized MaxPool2d + clamp
#    Grid: 2D over (P = N*H_out*W_out, C)
#    No padding -> no H/W boundary checks inside kernel
#    Fused clamp uses same (offs_m, offs_n, mask_m, mask_n)
# -----------------------------

@triton.jit
def maxpool_clamp_kernel(
    x_ptr, y_ptr,
    N, C, H, W,
    H_out, W_out,
    K, stride_hw,
    clamp_min, clamp_max,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_yn, stride_yc, stride_yh, stride_yw,
    BLOCK_M: tl.constexpr,  # over P = N * H_out * W_out
    BLOCK_N: tl.constexpr,  # over C
):
    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)

    P = N * H_out * W_out
    HW_out = H_out * W_out

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    mask_m = offs_m < P
    mask_n = offs_n < C

    n_idx = offs_m // HW_out
    rem = offs_m % HW_out
    oh_idx = rem // W_out
    ow_idx = rem % W_out

    # Initialize accumulator with -inf
    acc = tl.full((BLOCK_M, BLOCK_N), -float("inf"), dtype=tl.float32)

    # For stride/padding configuration used here:
    #   H_out = (H - K) // stride + 1
    #   W_out = (W - K) // stride + 1
    # So all windows are strictly in-bounds and we do not need per-window H/W masks.
    for kh in range(0, K):
        h_in = oh_idx * stride_hw + kh
        for kw in range(0, K):
            w_in = ow_idx * stride_hw + kw

            x_ptrs = x_ptr + (
                n_idx[:, None] * stride_xn
                + offs_n[None, :] * stride_xc
                + h_in[:, None] * stride_xh
                + w_in[:, None] * stride_xw
            )

            mask = mask_m[:, None] & mask_n[None, :]
            vals = tl.load(x_ptrs, mask=mask, other=-float("inf")).to(tl.float32)
            acc = tl.maximum(acc, vals)

    # Fused clamp (same mask as output)
    acc = tl.maximum(acc, clamp_min)
    acc = tl.minimum(acc, clamp_max)

    y_ptrs = y_ptr + (
        n_idx[:, None] * stride_yn
        + offs_n[None, :] * stride_yc
        + oh_idx[:, None] * stride_yh
        + ow_idx[:, None] * stride_yw
    )
    tl.store(y_ptrs, acc, mask=mask_m[:, None] & mask_n[None, :])


def maxpool_clamp_triton(x, kernel_size, clamp_min, clamp_max, stride=None):
    """
    MaxPool2d with kernel_size and stride (default stride=kernel_size) followed by clamp.
    Args:
        x: (N, C, H, W)
    """
    if stride is None:
        stride = kernel_size

    assert x.ndim == 4
    N, C, H, W = x.shape

    H_out = (H - kernel_size) // stride + 1
    W_out = (W - kernel_size) // stride + 1
    assert H_out > 0 and W_out > 0

    x_contig = x.contiguous()
    y = torch.empty((N, C, H_out, W_out), device=x.device, dtype=x.dtype)

    def grid(meta):
        return (
            triton.cdiv(N * H_out * W_out, meta["BLOCK_M"]),
            triton.cdiv(C, meta["BLOCK_N"]),
        )

    maxpool_clamp_kernel[grid](
        x_contig, y,
        N, C, H, W,
        H_out, W_out,
        kernel_size, stride,
        clamp_min, clamp_max,
        x_contig.stride(0), x_contig.stride(1), x_contig.stride(2), x_contig.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        BLOCK_M=64, BLOCK_N=32,
    )
    return y


# -----------------------------
# 4. ModelNew: Conv2d -> GroupNorm+scale -> MaxPool2d+clamp
# -----------------------------

class ModelNew(nn.Module):
    """
    Triton-based implementation of:
      Conv2d -> GroupNorm -> per-channel scale -> MaxPool2d -> clamp
    """

    def __init__(self, in_channels, out_channels, kernel_size,
                 num_groups, scale_shape, maxpool_kernel_size,
                 clamp_min, clamp_max):
        super(ModelNew, self).__init__()
        # Conv parameters
        self.weight = nn.Parameter(
            torch.empty(out_channels, in_channels, kernel_size, kernel_size)
        )
        self.bias = nn.Parameter(torch.zeros(out_channels))

        # Match PyTorch Conv2d default initialization
        if in_channels > 0:
            nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        fan_in = in_channels * kernel_size * kernel_size
        bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0
        nn.init.uniform_(self.bias, -bound, bound)

        # GroupNorm parameters
        self.num_groups = num_groups
        self.group_norm_weight = nn.Parameter(torch.ones(out_channels))
        self.group_norm_bias = nn.Parameter(torch.zeros(out_channels))

        # Extra per-channel scale
        self.scale = nn.Parameter(torch.ones(scale_shape))

        # MaxPool and clamp params
        self.maxpool_kernel_size = maxpool_kernel_size
        self.clamp_min = clamp_min
        self.clamp_max = clamp_max

    def forward(self, x):
        # Conv2d
        x = conv2d_triton(x, self.weight, self.bias)
        # GroupNorm + extra scale (fused in kernel/host)
        x = groupnorm_scale_triton(
            x,
            self.num_groups,
            self.group_norm_weight,
            self.group_norm_bias,
            self.scale,
            eps=1e-5,
        )
        # MaxPool + clamp
        x = maxpool_clamp_triton(
            x,
            self.maxpool_kernel_size,
            self.clamp_min,
            self.clamp_max,
            stride=self.maxpool_kernel_size,
        )
        return x
```

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl, AND any other modules used (e.g., import math if using math.sqrt)
   2. @triton.jit decorated kernel function(s) — NO continue/break/return inside loops (use masking)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels — THIS CLASS IS REQUIRED
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs
3. Learn from previous repair attempts to avoid repeating the same mistakes
4. Ensure ALL imports are included at the top (common mistake: forgetting `import math`)

```python
# <corrected code>
```
