You are a GPU kernel optimization architect. Analyze the kernel and identify **ONE high-level algorithmic optimization**.

# PyTorch Reference
```python
import torch
import torch.nn as nn

class Model(nn.Module):
    """
    Model that performs convolution, group normalization, scaling, max pooling, and clamping.
    """
    def __init__(self, in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max):
        super(Model, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.group_norm = nn.GroupNorm(num_groups, out_channels)
        self.scale = nn.Parameter(torch.ones(scale_shape))
        self.maxpool = nn.MaxPool2d(kernel_size=maxpool_kernel_size)
        self.clamp_min = clamp_min
        self.clamp_max = clamp_max

    def forward(self, x):
        """
        Args:
            x: Input tensor of shape (batch_size, in_channels, height, width).
        Returns:
            Output tensor of shape (batch_size, out_channels, height', width').
        """
        x = self.conv(x)
        x = self.group_norm(x)
        x = x * self.scale
        x = self.maxpool(x)
        x = torch.clamp(x, self.clamp_min, self.clamp_max)
        return x

batch_size = 128
in_channels = 8
out_channels = 64
height, width = 128, 128 
kernel_size = 3
num_groups = 16
scale_shape = (out_channels, 1, 1)
maxpool_kernel_size = 4
clamp_min = 0.0
clamp_max = 1.0

def get_inputs():
    return [torch.rand(batch_size, in_channels, height, width)]

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, num_groups, scale_shape, maxpool_kernel_size, clamp_min, clamp_max]
```

# Current Triton Kernel
```python
# <complete ModelNew code with optimized Triton kernels>
import torch
import torch.nn as nn
import triton
import triton.language as tl


# ---------------------------------------------------------------------------
# 2D Convolution kernel (NCHW, no padding, stride=1, dilation=1, groups=1)
# ---------------------------------------------------------------------------

@triton.jit
def conv2d_forward_kernel(
    x_ptr, w_ptr, b_ptr, y_ptr,
    N, C_in, H, W,
    OC, K, H_out, W_out,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_wn, stride_wc, stride_wh, stride_ww,
    stride_yn, stride_yc, stride_yh, stride_yw,
    BLOCK_OC: tl.constexpr, BLOCK_W: tl.constexpr,
):
    pid_nh = tl.program_id(0)
    pid_oc = tl.program_id(1)
    pid_w = tl.program_id(2)

    offs_oc = pid_oc * BLOCK_OC + tl.arange(0, BLOCK_OC)
    offs_w = pid_w * BLOCK_W + tl.arange(0, BLOCK_W)

    oc_mask = offs_oc < OC
    w_mask = offs_w < W_out

    # Decode (n, h_out) from pid_nh
    n = pid_nh // H_out
    h_out = pid_nh - n * H_out

    acc = tl.zeros((BLOCK_OC, BLOCK_W), dtype=tl.float32)

    # Convolution over input channels and kernel spatial dims
    for c in range(0, C_in):
        for kh in range(0, K):
            h_in = h_out + kh
            x_base = x_ptr + n * stride_xn + c * stride_xc + h_in * stride_xh
            for kw in range(0, K):
                w_in = offs_w + kw
                x_ptrs = x_base + w_in * stride_xw
                x = tl.load(x_ptrs, mask=w_mask, other=0.0).to(tl.float32)

                w_base = (
                    w_ptr
                    + offs_oc * stride_wn
                    + c * stride_wc
                    + kh * stride_wh
                    + kw * stride_ww
                )
                w = tl.load(w_base, mask=oc_mask, other=0.0).to(tl.float32)

                acc += w[:, None] * x[None, :]

    # Add bias
    b = tl.load(b_ptr + offs_oc, mask=oc_mask, other=0.0).to(tl.float32)
    acc += b[:, None]

    y_ptrs = (
        y_ptr
        + n * stride_yn
        + offs_oc[:, None] * stride_yc
        + h_out * stride_yh
        + offs_w[None, :] * stride_yw
    )
    tl.store(y_ptrs, acc.to(tl.float32), mask=oc_mask[:, None] & w_mask[None, :])


def conv2d_triton(x, weight, bias):
    """
    x: (N, C_in, H, W)
    weight: (OC, C_in, K, K)
    bias: (OC,)
    No padding, stride=1, dilation=1, groups=1.
    """
    x = x.contiguous()
    weight = weight.contiguous()
    bias = bias.contiguous()

    N, C_in, H, W = x.shape
    OC, C_w, K, K_w = weight.shape
    assert C_w == C_in
    assert K == K_w  # square kernel

    H_out = H - K + 1
    W_out = W - K + 1

    y = torch.empty((N, OC, H_out, W_out), device=x.device, dtype=x.dtype)

    stride_xn, stride_xc, stride_xh, stride_xw = x.stride()
    stride_wn, stride_wc, stride_wh, stride_ww = weight.stride()
    stride_yn, stride_yc, stride_yh, stride_yw = y.stride()

    BLOCK_OC = 32
    BLOCK_W = 64

    grid = lambda META: (
        N * H_out,
        triton.cdiv(OC, META["BLOCK_OC"]),
        triton.cdiv(W_out, META["BLOCK_W"]),
    )

    conv2d_forward_kernel[grid](
        x, weight, bias, y,
        N, C_in, H, W,
        OC, K, H_out, W_out,
        stride_xn, stride_xc, stride_xh, stride_xw,
        stride_wn, stride_wc, stride_wh, stride_ww,
        stride_yn, stride_yc, stride_yh, stride_yw,
        BLOCK_OC=BLOCK_OC,
        BLOCK_W=BLOCK_W,
        num_warps=4,
        num_stages=2,
    )
    return y


# ---------------------------------------------------------------------------
# GroupNorm + scale kernel
#   GroupNorm(num_groups, C) with affine (gamma, beta), then multiply by scale
#   y = ((x - mean) / sqrt(var + eps) * gamma + beta) * scale
# ---------------------------------------------------------------------------

@triton.jit
def groupnorm_scale_kernel(
    x_ptr, gamma_ptr, beta_ptr, scale_ptr, y_ptr,
    N, C, H, W,
    num_groups, group_size,
    eps,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_yn, stride_yc, stride_yh, stride_yw,
    stride_scale_c,
    BLOCK_SIZE: tl.constexpr,
):
    pid = tl.program_id(0)
    offs = tl.arange(0, BLOCK_SIZE)

    n = pid // num_groups
    g = pid - n * num_groups

    S = group_size * H * W  # elements per group (scalar Tensor)
    S_f = S.to(tl.float32)

    # First pass: compute mean and variance
    sum_val = tl.zeros((), dtype=tl.float32)
    sum_sq = tl.zeros((), dtype=tl.float32)

    for offset in range(0, S, BLOCK_SIZE):
        idx = offset + offs
        mask = idx < S

        c_local = idx // (H * W)
        hw = idx - c_local * (H * W)
        h = hw // W
        w = hw - h * W

        c_global = g * group_size + c_local

        x_ptrs = (
            x_ptr
            + n * stride_xn
            + c_global * stride_xc
            + h * stride_xh
            + w * stride_xw
        )
        x = tl.load(x_ptrs, mask=mask, other=0.0).to(tl.float32)

        sum_val += tl.sum(x, axis=0)
        sum_sq += tl.sum(x * x, axis=0)

    mean = sum_val / S_f
    var = sum_sq / S_f - mean * mean
    rstd = 1.0 / tl.sqrt(var + eps)

    # Second pass: normalize, apply affine (gamma, beta), then scale
    for offset in range(0, S, BLOCK_SIZE):
        idx = offset + offs
        mask = idx < S

        c_local = idx // (H * W)
        hw = idx - c_local * (H * W)
        h = hw // W
        w = hw - h * W

        c_global = g * group_size + c_local

        x_ptrs = (
            x_ptr
            + n * stride_xn
            + c_global * stride_xc
            + h * stride_xh
            + w * stride_xw
        )
        x = tl.load(x_ptrs, mask=mask, other=0.0).to(tl.float32)

        gamma = tl.load(gamma_ptr + c_global, mask=c_global < C, other=1.0).to(tl.float32)
        beta = tl.load(beta_ptr + c_global, mask=c_global < C, other=0.0).to(tl.float32)
        scale = tl.load(
            scale_ptr + c_global * stride_scale_c,
            mask=c_global < C,
            other=1.0,
        ).to(tl.float32)

        x_hat = (x - mean) * rstd
        y = x_hat * gamma * scale + beta * scale

        y_ptrs = (
            y_ptr
            + n * stride_yn
            + c_global * stride_yc
            + h * stride_yh
            + w * stride_yw
        )
        tl.store(y_ptrs, y, mask=mask)


def groupnorm_scale_triton(x, num_groups, weight, bias, scale, eps=1e-5):
    """
    x: (N, C, H, W)
    weight: (C,) - GroupNorm gamma
    bias: (C,)   - GroupNorm beta
    scale: (C, 1, 1) or (C,) - per-channel scaling after GroupNorm
    """
    x = x.contiguous()
    weight = weight.contiguous()
    bias = bias.contiguous()
    scale = scale.contiguous().view(-1)

    N, C, H, W = x.shape
    assert C % num_groups == 0
    group_size = C // num_groups

    y = torch.empty_like(x)

    stride_xn, stride_xc, stride_xh, stride_xw = x.stride()
    stride_yn, stride_yc, stride_yh, stride_yw = y.stride()

    stride_scale_c = scale.stride(0)

    BLOCK_SIZE = 256
    grid = lambda META: (N * num_groups,)

    groupnorm_scale_kernel[grid](
        x, weight, bias, scale, y,
        N, C, H, W,
        num_groups, group_size,
        eps,
        stride_xn, stride_xc, stride_xh, stride_xw,
        stride_yn, stride_yc, stride_yh, stride_yw,
        stride_scale_c,
        BLOCK_SIZE=BLOCK_SIZE,
        num_warps=4,
        num_stages=2,
    )
    return y


# ---------------------------------------------------------------------------
# MaxPool2d + clamp kernel
#   MaxPool2d(kernel_size=Kp, stride=stride, padding=0), then clamp
# ---------------------------------------------------------------------------

@triton.jit
def maxpool_clamp_kernel(
    x_ptr, y_ptr,
    N, C, H_in, W_in,
    H_out, W_out,
    kernel_size, stride,
    clamp_min, clamp_max,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_yn, stride_yc, stride_yh, stride_yw,
    BLOCK_W: tl.constexpr,
):
    pid_nch = tl.program_id(0)
    pid_w = tl.program_id(1)

    offs_w = pid_w * BLOCK_W + tl.arange(0, BLOCK_W)
    w_out_mask = offs_w < W_out

    # Decode (n, c, h_out) from pid_nch
    nch = C * H_out
    n = pid_nch // nch
    rem = pid_nch - n * nch
    c = rem // H_out
    h_out = rem - c * H_out

    h_start = h_out * stride
    w_start = offs_w * stride

    # Initialize max with very low value
    neg_inf = tl.full((BLOCK_W,), -1.0e30, dtype=tl.float32)
    max_val = neg_inf

    for kh in range(0, kernel_size):
        h_in = h_start + kh
        h_mask = h_in < H_in
        for kw in range(0, kernel_size):
            w_in = w_start + kw
            in_bounds = w_in < W_in
            mask = w_out_mask & h_mask & in_bounds

            x_ptrs = (
                x_ptr
                + n * stride_xn
                + c * stride_xc
                + h_in * stride_xh
                + w_in * stride_xw
            )
            x = tl.load(x_ptrs, mask=mask, other=-1.0e30).to(tl.float32)
            max_val = tl.maximum(max_val, x)

    # Clamp
    max_val = tl.minimum(tl.maximum(max_val, clamp_min), clamp_max)

    y_ptrs = (
        y_ptr
        + n * stride_yn
        + c * stride_yc
        + h_out * stride_yh
        + offs_w * stride_yw
    )
    tl.store(y_ptrs, max_val, mask=w_out_mask)


def maxpool_clamp_triton(x, kernel_size, clamp_min, clamp_max, stride=None):
    """
    x: (N, C, H_in, W_in)
    MaxPool2d(kernel_size=kernel_size, stride=stride or kernel_size, padding=0),
    then clamp to [clamp_min, clamp_max].
    """
    x = x.contiguous()
    if stride is None:
        stride = kernel_size

    N, C, H_in, W_in = x.shape

    H_out = (H_in - kernel_size) // stride + 1
    W_out = (W_in - kernel_size) // stride + 1

    y = torch.empty((N, C, H_out, W_out), device=x.device, dtype=x.dtype)

    stride_xn, stride_xc, stride_xh, stride_xw = x.stride()
    stride_yn, stride_yc, stride_yh, stride_yw = y.stride()

    BLOCK_W = 64
    grid = lambda META: (
        N * C * H_out,
        triton.cdiv(W_out, META["BLOCK_W"]),
    )

    maxpool_clamp_kernel[grid](
        x, y,
        N, C, H_in, W_in,
        H_out, W_out,
        kernel_size, stride,
        clamp_min, clamp_max,
        stride_xn, stride_xc, stride_xh, stride_xw,
        stride_yn, stride_yc, stride_yh, stride_yw,
        BLOCK_W=BLOCK_W,
        num_warps=4,
        num_stages=2,
    )
    return y


# ---------------------------------------------------------------------------
# Model using Triton kernels
# ---------------------------------------------------------------------------

class ModelNew(nn.Module):
    """
    Model that performs:
      - 2D convolution (no padding, stride=1)
      - Group Normalization (with affine)
      - Per-channel scaling
      - Max pooling
      - Clamping
    All heavy ops are implemented with Triton kernels.
    """
    def __init__(
        self,
        in_channels,
        out_channels,
        kernel_size,
        num_groups,
        scale_shape,
        maxpool_kernel_size,
        clamp_min,
        clamp_max,
    ):
        super(ModelNew, self).__init__()
        # Conv parameters
        self.weight = nn.Parameter(
            torch.randn(out_channels, in_channels, kernel_size, kernel_size)
        )
        self.bias = nn.Parameter(torch.randn(out_channels))

        # GroupNorm parameters (affine)
        self.num_groups = num_groups
        self.gn_weight = nn.Parameter(torch.ones(out_channels))
        self.gn_bias = nn.Parameter(torch.zeros(out_channels))

        # Per-channel scale applied after GroupNorm
        self.scale = nn.Parameter(torch.ones(scale_shape))

        # MaxPool and clamp hyperparameters
        self.maxpool_kernel_size = maxpool_kernel_size
        self.clamp_min = clamp_min
        self.clamp_max = clamp_max

    def forward(self, x):
        # Conv2d
        x = conv2d_triton(x, self.weight, self.bias)
        # GroupNorm + scale
        x = groupnorm_scale_triton(
            x,
            self.num_groups,
            self.gn_weight,
            self.gn_bias,
            self.scale,
            eps=1e-5,
        )
        # MaxPool + clamp
        x = maxpool_clamp_triton(
            x,
            self.maxpool_kernel_size,
            self.clamp_min,
            self.clamp_max,
        )
        return x
```

# NCU Metrics
{
  "conv2d_forward_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 66.21,
    "launch__grid_size": 64512,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 32.83,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 20.36,
    "lts__t_sector_hit_rate.pct": 86.35
  },
  "groupnorm_scale_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 28.62,
    "launch__grid_size": 2048,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 87.8,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 75.58,
    "lts__t_sector_hit_rate.pct": 33.4
  },
  "maxpool_clamp_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 60.24,
    "launch__grid_size": 253952,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 90.94,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 94.29,
    "lts__t_sector_hit_rate.pct": 7.64
  }
}


---

## Analysis Steps

1. **Code Analysis**: Count kernels, identify operations, check for inefficiencies
2. **Performance Diagnosis**: Use metrics/latency to identify bottleneck type
3. **Root Cause**: Combine code + performance to find the core issue

## Optimization Categories (pick ONE if worth optimizing):

### 1. Operator Fusion
Fuse consecutive ops into fewer kernels to reduce memory traffic and launch overhead.

### 2. Algorithm Replacement
Replace naive algorithm with optimized variant.
- For Attention: Flash Attention, online softmax
- For Convolution: Winograd, im2col
- **For RNN/GRU/LSTM**: Persistent kernel with HYBRID computation
  - **CRITICAL**: Use hybrid approach for best performance:
    * Precompute input-side gates ONCE (outside kernel): `gates_x = (T*B, In) @ W_ih`
    * Persistent kernel (inside): only recurrent-side: `for t: gates_h = h @ W_hh`
  - Time loop `for t in range(T)` must be inside kernel, NOT in Python
  - Launch kernel once per layer, not once per timestep
  - Expected speedup: 10-100x (vs per-timestep launches)

### 3. Kernel Launch Reduction
Combine multiple small kernels to reduce overhead.
- **For RNN/GRU/LSTM**: See "Algorithm Replacement" above for persistent kernel approach

### 4. Memory Layout Optimization
Use in-place operations, buffer reuse, or better layouts.

## Should We Optimize?

Before proposing optimization, determine if it's worthwhile:
- **Not worth optimizing** if:
  - Code is already near-optimal (expected speedup < 10%)
  - Bottleneck cannot be addressed (hardware limited, already optimal algorithm)
  - Optimization would add significant complexity with minimal gain

- **Worth optimizing** if:
  - Clear algorithmic inefficiency exists (multiple kernels, suboptimal algorithm)
  - Expected speedup >= 20%
  - Concrete optimization path available

## Output (JSON)

```json
{
  "worth_optimizing": "yes/no",
  "reason": "<Why worth or not worth optimizing, 1 sentence>",
  "bottleneck": "<Root cause in 1-2 sentences, empty if not worth optimizing>",
  "optimisation method": "<Specific optimization in 1-2 sentences, empty if not worth optimizing>",
  "modification plan": "<Implementation steps in 2-3 sentences, empty if not worth optimizing>",
  "expected_speedup": "<e.g., '30-40%', empty if not worth optimizing>"
}
```

Return JSON only.
