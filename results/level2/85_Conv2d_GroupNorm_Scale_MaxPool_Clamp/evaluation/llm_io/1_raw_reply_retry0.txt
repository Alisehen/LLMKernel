```python
# <optimized Triton code>
import torch
import torch.nn as nn
import triton
import triton.language as tl


# -----------------------------------
# Optimized Conv2D (im2col-style GEMM)
# -----------------------------------
@triton.jit
def conv2d_forward_kernel(
    x_ptr, w_ptr, b_ptr, y_ptr,
    B, Cin, H, W, Cout, Ho, Wo, Kh, Kw, Ktotal: tl.constexpr, P,
    stride_xb, stride_xc, stride_xh, stride_xw,
    stride_wco, stride_wci, stride_wkh, stride_wkw,
    stride_yb, stride_yc, stride_yh, stride_yw,
    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,
):
    # 2D grid over output: M = B*Ho*Wo, N = Cout
    pid_m = tl.program_id(0)
    pid_n = tl.program_id(1)

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    mask_m = offs_m < P
    mask_n = offs_n < Cout

    # Map flattened M index -> (b, ho, wo)
    HoWo = Ho * Wo
    offs_m_b = offs_m // HoWo
    rem_m = offs_m - offs_m_b * HoWo
    offs_m_ho = rem_m // Wo
    offs_m_wo = rem_m - offs_m_ho * Wo

    b = offs_m_b[:, None]
    ho = offs_m_ho[:, None]
    wo = offs_m_wo[:, None]
    n = offs_n[None, :]

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    KhKw = Kh * Kw

    # Ktotal is constexpr -> fully unrolled at compile-time
    for k0 in range(0, Ktotal, BLOCK_K):
        offs_k = k0 + tl.arange(0, BLOCK_K)
        mask_k = offs_k < Ktotal

        # Map K index -> (cin, kh, kw)
        cin = offs_k // KhKw
        rem_k = offs_k - cin * KhKw
        kh = rem_k // Kw
        kw = rem_k - kh * Kw

        cin_b = cin[None, :]
        kh_b = kh[None, :]
        kw_b = kw[None, :]

        # Input tile A [BM, BK]
        x_ptrs = (
            x_ptr
            + b * stride_xb
            + cin_b * stride_xc
            + (ho + kh_b) * stride_xh
            + (wo + kw_b) * stride_xw
        )
        mask_a = mask_m[:, None] & mask_k[None, :]
        a = tl.load(x_ptrs, mask=mask_a, other=0.0)

        # Weight tile B [BK, BN]
        w_ptrs = (
            w_ptr
            + cin[:, None] * stride_wci
            + kh[:, None] * stride_wkh
            + kw[:, None] * stride_wkw
            + n * stride_wco
        )
        mask_b = mask_k[:, None] & mask_n[None, :]
        b_mat = tl.load(w_ptrs, mask=mask_b, other=0.0)

        # Tensor-core friendly dot
        acc += tl.dot(a, b_mat, allow_tf32=True)

    # Bias add (fused with same (offs_m, offs_n, mask_n/mask_out))
    bias = tl.load(b_ptr + offs_n, mask=mask_n, other=0.0)
    acc += bias[None, :]

    # Store output
    y_ptrs = (
        y_ptr
        + b * stride_yb
        + n * stride_yc
        + ho * stride_yh
        + wo * stride_yw
    )
    mask_out = mask_m[:, None] & mask_n[None, :]
    tl.store(y_ptrs, acc, mask=mask_out)


def conv2d_triton(x, weight, bias):
    """
    x:      (B, Cin, H, W)
    weight: (Cout, Cin, Kh, Kw)
    bias:   (Cout,)
    Returns: (B, Cout, Ho, Wo), stride=1, padding=0
    """
    assert x.is_cuda and weight.is_cuda and bias.is_cuda
    B, Cin, H, W = x.shape
    Cout, Cin_w, Kh, Kw = weight.shape
    assert Cin == Cin_w
    Ho = H - Kh + 1
    Wo = W - Kw + 1
    Ktotal = Cin * Kh * Kw
    P = B * Ho * Wo

    y = torch.empty((B, Cout, Ho, Wo), device=x.device, dtype=x.dtype)

    # Tile tuned for Ada (4090)-like GPUs, tensor-core friendly
    BLOCK_M = 128
    BLOCK_N = 128
    BLOCK_K = 32

    grid = lambda META: (
        triton.cdiv(P, META["BLOCK_M"]),
        triton.cdiv(Cout, META["BLOCK_N"]),
    )

    conv2d_forward_kernel[grid](
        x, weight, bias, y,
        B, Cin, H, W, Cout, Ho, Wo, Kh, Kw, Ktotal, P,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        weight.stride(0), weight.stride(1), weight.stride(2), weight.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K,
        num_warps=8, num_stages=3,
    )
    return y


# ---------------------------------------------------------
# GroupNorm statistics kernel: per-(batch, group) mean/rstd
# ---------------------------------------------------------
@triton.jit
def groupnorm_stats_kernel(
    x_ptr, mean_ptr, rstd_ptr,
    B, C, H, W, G, channels_per_group,
    eps,
    stride_xb, stride_xc, stride_xh, stride_xw,
    M: tl.constexpr,          # M = channels_per_group * H * W
    BLOCK: tl.constexpr,
):
    """
    One program per (batch, group):
      - computes mean and rstd over C_group * H * W elements
    """
    pid = tl.program_id(0)  # 0 .. B*G-1
    b = pid // G
    g = pid - b * G

    sum_val = tl.zeros((), dtype=tl.float32)
    sum_sq_val = tl.zeros((), dtype=tl.float32)

    HW = H * W

    for offset in range(0, M, BLOCK):
        offs = offset + tl.arange(0, BLOCK)
        mask = offs < M

        ch_idx = offs // HW
        sp_idx = offs - ch_idx * HW
        h_idx = sp_idx // W
        w_idx = sp_idx - h_idx * W

        c = g * channels_per_group + ch_idx

        x_ptrs = (
            x_ptr
            + b * stride_xb
            + c * stride_xc
            + h_idx * stride_xh
            + w_idx * stride_xw
        )
        x = tl.load(x_ptrs, mask=mask, other=0.0).to(tl.float32)

        sum_val += tl.sum(x, axis=0)
        sum_sq_val += tl.sum(x * x, axis=0)

    M_f = tl.full((), M, tl.float32)
    mean = sum_val / M_f
    var = sum_sq_val / M_f - mean * mean
    rstd = 1.0 / tl.sqrt(var + eps)

    # Flattened index for (b, g)
    tl.store(mean_ptr + pid, mean)
    tl.store(rstd_ptr + pid, rstd)


# -----------------------------------------------------------------
# Fused GroupNorm (using precomputed stats) + scale + MaxPool + clamp
# Grid-layout for fused ops:
#   - 1D grid over flattened OUTPUT tensor: P = B*C*Hpo*Wpo
#   - Single offsets/mask used for all fused operations
# -----------------------------------------------------------------
@triton.jit
def groupnorm_scale_maxpool_clamp_fused_kernel(
    x_ptr, weight_ptr, bias_ptr, scale_ptr,
    mean_ptr, rstd_ptr,
    y_ptr,
    B, C, H, W, G, channels_per_group,
    Hpo: tl.constexpr, Wpo: tl.constexpr, Kp: tl.constexpr, stride_p,
    clamp_min, clamp_max,
    stride_xb, stride_xc, stride_xh, stride_xw,
    stride_yb, stride_yc, stride_yh, stride_yw,
    BLOCK: tl.constexpr,
):
    """
    Fused kernel over output tensor y:
      y: (B, C, Hpo, Wpo)

      For each output element (b, c, ho, wo):
        - gather Kp x Kp window from x[b, c, :, :]
        - apply GroupNorm (using precomputed mean/rstd for (b, group(c)))
        - apply affine (weight/bias) and extra scale
        - max-pool over window
        - clamp and store

    All fused ops (norm, affine, scale, pool, clamp, store) share:
      - same flattened offsets
      - same boundary mask
      - grid over OUTPUT elements
    """
    pid = tl.program_id(0)

    offs = pid * BLOCK + tl.arange(0, BLOCK)
    # Total number of output elements
    P = B * C * Hpo * Wpo
    mask = offs < P

    HWpo = Hpo * Wpo
    CHWpo = C * HWpo

    # Map flattened output index -> (b, c, ho, wo)
    b = offs // CHWpo
    rem_b = offs - b * CHWpo
    c = rem_b // HWpo
    rem_c = rem_b - c * HWpo
    ho = rem_c // Wpo
    wo = rem_c - ho * Wpo

    # Group index for GroupNorm
    g = c // channels_per_group
    bg_idx = b * G + g

    # Load GroupNorm affine + extra scale parameters per-channel
    gamma = tl.load(weight_ptr + c, mask=mask, other=1.0).to(tl.float32)
    beta = tl.load(bias_ptr + c, mask=mask, other=0.0).to(tl.float32)
    scale_v = tl.load(scale_ptr + c, mask=mask, other=1.0).to(tl.float32)

    # Load precomputed mean/rstd for (b, g)
    mean = tl.load(mean_ptr + bg_idx, mask=mask, other=0.0)
    rstd = tl.load(rstd_ptr + bg_idx, mask=mask, other=1.0)

    # Base coordinates of pooling window
    h0 = ho * stride_p
    w0 = wo * stride_p

    max_val = tl.full((BLOCK,), -1.0e30, dtype=tl.float32)

    # Kp x Kp maxpool window
    for kh in range(0, Kp):
        for kw in range(0, Kp):
            h_in = h0 + kh
            w_in = w0 + kw

            x_ptrs = (
                x_ptr
                + b * stride_xb
                + c * stride_xc
                + h_in * stride_xh
                + w_in * stride_xw
            )
            x_val = tl.load(x_ptrs, mask=mask, other=0.0).to(tl.float32)

            # GroupNorm normalization + affine + extra scale
            xn = (x_val - mean) * rstd
            xn = xn * gamma + beta
            xn = xn * scale_v

            max_val = tl.maximum(max_val, xn)

    # Clamp
    max_val = tl.maximum(max_val, clamp_min)
    max_val = tl.minimum(max_val, clamp_max)

    # Store outputs with same offsets/mask
    y_ptrs = (
        y_ptr
        + b * stride_yb
        + c * stride_yc
        + ho * stride_yh
        + wo * stride_yw
    )
    tl.store(y_ptrs, max_val, mask=mask)


def groupnorm_scale_maxpool_clamp_fused_triton(
    x, weight, bias, scale,
    num_groups, pool_ks, clamp_min, clamp_max, eps,
):
    """
    x: (B, C, H, W)  - conv output
    weight, bias: GroupNorm affine params, shape (C,)
    scale: (C, 1, 1) or (C,)
    Returns:
        y: (B, C, Hpo, Wpo) after:
            GroupNorm (per group) + extra scale + MaxPool2d + clamp
    """
    assert x.is_cuda
    B, C, H, W = x.shape
    G = num_groups
    assert C % G == 0
    channels_per_group = C // G

    stride_p = pool_ks
    Hpo = (H - pool_ks) // stride_p + 1
    Wpo = (W - pool_ks) // stride_p + 1

    # Output tensor
    y = torch.empty((B, C, Hpo, Wpo), device=x.device, dtype=x.dtype)

    # Flatten params to 1D (C,)
    weight_flat = weight.view(-1)
    bias_flat = bias.view(-1)
    scale_flat = scale.view(-1)

    # --------------------------------------
    # 1) GroupNorm statistics kernel (B * G)
    # --------------------------------------
    M = channels_per_group * H * W  # elements per (batch, group)

    mean = torch.empty(B * G, device=x.device, dtype=torch.float32)
    rstd = torch.empty(B * G, device=x.device, dtype=torch.float32)

    BLOCK_STATS = 256

    grid_stats = lambda META: (B * G,)

    groupnorm_stats_kernel[grid_stats](
        x, mean, rstd,
        B, C, H, W, G, channels_per_group,
        eps,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        M,
        BLOCK=BLOCK_STATS,
        num_warps=4,
        num_stages=2,
    )

    # --------------------------------------------------
    # 2) Fused norm + affine + scale + maxpool + clamp
    #    Grid over OUTPUT tensor (B*C*Hpo*Wpo), 1D
    # --------------------------------------------------
    P_out = B * C * Hpo * Wpo
    BLOCK_OUT = 256

    grid_fused = lambda META: (triton.cdiv(P_out, META["BLOCK"]),)

    groupnorm_scale_maxpool_clamp_fused_kernel[grid_fused](
        x, weight_flat, bias_flat, scale_flat,
        mean, rstd,
        y,
        B, C, H, W, G, channels_per_group,
        Hpo, Wpo, pool_ks, stride_p,
        clamp_min, clamp_max,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        BLOCK=BLOCK_OUT,
        num_warps=4,
        num_stages=2,
    )
    return y


class ModelNew(nn.Module):
    """
    Triton-optimized model:
      Conv2d (Triton) -> GroupNorm -> extra scale -> MaxPool2d -> clamp
    """
    def __init__(self, in_channels, out_channels, kernel_size,
                 num_groups, scale_shape, maxpool_kernel_size,
                 clamp_min, clamp_max):
        super(ModelNew, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.group_norm = nn.GroupNorm(num_groups, out_channels)
        self.scale = nn.Parameter(torch.ones(scale_shape))
        self.maxpool_kernel_size = maxpool_kernel_size
        self.clamp_min = clamp_min
        self.clamp_max = clamp_max

    def forward(self, x):
        # Conv via Triton
        x = conv2d_triton(x, self.conv.weight, self.conv.bias)

        # Fused GroupNorm + scale + maxpool + clamp via Triton
        x = groupnorm_scale_maxpool_clamp_fused_triton(
            x,
            self.group_norm.weight,
            self.group_norm.bias,
            self.scale,
            self.group_norm.num_groups,
            self.maxpool_kernel_size,
            self.clamp_min,
            self.clamp_max,
            self.group_norm.eps,
        )
        return x
```