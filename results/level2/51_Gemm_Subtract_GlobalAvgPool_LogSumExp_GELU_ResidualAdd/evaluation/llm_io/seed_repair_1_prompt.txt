Fix the Triton kernel errors. Generate correct, high-performance code.

Current Error Log:
Traceback (most recent call last):
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 535, in compare_and_bench
    test_out, _ = _run_once(test_model, inp, dev)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 132, in _run_once
    out = model(*inp)
          ^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/run/20251213_080631_batch_range40to70_deepseek_deepseek/51_Gemm_Subtract_GlobalAvgPool_LogSumExp_GELU_ResidualAdd/code/kernel_20251213_145009.py", line 303, in forward
    x = triton_fused_forward(
        ^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/run/20251213_080631_batch_range40to70_deepseek_deepseek/51_Gemm_Subtract_GlobalAvgPool_LogSumExp_GELU_ResidualAdd/code/kernel_20251213_145009.py", line 268, in triton_fused_forward
    reduce_and_activate_kernel[grid_red](
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 347, in <lambda>
    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 569, in run
    kernel = self.compile(src, target=target, options=options.__dict__)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py", line 230, in compile
    key = f"{triton_key()}-{src.hash()}-{backend.hash()}-{options.hash()}-{str(sorted(env_vars.items()))}"
                            ^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py", line 77, in hash
    key = f"{self.fn.cache_key}-{str(self.attrs)}-{sorted_sig}-{constants_key}"
             ^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 665, in cache_key
    dependencies_finder.visit(self.parse())
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/ast.py", line 418, in visit
    return visitor(node)
           ^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/ast.py", line 426, in generic_visit
    self.visit(item)
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/ast.py", line 418, in visit
    return visitor(node)
           ^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 149, in visit_FunctionDef
    self.generic_visit(node)
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/ast.py", line 426, in generic_visit
    self.visit(item)
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/ast.py", line 418, in visit
    return visitor(node)
           ^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 203, in visit_Assign
    self.generic_visit(node)
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/ast.py", line 428, in generic_visit
    self.visit(value)
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/ast.py", line 418, in visit
    return visitor(node)
           ^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/ast.py", line 428, in generic_visit
    self.visit(value)
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/ast.py", line 418, in visit
    return visitor(node)
           ^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 142, in visit_Attribute
    ret = getattr(lhs, node.attr)
          ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: module 'triton.language' has no attribute 'tanh'

History Error:
None


PyTorch Reference:
```python
import torch
import torch.nn as nn

class Model(nn.Module):
    """
    Model that performs a series of operations: Gemm, Subtract, GlobalAvgPool, LogSumExp, GELU, and ResidualAdd.
    """
    def __init__(self, in_features, out_features, bias=True):
        super(Model, self).__init__()
        self.gemm = nn.Linear(in_features, out_features, bias=bias)
        self.subtract = nn.Parameter(torch.randn(out_features))

    def forward(self, x):
        original_x = x.clone().detach()
        # Gemm
        x = self.gemm(x)

        # Subtract
        x = x - self.subtract

        # GlobalAvgPool
        x = torch.mean(x, dim=1, keepdim=True)

        # LogSumExp
        x = torch.logsumexp(x, dim=1, keepdim=True)

        # GELU
        x = torch.nn.functional.gelu(x)

        # ResidualAdd
        x = x + original_x

        return x

batch_size = 2048
in_features = 8192
out_features = 8192

def get_inputs():
    return [torch.rand(batch_size, in_features)]

def get_init_inputs():
    return [in_features, out_features]
```

Broken Code:
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.jit
def fused_forward_kernel(
    # Pointers to input and parameters
    input_ptr,
    weight_ptr,
    bias_ptr,
    subtract_ptr,
    output_ptr,
    # Matrix dimensions
    B,  # batch size
    N,  # input features
    K,  # output features (must equal N for residual add)
    # Strides
    stride_input_batch,
    stride_input_feat,
    stride_weight_in,
    stride_weight_out,
    # Meta-parameters
    BLOCK_SIZE_B: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
    BLOCK_SIZE_N: tl.constexpr,
    USE_BIAS: tl.constexpr,
):
    # Parallelize over batches and output features
    pid_b = tl.program_id(0)
    pid_k = tl.program_id(1)
    
    # Block indices
    offs_b = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)
    offs_k = pid_k * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)
    
    # Create masks for boundary checks
    mask_b = offs_b < B
    mask_k = offs_k < K
    
    # Initialize accumulator for GEMM
    accumulator = tl.zeros((BLOCK_SIZE_B, BLOCK_SIZE_K), dtype=tl.float32)
    
    # Blocked matrix multiplication
    for n_block in range(0, tl.cdiv(N, BLOCK_SIZE_N)):
        offs_n = n_block * BLOCK_SIZE_N + tl.arange(0, BLOCK_SIZE_N)
        mask_n = offs_n < N
        
        # Load input block
        input_ptrs = (
            input_ptr + 
            offs_b[:, None] * stride_input_batch + 
            offs_n[None, :] * stride_input_feat
        )
        input_block = tl.load(
            input_ptrs, 
            mask=mask_b[:, None] & mask_n[None, :],
            other=0.0
        )
        
        # Load weight block
        weight_ptrs = (
            weight_ptr + 
            offs_n[:, None] * stride_weight_in + 
            offs_k[None, :] * stride_weight_out
        )
        weight_block = tl.load(
            weight_ptrs,
            mask=mask_n[:, None] & mask_k[None, :],
            other=0.0
        )
        
        # Accumulate GEMM result
        accumulator += tl.dot(input_block, weight_block)
    
    # Apply bias if needed
    if USE_BIAS:
        bias_ptrs = bias_ptr + offs_k[None, :]
        bias = tl.load(bias_ptrs, mask=mask_k[None, :], other=0.0)
        accumulator += bias
    
    # Apply subtract parameter (broadcast over batch dimension)
    subtract_ptrs = subtract_ptr + offs_k[None, :]
    subtract = tl.load(subtract_ptrs, mask=mask_k[None, :], other=0.0)
    accumulator -= subtract
    
    # Store to temporary output for reductions
    # We'll compute mean and logsumexp in separate steps
    # First, store the GEMM-subtract result
    gemm_output_ptrs = (
        output_ptr + 
        offs_b[:, None] * K + 
        offs_k[None, :]
    )
    tl.store(
        gemm_output_ptrs,
        accumulator,
        mask=mask_b[:, None] & mask_k[None, :]
    )


@triton.jit
def reduce_and_activate_kernel(
    # Pointers
    gemm_output_ptr,
    original_input_ptr,
    final_output_ptr,
    # Dimensions
    B,
    K,
    # Strides
    stride_gemm_batch,
    stride_gemm_feat,
    stride_input_batch,
    stride_input_feat,
    # Meta-parameters
    BLOCK_SIZE_B: tl.constexpr,
    BLOCK_SIZE_K: tl.constexpr,
):
    # Parallelize over batches only
    pid_b = tl.program_id(0)
    
    offs_b = pid_b * BLOCK_SIZE_B + tl.arange(0, BLOCK_SIZE_B)
    mask_b = offs_b < B
    
    # Allocate block for reduction
    block_vals = tl.zeros((BLOCK_SIZE_B,), dtype=tl.float32)
    
    # Load block of values for this batch
    for k_block in range(0, tl.cdiv(K, BLOCK_SIZE_K)):
        offs_k = k_block * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)
        mask_k = offs_k < K
        
        # Load gemm output values
        gemm_ptrs = (
            gemm_output_ptr + 
            offs_b[:, None] * stride_gemm_batch + 
            offs_k[None, :] * stride_gemm_feat
        )
        vals = tl.load(
            gemm_ptrs,
            mask=mask_b[:, None] & mask_k[None, :],
            other=0.0
        )
        
        # Accumulate for mean
        block_vals += tl.sum(vals, axis=1)
    
    # Compute mean (divide by K)
    mean_val = block_vals / K
    
    # LogSumExp: Since we have only 1 value per batch after mean,
    # logsumexp(x) = log(exp(x)) = x
    # So we can skip the actual logsumexp computation
    
    # GELU activation
    # GELU(x) = 0.5 * x * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3)))
    sqrt_2_over_pi = 0.7978845608028654
    gelu_coef = 0.044715
    
    x = mean_val
    x_cubed = x * x * x
    inner = sqrt_2_over_pi * (x + gelu_coef * x_cubed)
    tanh_inner = tl.tanh(inner)
    gelu_val = 0.5 * x * (1 + tanh_inner)
    
    # Residual add: add original input
    # Original input shape: (B, N) where N = K
    # We need to add gelu_val to each element of original input row
    
    # For each batch, add gelu_val[batch] to all features of original input
    for k_block in range(0, tl.cdiv(K, BLOCK_SIZE_K)):
        offs_k = k_block * BLOCK_SIZE_K + tl.arange(0, BLOCK_SIZE_K)
        mask_k = offs_k < K
        
        # Load original input
        input_ptrs = (
            original_input_ptr + 
            offs_b[:, None] * stride_input_batch + 
            offs_k[None, :] * stride_input_feat
        )
        orig_vals = tl.load(
            input_ptrs,
            mask=mask_b[:, None] & mask_k[None, :],
            other=0.0
        )
        
        # Add GELU value (broadcast over features)
        result = orig_vals + gelu_val[:, None]
        
        # Store final output
        output_ptrs = (
            final_output_ptr + 
            offs_b[:, None] * K + 
            offs_k[None, :]
        )
        tl.store(
            output_ptrs,
            result,
            mask=mask_b[:, None] & mask_k[None, :]
        )


def triton_fused_forward(
    x: torch.Tensor,
    weight: torch.Tensor,
    bias: torch.Tensor,
    subtract: torch.Tensor,
) -> torch.Tensor:
    """
    Fused forward pass implementing:
    1. GEMM (linear layer)
    2. Subtract parameter
    3. Global average pool (mean over features)
    4. LogSumExp (simplified to identity after mean)
    5. GELU activation
    6. Residual add with original input
    """
    B, N = x.shape
    K = weight.shape[0]  # output features
    
    # Ensure K == N for residual add
    if K != N:
        raise ValueError(f"Output features ({K}) must equal input features ({N}) for residual add")
    
    # Intermediate storage for GEMM output
    gemm_output = torch.empty((B, K), device=x.device, dtype=x.dtype)
    
    # Configure GEMM kernel
    BLOCK_SIZE_B = 64  # Reduced for better occupancy
    BLOCK_SIZE_K = 64
    BLOCK_SIZE_N = 64
    
    grid = (
        triton.cdiv(B, BLOCK_SIZE_B),
        triton.cdiv(K, BLOCK_SIZE_K),
    )
    
    fused_forward_kernel[grid](
        x,
        weight,
        bias,
        subtract,
        gemm_output,
        B,
        N,
        K,
        x.stride(0),
        x.stride(1),
        weight.stride(1),
        weight.stride(0),
        BLOCK_SIZE_B=BLOCK_SIZE_B,
        BLOCK_SIZE_K=BLOCK_SIZE_K,
        BLOCK_SIZE_N=BLOCK_SIZE_N,
        USE_BIAS=bias is not None,
    )
    
    # Allocate final output
    final_output = torch.empty_like(x)
    
    # Configure reduction and activation kernel
    BLOCK_SIZE_B_RED = 64
    BLOCK_SIZE_K_RED = 64
    
    grid_red = (triton.cdiv(B, BLOCK_SIZE_B_RED),)
    
    reduce_and_activate_kernel[grid_red](
        gemm_output,
        x,
        final_output,
        B,
        K,
        gemm_output.stride(0),
        gemm_output.stride(1),
        x.stride(0),
        x.stride(1),
        BLOCK_SIZE_B=BLOCK_SIZE_B_RED,
        BLOCK_SIZE_K=BLOCK_SIZE_K_RED,
    )
    
    return final_output


class ModelNew(nn.Module):
    """
    Model that performs a series of operations: Gemm, Subtract, GlobalAvgPool, LogSumExp, GELU, and ResidualAdd.
    Optimized with fused Triton kernels.
    """
    def __init__(self, in_features, out_features, bias=True):
        super(ModelNew, self).__init__()
        self.gemm = nn.Linear(in_features, out_features, bias=bias)
        self.subtract = nn.Parameter(torch.randn(out_features))
        
        # Store original weight and bias for Triton kernel
        self._weight = self.gemm.weight
        self._bias = self.gemm.bias if bias else None

    def forward(self, x):
        original_x = x
        
        # Fused forward pass with Triton kernels
        x = triton_fused_forward(
            x,
            self._weight,
            self._bias,
            self.subtract,
        )
        
        return x
```

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs
3. Learn from previous repair attempts to avoid repeating the same mistakes

```python
# <corrected code>
```
