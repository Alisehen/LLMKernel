{
  "timestamp": "2025-12-28T16:49:02",
  "reference_file": "KernelBench/tt/80_Gemm_Max_Subtract_GELU.py",
  "candidate_file": "/home/hyc/LLMKernel/run/20251228_161811_batch_range79to85_openai_deepseek/80_Gemm_Max_Subtract_GELU/code/kernel_20251228_164856.py",
  "tolerance": 1,
  "max_abs_err": 0.0,
  "mean_abs_err": 0.0,
  "ref_latency_ms": {
    "avg": 3.2091904163360594,
    "min": 3.2021119594573975,
    "max": 3.220479965209961,
    "all": [
      3.220479965209961,
      3.2110719680786133,
      3.2021119594573975,
      3.2040960788726807,
      3.2081921100616455
    ]
  },
  "test_latency_ms": {
    "avg": 2.934841585159302,
    "min": 2.9256319999694824,
    "max": 2.9429759979248047,
    "all": [
      2.9429759979248047,
      2.934783935546875,
      2.927839994430542,
      2.9256319999694824,
      2.9429759979248047
    ]
  },
  "num_runs": 5,
  "model_init_args": [
    8192,
    8192,
    1
  ],
  "model_init_kwargs": {},
  "seed": 100,
  "align_stats": {
    "copied_same_shape": 2,
    "unique_shape_copied": 0,
    "mapped_shape": 0,
    "skipped": 0,
    "pair_aligner": 0,
    "pair_key": "Model->ModelNew"
  },
  "runnable": true,
  "phase": "stage3_memory_and_tuning_repair",
  "pytorch_baseline_ms": 3.142259216308594,
  "score": 1.0706742170337733
}