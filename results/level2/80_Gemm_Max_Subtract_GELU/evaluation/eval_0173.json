{
  "runnable": false,
  "phase": "seed_repair",
  "error_type": "RuntimeError",
  "message": "Traceback (most recent call last):\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py\", line 34, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py\", line 2400, in reduce\n    return reduce((input, ), axis, combine_fn, keep_dims=keep_dims, _builder=_builder, _generator=_generator)[0]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py\", line 34, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py\", line 2424, in reduce\n    axis = _wrap_axis(axis, len(input[0].shape))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py\", line 1712, in _wrap_axis\n    if not (-ndim <= axis < ndim):\n            ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py\", line 32, in wrapper\n    raise ValueError(\"Did you forget to add @triton.jit ? \"\nValueError: Did you forget to add @triton.jit ? (`_builder` argument must be provided outside of JIT functions.)\n\nThe above exception was the direct cause of the following exception:\n\ntriton.compiler.errors.CompilationError: at 15:15:\n        if return_indices_tie_break_left:\n            return core._reduce_with_indices(input, axis, _argmax_combine_tie_break_left, keep_dims=keep_dims)\n        else:\n            return core._reduce_with_indices(input, axis, _argmax_combine_tie_break_fast, keep_dims=keep_dims)\n    else:\n        if core.constexpr(input.dtype.primitive_bitwidth) < core.constexpr(32):\n            if core.constexpr(input.dtype.is_floating()):\n                input = input.to(core.float32)\n            else:\n                assert input.dtype.is_int(), \"Expecting input to be integer type\"\n                input = input.to(core.int32)\n        return core.reduce(input, axis, _elementwise_max, keep_dims=keep_dims)\n               ^\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/hyc/LLMKernel/utils/compile_and_run.py\", line 538, in compare_and_bench\n    test_out, _ = _run_once(test_model, inp, dev)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/utils/compile_and_run.py\", line 132, in _run_once\n    out = model(*inp)\n          ^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/run/20251214_114735_batch_range56to80_deepseek_deepseek/80_Gemm_Max_Subtract_GELU/code/kernel_20251215_020608.py\", line 268, in forward\n    return fused_gemm_max_sub_gelu(x, self.weight, self.max_dim)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/run/20251214_114735_batch_range56to80_deepseek_deepseek/80_Gemm_Max_Subtract_GELU/code/kernel_20251215_020608.py\", line 208, in fused_gemm_max_sub_gelu\n    fused_gemm_max_sub_gelu_kernel[grid](\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py\", line 347, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py\", line 569, in run\n    kernel = self.compile(src, target=target, options=options.__dict__)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py\", line 278, in compile\n    module = src.make_ir(options, codegen_fns, module_map, context)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py\", line 81, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntriton.compiler.errors.CompilationError: at 56:26:\n            tl.store(c_ptr + offs_m * stride_cm, new_max, mask=offs_m < M)\n        else:\n            # Reduce within block first, then atomic max\n            block_max = tl.max(acc, axis=1)  # shape: (BLOCK_M,)\n            for i in range(0, BLOCK_N):\n                col_idx = pid_n * BLOCK_N + i\n                if col_idx < N:\n                    # Extract column i from acc matrix properly using masking\n                    col_mask = tl.arange(0, BLOCK_N) == i\n                    acc_col = tl.where(col_mask, acc, -float('inf'))\n                    col_max = tl.max(acc_col, axis=1)\n                    val = tl.max(block_max, col_max)\n                          ^\n"
}