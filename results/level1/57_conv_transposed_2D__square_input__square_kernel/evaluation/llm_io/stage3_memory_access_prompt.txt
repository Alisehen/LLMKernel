You are a Triton kernel optimization specialist. Generate the FASTEST possible kernel.

# Target GPU
GPU Name: 4090
Architecture: Ada Lovelace
• Compute Capability: 8.9
• Number of SMs: 128
• Memory Bandwidth: 1008 GB/s
• TF32 Tensor Core TFLOPS: 82.6 with dense
• BFLOAT16 Tensor Core TFLOPS: 165.2 with dense
• FP16 Tensor Core TFLOPS: 165.2 with dense
• Maximum number of registers per thread: 255
• Maximum threads per block: 1024
• Maximum threads per SM: 1536
• Warp size: 32
• Maximum concurrent warps per SM: 48
• Shared memory capacity per SM: 100 KB
• Maximum shared memory per thread block: 99 KB
• L2 cache (global, all SM shared): 72 MB



[OPTIMIZATION STAGE]

## Current Optimization Stage

Focus: Memory efficiency & latency hiding.

Metrics:
- dram__throughput.avg.pct_of_peak_sustained_elapsed
- lts__t_sector_hit_rate.pct
- smsp__warp_issue_stalled_memory_dependency_per_warp_active.pct (<20%)

Rules:
- Increase num_stages only if memory stalls are high
- Do not rewrite access patterns without metric evidence
- Larger BLOCK_K improves reuse but increases register pressure

Autotune:
- If unsure, try num_stages ∈ {1,2,3} on kernel



[CURRENT CODE]
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.autotune(
    configs=[
        # Balanced square tile
        triton.Config(
            {
                "BLOCK_M": 64,   # spatial tile
                "BLOCK_N": 64,   # output-channel tile
                "BLOCK_K": 32,   # reduction tile
            },
            num_warps=4,
            num_stages=2,
        ),
        # Wider in channels: good when C_out is large
        triton.Config(
            {
                "BLOCK_M": 32,
                "BLOCK_N": 128,
                "BLOCK_K": 32,
            },
            num_warps=4,
            num_stages=2,
        ),
        # Taller in spatial: good when H_out*W_out is large
        triton.Config(
            {
                "BLOCK_M": 128,
                "BLOCK_N": 32,
                "BLOCK_K": 32,
            },
            num_warps=4,
            num_stages=2,
        ),
    ],
    key=["C_in", "C_out", "H_out", "W_out", "KH", "KW", "HAS_BIAS"],
)
@triton.jit
def conv_transpose2d_full_kernel(
    x_ptr,        # *f32, [N, C_in, H_in, W_in]
    w_ptr,        # *f32, [C_in, C_out, KH, KW]
    y_ptr,        # *f32, [N, C_out, H_out, W_out]
    bias_ptr,     # *f32, [C_out] (unused if HAS_BIAS == False)
    N, C_in, H_in, W_in,
    C_out, H_out, W_out,
    KH, KW,
    HAS_BIAS: tl.constexpr,
    BLOCK_M: tl.constexpr,
    BLOCK_N: tl.constexpr,
    BLOCK_K: tl.constexpr,
):
    """
    ConvTranspose2d, special case:
        stride = 1, padding = 0, output_padding = 0, dilation = 1, groups = 1
    Implemented as a full 2D convolution.

    Grid (3D):
      - program_id(0): batch   n in [0, N)
      - program_id(1): tiles over H_out * W_out (spatial positions)
      - program_id(2): tiles over C_out (output channels)

    M dimension: H_out * W_out, processed in blocks of BLOCK_M
    N dimension: C_out, processed in blocks of BLOCK_N
    K dimension: C_in, processed in blocks of BLOCK_K
    """
    pid_n = tl.program_id(axis=0)   # batch index n
    pid_m = tl.program_id(axis=1)   # tile over spatial positions H_out * W_out
    pid_co = tl.program_id(axis=2)  # tile over output channels C_out

    # Offsets in spatial (ho, wo) and output-channel dimensions
    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)  # [BLOCK_M]
    offs_co = pid_co * BLOCK_N + tl.arange(0, BLOCK_N)  # [BLOCK_N]

    tl.multiple_of(offs_m, BLOCK_M)
    tl.multiple_of(offs_co, BLOCK_N)

    hw_out = H_out * W_out
    mask_m = offs_m < hw_out
    mask_co = offs_co < C_out

    # Decompose spatial index into (ho, wo)
    ho = offs_m // W_out  # [BLOCK_M]
    wo = offs_m % W_out   # [BLOCK_M]

    # Broadcasted versions for pointer arithmetic
    ho_b = ho[:, None]              # [BLOCK_M, 1]
    wo_b = wo[:, None]              # [BLOCK_M, 1]
    co_b = offs_co[None, :]         # [1, BLOCK_N]

    # Accumulator for output tile
    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    # Scalar batch index
    n = pid_n

    # Main loops over kernel spatial dims and input channels
    for kh in range(0, KH):
        hi = ho - kh
        valid_hi = (hi >= 0) & (hi < H_in)
        hi_b = hi[:, None]  # [BLOCK_M, 1]

        for kw in range(0, KW):
            wi = wo - kw
            valid_wi = (wi >= 0) & (wi < W_in)
            wi_b = wi[:, None]  # [BLOCK_M, 1]

            mask_hw = mask_m & valid_hi & valid_wi  # [BLOCK_M]

            # Loop over input channels in tiles of BLOCK_K
            for c_start in range(0, C_in, BLOCK_K):
                ci = c_start + tl.arange(0, BLOCK_K)  # [BLOCK_K]
                mask_ci = ci < C_in                   # [BLOCK_K]

                tl.multiple_of(ci, BLOCK_K)

                ci_row = ci[None, :]   # [1, BLOCK_K]
                ci_col = ci[:, None]   # [BLOCK_K, 1]

                # ------------------------------------------------------------------
                # Load input tile X: shape [BLOCK_M, BLOCK_K]
                #   x[n, ci, hi, wi]
                # Linear index: (((n * C_in + ci) * H_in + hi) * W_in + wi)
                # ------------------------------------------------------------------
                x_ptrs = (((n * C_in + ci_row) * H_in + hi_b) * W_in + wi_b)
                mask_x = mask_hw[:, None] & mask_ci[None, :]
                x_tile = tl.load(x_ptr + x_ptrs, mask=mask_x, other=0.0)

                # ------------------------------------------------------------------
                # Load weight tile W: shape [BLOCK_K, BLOCK_N]
                #   w[ci, co, kh, kw]
                # Linear index: (((ci * C_out + co) * KH + kh) * KW + kw)
                # ------------------------------------------------------------------
                w_ptrs = (((ci_col * C_out + co_b) * KH + kh) * KW + kw)
                mask_w = mask_ci[:, None] & mask_co[None, :]
                w_tile = tl.load(w_ptr + w_ptrs, mask=mask_w, other=0.0)

                # Accumulate
                acc += tl.dot(x_tile, w_tile)

    # Add bias if present
    if HAS_BIAS:
        bias = tl.load(bias_ptr + offs_co, mask=mask_co, other=0.0)  # [BLOCK_N]
        acc = acc + bias[None, :]                                    # [BLOCK_M, BLOCK_N]

    # Store results
    # y[n, co, ho, wo]
    y_ptrs = (((n * C_out + co_b) * H_out + ho_b) * W_out + wo_b)
    mask_y = mask_m[:, None] & mask_co[None, :]
    tl.store(y_ptr + y_ptrs, acc, mask=mask_y)


def triton_conv_transpose2d_full(
    x: torch.Tensor,
    weight: torch.Tensor,
    bias: torch.Tensor | None,
) -> torch.Tensor:
    """
    Triton implementation of ConvTranspose2d for the restricted case:

        stride = 1
        padding = 0
        output_padding = 0
        dilation = 1
        groups = 1

    which is equivalent to a 2D full convolution.

    Args:
        x:      [N, C_in, H_in, W_in], float32, CUDA
        weight: [C_in, C_out, KH, KW], float32, CUDA
        bias:   [C_out] or None, float32, CUDA

    Returns:
        y: [N, C_out, H_out, W_out]
           where H_out = H_in + KH - 1, W_out = W_in + KW - 1
    """
    assert x.is_cuda and weight.is_cuda, "Inputs must be CUDA tensors"
    assert x.dtype == torch.float32 and weight.dtype == torch.float32, "Only float32 is supported in Triton kernel"
    assert x.ndim == 4 and weight.ndim == 4, "x must be [N,C,H,W], weight must be [C_in,C_out,KH,KW]"

    N, C_in, H_in, W_in = x.shape
    C_in_w, C_out, KH, KW = weight.shape
    assert C_in_w == C_in, "Input channels mismatch between x and weight"

    H_out = H_in + KH - 1
    W_out = W_in + KW - 1

    y = torch.empty((N, C_out, H_out, W_out), device=x.device, dtype=x.dtype)

    # 3D grid: (batch, spatial tiles, channel tiles)
    grid = lambda meta: (
        N,
        triton.cdiv(H_out * W_out, meta["BLOCK_M"]),
        triton.cdiv(C_out, meta["BLOCK_N"]),
    )

    has_bias = bias is not None
    if bias is None:
        # Dummy pointer; will not be used when HAS_BIAS=False
        bias = y.new_empty(1)

    conv_transpose2d_full_kernel[grid](
        x, weight, y, bias,
        N, C_in, H_in, W_in,
        C_out, H_out, W_out,
        KH, KW,
        HAS_BIAS=has_bias,
    )

    return y


class ModelNew(nn.Module):
    """
    Triton-accelerated ConvTranspose2d for the restricted case:

        stride == 1
        padding == 0
        output_padding == 0
        dilation == 1
        groups == 1
        dtype == float32
        device == CUDA
    """

    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: int,
        stride: int = 1,
        padding: int = 0,
        output_padding: int = 0,
        groups: int = 1,
        bias: bool = False,
    ) -> None:
        super().__init__()
        self.conv_transpose2d = nn.ConvTranspose2d(
            in_channels,
            out_channels,
            kernel_size,
            stride=stride,
            padding=padding,
            output_padding=output_padding,
            groups=groups,
            bias=bias,
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        ct = self.conv_transpose2d

        use_triton = (
            x.is_cuda
            and x.dtype == torch.float32
            and ct.weight.is_cuda
            and ct.weight.dtype == torch.float32
            and ct.groups == 1
            and ct.dilation == (1, 1)
            and ct.stride == (1, 1)
            and ct.padding == (0, 0)
            and ct.output_padding == (0, 0)
        )

        if use_triton:
            return triton_conv_transpose2d_full(x, ct.weight, ct.bias)
        else:
            return ct(x)
```

[NCU PROFILING METRICS]
{
  "conv_transpose2d_full_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 17.24,
    "launch__grid_size": 131600,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 16.63,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 15.28,
    "lts__t_sector_hit_rate.pct": 95.51
  }
}

**Task**: Analyze the NCU metrics and current code, then generate optimized code that maximizes performance.

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <optimized Triton code>
```
