```python
# <complete ModelNew code with optimized Triton kernels>
import torch
import torch.nn as nn
import triton
import triton.language as tl
import math


@triton.autotune(
    configs=[
        triton.Config({'BLOCK_M': 32, 'BLOCK_N': 64, 'BLOCK_K': 16, 'num_warps': 4, 'num_stages': 2}),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 64, 'BLOCK_K': 32, 'num_warps': 8, 'num_stages': 3}),
        triton.Config({'BLOCK_M': 64, 'BLOCK_N': 32, 'BLOCK_K': 32, 'num_warps': 4, 'num_stages': 2}),
    ],
    key=['M_SIZE', 'N_SIZE', 'K_SIZE'],
)
@triton.jit
def conv3d_im2col_kernel(
    input_ptr,
    weight_ptr,
    bias_ptr,
    output_ptr,
    N_batches,
    Cin,
    Cout,
    D,
    H,
    W,
    KD,
    KH,
    KW,
    stride_d,
    stride_h,
    stride_w,
    pad_d,
    pad_h,
    pad_w,
    dil_d,
    dil_h,
    dil_w,
    D_out,
    H_out,
    W_out,
    M_SIZE,
    N_SIZE,
    K_SIZE,
    HAS_BIAS: tl.constexpr,
    BLOCK_M: tl.constexpr,
    BLOCK_N: tl.constexpr,
    BLOCK_K: tl.constexpr,
):
    pid_m = tl.program_id(axis=0)
    pid_n = tl.program_id(axis=1)

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    mask_m = offs_m < M_SIZE
    mask_n = offs_n < N_SIZE

    offs_m_i32 = offs_m.to(tl.int32)

    ow = offs_m_i32 % W_out
    tmp = offs_m_i32 // W_out
    oh = tmp % H_out
    tmp = tmp // H_out
    od = tmp % D_out
    n_batch = tmp // D_out

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    if HAS_BIAS:
        bias_vals = tl.load(bias_ptr + offs_n, mask=mask_n, other=0.0).to(tl.float32)
        acc += bias_vals[None, :]

    for k_start in range(0, K_SIZE, BLOCK_K):
        k_idx = k_start + tl.arange(0, BLOCK_K)
        k_mask = k_idx < K_SIZE
        k_safe = tl.where(k_mask, k_idx, 0)

        kw = k_safe % KW
        tmp_k = k_safe // KW
        kh = tmp_k % KH
        tmp_k = tmp_k // KH
        kd = tmp_k % KD
        ic = tmp_k // KD

        ow_b = ow[:, None]
        oh_b = oh[:, None]
        od_b = od[:, None]
        n_b = n_batch[:, None]

        kw_b = kw[None, :]
        kh_b = kh[None, :]
        kd_b = kd[None, :]
        ic_bk = ic[None, :]

        in_w = ow_b * stride_w + kw_b * dil_w - pad_w
        in_h = oh_b * stride_h + kh_b * dil_h - pad_h
        in_d = od_b * stride_d + kd_b * dil_d - pad_d

        valid_in = (
            mask_m[:, None]
            & k_mask[None, :]
            & (in_w >= 0) & (in_w < W)
            & (in_h >= 0) & (in_h < H)
            & (in_d >= 0) & (in_d < D)
        )

        n_b64 = n_b.to(tl.int64)
        ic_bk64 = ic_bk.to(tl.int64)
        in_d64 = in_d.to(tl.int64)
        in_h64 = in_h.to(tl.int64)
        in_w64 = in_w.to(tl.int64)

        inp_ptrs = ((((n_b64 * Cin + ic_bk64) * D + in_d64) * H + in_h64) * W + in_w64)
        inp_vals = tl.load(input_ptr + inp_ptrs, mask=valid_in, other=0.0)

        oc_b = offs_n[None, :]
        oc_b64 = oc_b.to(tl.int64)
        ic_bc64 = ic[:, None].to(tl.int64)
        kd64 = kd[:, None].to(tl.int64)
        kh64 = kh[:, None].to(tl.int64)
        kw64 = kw[:, None].to(tl.int64)

        w_ptrs = (((((oc_b64 * Cin + ic_bc64) * KD + kd64) * KH + kh64) * KW + kw64))
        w_mask = k_mask[:, None] & mask_n[None, :]
        w_vals = tl.load(weight_ptr + w_ptrs, mask=w_mask, other=0.0)

        acc += tl.dot(inp_vals, w_vals)

    n_b64 = n_batch[:, None].to(tl.int64)
    od64 = od[:, None].to(tl.int64)
    oh64 = oh[:, None].to(tl.int64)
    ow64 = ow[:, None].to(tl.int64)
    oc64 = offs_n[None, :].to(tl.int64)

    out_ptrs = (((((n_b64 * Cout + oc64) * D_out + od64) * H_out + oh64) * W_out + ow64))
    out_mask = mask_m[:, None] & mask_n[None, :]
    tl.store(output_ptr + out_ptrs, acc, mask=out_mask)


def _triple(x):
    if isinstance(x, tuple):
        assert len(x) == 3
        return x
    return (x, x, x)


def triton_conv3d(x, weight, bias, stride, padding, dilation):
    if x.dtype != torch.float32 or weight.dtype != torch.float32:
        raise NotImplementedError("Only float32 tensors are supported in this implementation.")

    stride_d, stride_h, stride_w = _triple(stride)
    pad_d, pad_h, pad_w = _triple(padding)
    dil_d, dil_h, dil_w = _triple(dilation)

    N, Cin, D, H, W = x.shape
    Cout, Cin_w, KD, KH, KW = weight.shape
    if Cin != Cin_w:
        raise NotImplementedError("Grouped convolution is not supported in this implementation.")

    D_out = (D + 2 * pad_d - dil_d * (KD - 1) - 1) // stride_d + 1
    H_out = (H + 2 * pad_h - dil_h * (KH - 1) - 1) // stride_h + 1
    W_out = (W + 2 * pad_w - dil_w * (KW - 1) - 1) // stride_w + 1

    x_contig = x.contiguous()
    w_contig = weight.contiguous()
    output = torch.empty((N, Cout, D_out, H_out, W_out), device=x.device, dtype=x.dtype)

    M_SIZE = N * D_out * H_out * W_out
    N_SIZE = Cout
    K_SIZE = Cin * KD * KH * KW

    grid = lambda META: (triton.cdiv(M_SIZE, META['BLOCK_M']), triton.cdiv(N_SIZE, META['BLOCK_N']))

    bias_ptr = bias.contiguous() if bias is not None else output.new_empty(1)

    conv3d_im2col_kernel[grid](
        x_contig,
        w_contig,
        bias_ptr,
        output,
        N,
        Cin,
        Cout,
        D,
        H,
        W,
        KD,
        KH,
        KW,
        stride_d,
        stride_h,
        stride_w,
        pad_d,
        pad_h,
        pad_w,
        dil_d,
        dil_h,
        dil_w,
        D_out,
        H_out,
        W_out,
        M_SIZE,
        N_SIZE,
        K_SIZE,
        HAS_BIAS=bias is not None,
    )

    return output


class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int = 1, padding: int = 0, dilation: int = 1, groups: int = 1, bias: bool = False):
        super().__init__()
        if groups != 1:
            raise NotImplementedError("Grouped convolution is not supported in this implementation.")
        kernel_size = _triple(kernel_size) if isinstance(kernel_size, tuple) else (kernel_size, kernel_size, kernel_size)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.kernel_size = kernel_size
        self.stride = stride
        self.padding = padding
        self.dilation = dilation
        self.groups = groups

        self.weight = nn.Parameter(torch.empty(out_channels, in_channels, *kernel_size))
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.register_parameter("bias", None)
        self.reset_parameters()

    def reset_parameters(self):
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in = self.in_channels * self.kernel_size[0] * self.kernel_size[1] * self.kernel_size[2]
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return triton_conv3d(x, self.weight, self.bias, self.stride, self.padding, self.dilation)
```