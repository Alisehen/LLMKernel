You are a Triton kernel optimization specialist. Generate the FASTEST possible kernel.

# Target GPU
GPU Name: 4090
Architecture: Ada Lovelace
• Compute Capability: 8.9
• Number of SMs: 128
• Memory Bandwidth: 1008 GB/s
• TF32 Tensor Core TFLOPS: 82.6 with dense
• BFLOAT16 Tensor Core TFLOPS: 165.2 with dense
• FP16 Tensor Core TFLOPS: 165.2 with dense
• Maximum number of registers per thread: 255
• Maximum threads per block: 1024
• Maximum threads per SM: 1536
• Warp size: 32
• Maximum concurrent warps per SM: 48
• Shared memory capacity per SM: 100 KB
• Maximum shared memory per thread block: 99 KB
• L2 cache (global, all SM shared): 72 MB



[OPTIMIZATION STAGE]

## Current Optimization Stage

Focus: BLOCK_M/N/K selection.

Metrics:
- sm__warps_active.avg.pct_of_peak_sustained_active (>50%)

Rules:
- BLOCK_* must be powers of 2
- Tensor Core: BLOCK_M/N multiple of 16, BLOCK_K multiple of 8 (preference)
- FP32: M/N ∈ {32,64,128,256}, K ∈ {16,32,64}
- Avoid oversized tiles (mask waste)
- Keep baseline tile if unsure

Autotune:
- 2–4 configs max
- Autotune ONLY on @triton.jit kernel



[CURRENT CODE]
```python
import math
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.jit
def batched_matmul_kernel(
    A_ptr, B_ptr, C_ptr,
    BATCH, M, N, K,
    stride_ab, stride_am, stride_ak,
    stride_bb, stride_bk, stride_bn,
    stride_cb, stride_cm, stride_cn,
    scale,
    ADD_SCALE: tl.constexpr,
    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,
):
    """
    Compute batched matrix multiplication:
        for b in [0, BATCH):
            C[b, :, :] = (A[b, :, :] @ B[b, :, :]) * scale (if ADD_SCALE)
    Shapes:
        A: [BATCH, M, K]
        B: [BATCH, K, N]
        C: [BATCH, M, N]
    Strides are in *elements* (not bytes).
    """
    pid_m = tl.program_id(axis=0)
    pid_n = tl.program_id(axis=1)
    pid_b = tl.program_id(axis=2)

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
    offs_k = tl.arange(0, BLOCK_K)

    # Base pointers for this batch
    A_batch_ptr = A_ptr + pid_b * stride_ab
    B_batch_ptr = B_ptr + pid_b * stride_bb
    C_batch_ptr = C_ptr + pid_b * stride_cb

    # Accumulator in fp32 for better precision
    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    k = 0
    while k < K:
        k_offsets = k + offs_k
        k_mask = k_offsets < K

        # Pointers for A [M, K]
        a_ptrs = A_batch_ptr + (
            offs_m[:, None] * stride_am + k_offsets[None, :] * stride_ak
        )
        # Pointers for B [K, N]
        b_ptrs = B_batch_ptr + (
            k_offsets[:, None] * stride_bk + offs_n[None, :] * stride_bn
        )

        a = tl.load(
            a_ptrs,
            mask=(offs_m[:, None] < M) & (k_mask[None, :]),
            other=0.0
        )
        b = tl.load(
            b_ptrs,
            mask=(k_mask[:, None]) & (offs_n[None, :] < N),
            other=0.0
        )

        # tl.dot with fp16 inputs -> fp32 accumulation
        acc += tl.dot(a, b)

        k += BLOCK_K

    if ADD_SCALE:
        acc *= scale

    # Write back to C
    c = acc.to(tl.float16)
    c_ptrs = C_batch_ptr + (
        offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn
    )
    c_mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)
    tl.store(c_ptrs, c, mask=c_mask)


@triton.jit
def softmax_kernel(
    input_ptr, output_ptr,
    stride_ib, stride_im, stride_in,
    stride_ob, stride_om, stride_on,
    BATCH, M, N,
    BLOCK_N: tl.constexpr,
):
    """
    Row-wise softmax over the last dimension N for a [BATCH, M, N] tensor.
    Each program instance handles one row (fixed batch & row index).
    """
    pid_m = tl.program_id(axis=0)  # row index within sequence length (M)
    pid_b = tl.program_id(axis=1)  # batch-head index (BATCH)

    # Pointers to the start of this row
    row_in_ptr = input_ptr + pid_b * stride_ib + pid_m * stride_im
    row_out_ptr = output_ptr + pid_b * stride_ob + pid_m * stride_om

    offs_n = tl.arange(0, BLOCK_N)
    mask = offs_n < N

    # Load row, convert to fp32 for stability
    row = tl.load(
        row_in_ptr + offs_n * stride_in,
        mask=mask,
        other=-float("inf"),
    )
    row = row.to(tl.float32)

    # Numerically stable softmax
    row_max = tl.max(row, axis=0)
    row = row - row_max
    exp_row = tl.exp(row)
    denom = tl.sum(exp_row, axis=0)
    softmax = exp_row / denom

    softmax = softmax.to(tl.float16)
    tl.store(
        row_out_ptr + offs_n * stride_on,
        softmax,
        mask=mask,
    )


def triton_scaled_dot_product_attention(Q: torch.Tensor,
                                        K: torch.Tensor,
                                        V: torch.Tensor) -> torch.Tensor:
    """
    Triton implementation of scaled dot-product attention:

        attn = softmax(Q @ K^T / sqrt(d_k))
        out  = attn @ V

    Inputs:
        Q, K, V: [B, H, S, D], dtype=float16, CUDA tensors
    Output:
        out: [B, H, S, D], dtype=float16
    """
    assert Q.is_cuda and K.is_cuda and V.is_cuda, "Inputs must be CUDA tensors"
    assert Q.dtype == torch.float16 and K.dtype == torch.float16 and V.dtype == torch.float16
    assert Q.shape == K.shape == V.shape
    B, H, S, D = Q.shape
    BH = B * H

    # Make inputs contiguous and flatten batch + heads
    Q_flat = Q.contiguous().view(BH, S, D)
    K_flat = K.contiguous().view(BH, S, D)
    V_flat = V.contiguous().view(BH, S, D)

    device = Q.device

    # 1) Compute attention scores = Q @ K^T / sqrt(D)
    #    Result shape: [BH, S, S]
    scores = torch.empty((BH, S, S), device=device, dtype=torch.float16)

    BLOCK_M = 64
    BLOCK_N = 64
    BLOCK_K = 32

    # Matmul 1: Q [BH, S, D] @ K^T [BH, D, S] -> scores [BH, S, S]
    grid_scores = lambda meta: (
        triton.cdiv(S, meta["BLOCK_M"]),
        triton.cdiv(S, meta["BLOCK_N"]),
        BH,
    )

    scale = 1.0 / math.sqrt(D)

    batched_matmul_kernel[grid_scores](
        Q_flat, K_flat, scores,
        BH, S, S, D,
        # A strides: Q_flat as [BH, M=S, K=D]
        Q_flat.stride(0), Q_flat.stride(1), Q_flat.stride(2),
        # B strides: view K_flat as [BH, K=D, N=S] via transpose of last two dims
        K_flat.stride(0), K_flat.stride(2), K_flat.stride(1),
        # C strides: scores as [BH, M=S, N=S]
        scores.stride(0), scores.stride(1), scores.stride(2),
        scale,
        ADD_SCALE=True,
        BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K,
        num_warps=4,
        num_stages=2,
    )

    # 2) Softmax over last dimension of scores: [BH, S, S]
    probs = torch.empty_like(scores)

    BLOCK_SOFTMAX = 512  # >= S (=512), power of 2

    grid_softmax = (S, BH)
    softmax_kernel[grid_softmax](
        scores, probs,
        scores.stride(0), scores.stride(1), scores.stride(2),
        probs.stride(0), probs.stride(1), probs.stride(2),
        BH, S, S,
        BLOCK_N=BLOCK_SOFTMAX,
        num_warps=4,
        num_stages=1,
    )

    # 3) Compute output = probs @ V
    #    probs [BH, S, S], V [BH, S, D] -> out_flat [BH, S, D]
    out_flat = torch.empty((BH, S, D), device=device, dtype=torch.float16)

    grid_out = lambda meta: (
        triton.cdiv(S, meta["BLOCK_M"]),
        triton.cdiv(D, meta["BLOCK_N"]),
        BH,
    )

    batched_matmul_kernel[grid_out](
        probs, V_flat, out_flat,
        BH, S, D, S,
        # A strides: probs as [BH, M=S, K=S]
        probs.stride(0), probs.stride(1), probs.stride(2),
        # B strides: V_flat as [BH, K=S, N=D]
        V_flat.stride(0), V_flat.stride(1), V_flat.stride(2),
        # C strides: out_flat as [BH, M=S, N=D]
        out_flat.stride(0), out_flat.stride(1), out_flat.stride(2),
        1.0,
        ADD_SCALE=False,
        BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K,
        num_warps=4,
        num_stages=2,
    )

    # Reshape back to [B, H, S, D]
    out = out_flat.view(B, H, S, D)
    return out


class ModelNew(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, Q: torch.Tensor, K: torch.Tensor, V: torch.Tensor) -> torch.Tensor:
        return triton_scaled_dot_product_attention(Q, K, V)
```

[NCU PROFILING METRICS]
{
  "batched_matmul_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 44.71,
    "launch__grid_size": 131072,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 49.63,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 64.29,
    "lts__t_sector_hit_rate.pct": 91.15
  },
  "softmax_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 32.83,
    "launch__grid_size": 524288,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 95.64,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 93.77,
    "lts__t_sector_hit_rate.pct": 50.01
  }
}

**Task**: Analyze the NCU metrics and current code, then generate optimized code that maximizes performance.

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <optimized Triton code>
```
