{
  "runnable": false,
  "phase": "stage3_repair",
  "error_type": "RuntimeError",
  "message": "Traceback (most recent call last):\n  File \"/home/hyc/LLMKernel/utils/compile_and_run.py\", line 514, in compare_and_bench\n    inp = get_inputs()\n          ^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/KernelBench/level1_low_score/97_ScaledDotProductAttention.py\", line 18, in get_inputs\n    Q = torch.rand(batch_size, num_heads, sequence_length, embedding_dimension, device='cuda', dtype=torch.float16)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
}