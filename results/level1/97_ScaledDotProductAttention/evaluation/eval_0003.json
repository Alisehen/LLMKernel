{
  "runnable": false,
  "phase": "stage3_memory_access",
  "error_type": "RuntimeError",
  "message": "Traceback (most recent call last):\n  File \"/home/hyc/LLMKernel/utils/compile_and_run.py\", line 536, in compare_and_bench\n    test_out, _ = _run_once(test_model, inp, dev)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/utils/compile_and_run.py\", line 132, in _run_once\n    out = model(*inp)\n          ^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/run/20251213_163716_97_ScaledDotProductAttention_openai_deepseek/97_ScaledDotProductAttention/code/kernel_20251213_165355.py\", line 195, in forward\n    return triton_scaled_dot_product_attention(Q, K, V)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/run/20251213_163716_97_ScaledDotProductAttention_openai_deepseek/97_ScaledDotProductAttention/code/kernel_20251213_165355.py\", line 157, in triton_scaled_dot_product_attention\n    assert D <= 128, \"This optimized kernel assumes head_dim <= 128 for best performance.\"\n           ^^^^^^^^\nAssertionError: This optimized kernel assumes head_dim <= 128 for best performance.\n"
}