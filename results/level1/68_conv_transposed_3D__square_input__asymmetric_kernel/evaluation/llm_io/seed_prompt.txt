
Write a correct and reasonably fast Triton kernel to replace the given PyTorch operator.
This is a SEED implementation: prioritize correctness and stable compilation.

Rules:
- Use `tl.program_id(axis)` (axis=0/1/2 only)
- Use `tl.arange()` for block indices
- Operate on blocks (no CUDA thread model)
- No manual shared memory or synchronization

Hard Constraints:
- All BLOCK_* are `tl.constexpr` and powers of 2
- `tl.arange(0, BLOCK)` requires BLOCK to be power-of-2
- No dynamic `tl.reshape()` or view
- `tl.load` / `tl.store`: scalar ptr → scalar, block ptr → block
- No Python control flow on `tl.tensor` or BLOCK_*
- Triton does NOT support `continue`, `break`, or `return` inside loops — use masking instead
- Import ALL modules you use (e.g., `import math` if using `math.sqrt`)
- Do NOT index tensors with loop variables: `tensor[:, i]` or `tensor[i, :]` where i is a loop var is INVALID
- Shared memory limit ~100KB: for matmul, BLOCK_M*BLOCK_K + BLOCK_K*BLOCK_N < 25000 floats

CRITICAL API Constraints:
- Triton does NOT have `tl.any()` → use: `tl.sum(mask) > 0`
- Triton does NOT have `tl.all()` → use: `tl.sum(mask) == mask.numel()`
- Triton does NOT have `tl.reduce()` → use: `tl.sum()`, `tl.max()`, `tl.min()` with axis parameter
- Do NOT use f-strings or .format() with tl.constexpr in assert/error messages

Memory Best Practices:
- Avoid unnecessary `.contiguous()` calls - Triton kernels work with strided tensors
- Only call `.contiguous()` if you verified stride pattern causes correctness issues


Performance Guidelines for Transposed Convolution (ConvTranspose):
⚠️ CRITICAL DIFFERENCES from standard convolution:
- Output size GROWS: out_size = (in_size - 1) * stride + kernel_size - 2*padding
- Each INPUT element writes to MULTIPLE OUTPUT positions (scatter pattern)
- Groups require: in_channels % groups == 0 AND out_channels % groups == 0

RECOMMENDED APPROACH - Direct Implementation (NOT implicit GEMM):
1. **Reverse Index Mapping**:
   For each output position (od, oh, ow), find ALL contributing input positions:
   ```python
   # For each kernel position (kd, kh, kw):
   id = (od + padding - kd) // stride  # Must check if divisible!
   ih = (oh + padding - kh) // stride
   iw = (ow + padding - kw) // stride

   # Valid only if:
   valid = ((od + padding - kd) % stride == 0) & (id >= 0) & (id < ID) & ...
   ```

2. **Grid Layout for 3D Transposed Conv**:
   ```python
   # Parallelize over output spatial dimensions
   N, C_out, OD, OH, OW = output.shape
   grid = (triton.cdiv(N * OD * OH * OW, BLOCK_OUT), C_out // groups, groups)

   # In kernel - decode flat index:
   pid = tl.program_id(0)
   out_idx = pid * BLOCK_OUT + tl.arange(0, BLOCK_OUT)
   n = out_idx // (OD * OH * OW)
   remainder = out_idx % (OD * OH * OW)
   od = remainder // (OH * OW)
   oh = (remainder % (OH * OW)) // OW
   ow = remainder % OW
   ```

3. **Grouped Convolution Handling**:
   ```python
   group_id = tl.program_id(2)
   C_in_per_group = C_in // groups
   C_out_per_group = C_out // groups

   c_in_start = group_id * C_in_per_group
   c_out_start = group_id * C_out_per_group

   # Weight indexing: weight[c_out_in_group, c_in_in_group, kd, kh, kw]
   # where c_out_in_group ∈ [0, C_out_per_group)
   #       c_in_in_group ∈ [0, C_in_per_group)
   ```

4. **Accumulation Pattern**:
   ```python
   acc = tl.zeros((BLOCK_OUT,), dtype=tl.float32)

   # Loop over kernel dimensions
   for kd in range(KD):
       for kh in range(KH):
           for kw in range(KW):
               # Compute input indices
               id = (od + padding - kd) // stride
               ih = (oh + padding - kh) // stride
               iw = (ow + padding - kw) // stride

               # Check validity (must be divisible AND in bounds)
               valid_d = ((od + padding - kd) % stride == 0) & (id >= 0) & (id < ID)
               valid_h = ((oh + padding - kh) % stride == 0) & (ih >= 0) & (ih < IH)
               valid_w = ((ow + padding - kw) % stride == 0) & (iw >= 0) & (iw < IW)
               valid = valid_d & valid_h & valid_w

               # Loop over input channels in this group
               for c_in_offset in range(C_in_per_group):
                   c_in = c_in_start + c_in_offset
                   input_val = tl.load(input_ptr + ..., mask=valid, other=0.0)
                   weight_val = tl.load(weight_ptr + ...)
                   acc += input_val * weight_val
   ```

5. **AVOID Common Errors**:
   ❌ Do NOT use implicit GEMM (access pattern is fundamentally different)
   ❌ Do NOT forget modulo check: (od + pad - kd) % stride == 0
   ❌ Do NOT ignore groups in weight/channel indexing
   ❌ Do NOT use atomics unless truly necessary (prefer output parallelism)

6. **Numerical Precision**:
   - Use fp32 accumulation even for fp16 input
   - Test stride > 1 and groups > 1 carefully
   - Verify output shape formula matches PyTorch exactly

7. **Performance Tips**:
   - For small kernels (3x3x3), unroll loops manually
   - Use vectorized loads when possible (BLOCK_OUT should be power of 2)
   - Consider tiling over channels if C_in_per_group is large


Output Format (STRICT):
1. Imports (torch, torch.nn, triton, triton.language, and any other needed modules like math)
2. `@triton.jit` kernel(s)
3. Wrapper function(s)
4. `class ModelNew(nn.Module)` — this class is REQUIRED

Do NOT include testing code or `if __name__ == "__main__"`.

Example PyTorch:
'''
import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()

    def forward(self, a, b):
        return a + b


def get_inputs():
    # randomly generate input tensors based on the model architecture
    a = torch.randn(1, 128).cuda()
    b = torch.randn(1, 128).cuda()
    return [a, b]


def get_init_inputs():
    # randomly generate tensors required for initialization based on the model architecture
    return []
'''

Example Triton:
'''
import torch
import torch.nn as nn
import triton
import triton.language as tl

@triton.jit
def add_kernel(
    x_ptr,
    y_ptr,
    output_ptr,
    n_elements,
    BLOCK_SIZE: tl.constexpr,
):
    pid = tl.program_id(axis=0)
    block_start = pid * BLOCK_SIZE
    offsets = block_start + tl.arange(0, BLOCK_SIZE)
    mask = offsets < n_elements

    x = tl.load(x_ptr + offsets, mask=mask)
    y = tl.load(y_ptr + offsets, mask=mask)

    output = x + y
    tl.store(output_ptr + offsets, output, mask=mask)

def triton_add(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
    output = torch.empty_like(x)
    n_elements = output.numel()
    BLOCK_SIZE = 1024
    grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)
    add_kernel[grid](x, y, output, n_elements, BLOCK_SIZE=BLOCK_SIZE)

    return output

class ModelNew(nn.Module):
    def __init__(self) -> None:
        super().__init__()

    def forward(self, a, b):
        return triton_add(a, b)
'''

Hardware:
• Compute Capability: 8.9
• Number of SMs: 128
• Memory Bandwidth: 1008 GB/s
• TF32 Tensor Core TFLOPS: 82.6 with dense
• BFLOAT16 Tensor Core TFLOPS: 165.2 with dense
• FP16 Tensor Core TFLOPS: 165.2 with dense
• Maximum number of registers per thread: 255
• Maximum threads per block: 1024
• Maximum threads per SM: 1536
• Warp size: 32
• Maximum concurrent warps per SM: 48
• Shared memory capacity per SM: 100 KB
• Maximum shared memory per thread block: 99 KB
• L2 cache (global, all SM shared): 72 MB

Target:
```python
import torch
import torch.nn as nn

class Model(nn.Module):
    """
    Performs a transposed 3D convolution with a square input and an asymmetric kernel.

    Args:
        in_channels (int): Number of channels in the input tensor.
        out_channels (int): Number of channels produced by the convolution.
        kernel_size (tuple): Size of the convolution kernel (kernel_depth, kernel_width, kernel_height), 
                             where kernel_width == kernel_height.
        stride (tuple, optional): Stride of the convolution. Defaults to (1, 1, 1).
        padding (tuple, optional): Padding applied to the input. Defaults to (0, 0, 0).
        output_padding (tuple, optional): Additional size added to one side of the output shape. Defaults to (0, 0, 0).
        groups (int, optional): Number of blocked connections from input channels to output channels. Defaults to 1.
        bias (bool, optional): If `True`, adds a learnable bias to the output. Defaults to `False`.
    """
    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1, 1), padding: tuple = (0, 0, 0), output_padding: tuple = (0, 0, 0), groups: int = 1, bias: bool = False):
        super(Model, self).__init__()
        self.conv_transpose3d = nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, output_padding=output_padding, groups=groups, bias=bias)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Performs the transposed 3D convolution.

        Args:
            x (torch.Tensor): Input tensor of shape (batch_size, in_channels, depth, width, height).

        Returns:
            torch.Tensor: Output tensor of shape (batch_size, out_channels, depth_out, width_out, height_out).
        """
        return self.conv_transpose3d(x)

# Test code
batch_size = 16
in_channels = 32
out_channels = 64
kernel_depth = 3
kernel_width = 5
kernel_height = 5
depth = 64
width = 64
height = 64

def get_inputs():
    x = torch.rand(batch_size, in_channels, depth, width, height)
    return [x]

def get_init_inputs():
    return [in_channels, out_channels, (kernel_depth, kernel_width, kernel_height)]  # Provide in_channels, out_channels, kernel_size for initialization
