```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.autotune(
    configs=[
        triton.Config({}, num_warps=8, num_stages=3),
        triton.Config({}, num_warps=8, num_stages=4),
        triton.Config({}, num_warps=16, num_stages=3),
        triton.Config({}, num_warps=16, num_stages=4),
        triton.Config({}, num_warps=4, num_stages=3),
        triton.Config({}, num_warps=4, num_stages=4),
    ],
    key=['spatial_size', 'total_slices'],
)
@triton.jit
def compute_moments_kernel(
    x_ptr,
    mean_ptr,
    var_ptr,
    spatial_size,
    total_slices,
    eps: tl.constexpr,
    BLOCK_SIZE: tl.constexpr,
):
    """Compute mean and variance for each (n,c) slice using a single thread per slice"""
    pid = tl.program_id(0)  # which (n,c) slice
    
    if pid >= total_slices:
        return
    
    # Initialize accumulators
    sum_x = 0.0
    sum_x2 = 0.0
    
    # Process the entire spatial dimension in blocks
    for off in range(0, spatial_size, BLOCK_SIZE):
        idx = off + tl.arange(0, BLOCK_SIZE)
        mask = idx < spatial_size
        
        # Load data for this block
        x = tl.load(x_ptr + pid * spatial_size + idx, mask=mask, other=0.0)
        
        # Update accumulators
        sum_x += tl.sum(x)
        sum_x2 += tl.sum(x * x)
    
    # Compute final mean and variance
    mean_val = sum_x / spatial_size
    variance = tl.maximum(sum_x2 / spatial_size - mean_val * mean_val, 0.0)
    
    # Store results
    tl.store(mean_ptr + pid, mean_val)
    tl.store(var_ptr + pid, variance)


@triton.autotune(
    configs=[
        triton.Config({}, num_warps=8, num_stages=3),
        triton.Config({}, num_warps=8, num_stages=2),
        triton.Config({}, num_warps=16, num_stages=3),
        triton.Config({}, num_warps=16, num_stages=2),
        triton.Config({}, num_warps=4, num_stages=3),
        triton.Config({}, num_warps=4, num_stages=2),
    ],
    key=['spatial_size', 'total_slices'],
)
@triton.jit
def normalize_kernel(
    x_ptr,
    output_ptr,
    mean_ptr,
    var_ptr,
    spatial_size,
    total_slices,
    eps: tl.constexpr,
    BLOCK_SIZE: tl.constexpr,
):
    """Normalize each (n,c) slice using the precomputed mean and variance"""
    pid = tl.program_id(0)  # which (n,c) slice
    
    if pid >= total_slices:
        return
    
    # Load mean and variance for this slice
    mean_val = tl.load(mean_ptr + pid)
    var_val = tl.load(var_ptr + pid)
    
    # Compute inverse standard deviation
    inv_std = tl.math.rsqrt(var_val + eps)
    
    # Process the entire spatial dimension in blocks
    for off in range(0, spatial_size, BLOCK_SIZE):
        idx = off + tl.arange(0, BLOCK_SIZE)
        mask = idx < spatial_size
        
        # Load input data
        x = tl.load(x_ptr + pid * spatial_size + idx, mask=mask, other=0.0)
        
        # Normalize
        normalized = (x - mean_val) * inv_std
        
        # Store output
        tl.store(output_ptr + pid * spatial_size + idx, normalized, mask=mask)


def triton_instance_norm(x: torch.Tensor, eps: float = 1e-5) -> torch.Tensor:
    N, C, H, W = x.shape
    spatial_size = H * W
    total_slices = N * C
    
    # Ensure contiguous memory layout
    x_contig = x.contiguous()
    output = torch.empty_like(x_contig)
    
    # Optimized block size for spatial dimension processing
    BLOCK_SIZE = 1024
    
    # Allocate buffers for moments
    mean = torch.zeros(total_slices, device=x.device, dtype=torch.float32)
    var = torch.zeros(total_slices, device=x.device, dtype=torch.float32)
    
    # Launch compute moments kernel
    grid = (total_slices,)
    compute_moments_kernel[grid](
        x_contig, mean, var,
        spatial_size, total_slices,
        eps,
        BLOCK_SIZE=BLOCK_SIZE
    )
    
    # Launch normalize kernel
    normalize_kernel[grid](
        x_contig, output, mean, var,
        spatial_size, total_slices,
        eps,
        BLOCK_SIZE=BLOCK_SIZE
    )
    
    return output


class ModelNew(nn.Module):
    def __init__(self, num_features: int):
        super().__init__()
        self.num_features = num_features

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return triton_instance_norm(x)
```

**Optimization Analysis & Changes:**

1. **Added `@triton.autotune` decorators** to both kernels with 3-6 configurations each, as specified in the safe autotune tip.

2. **compute_moments_kernel tuning**:
   - **High warp activity (96.27%)** but only **16.04% SM throughput** indicates memory-bound behavior
   - **Very low L1 cache hit rate (0.01%)** suggests poor data reuse
   - Tested configurations: `num_warps={4,8,16}`, `num_stages={3,4}`
   - Kept the original `num_warps=8` config but added `num_stages=4` option

3. **normalize_kernel tuning**:
   - **Very low SM throughput (1.23%)** despite **94.68% warp activity**
   - **Better L1 cache hit rate (50.0%)** due to spatial locality
   - Tested configurations: `num_warps={4,8,16}`, `num_stages={2,3}`
   - Kept the original `num_warps=8` config but added `num_stages=2` option

4. **Why these specific configurations**:
   - The current `num_warps=8` (256 threads) provides good occupancy on Ada Lovelace (128 SMs, 1536 threads/SM)
   - Testing `num_warps=16` (512 threads) may improve memory latency hiding for memory-bound compute_moments_kernel
   - Testing `num_warps=4` (128 threads) may reduce register pressure and allow higher occupancy
   - `num_stages=3` (default) and `Â±1` variations as per optimization guidelines
   - Each autotune includes the original kernel config plus 5 variations

5. **Performance expectations**:
   - Autotuning will automatically select the fastest configuration for each input size
   - The memory-bound compute_moments_kernel may benefit from higher `num_stages` (4) to hide DRAM latency
   - The normalize_kernel may benefit from lower `num_stages` (2) to reduce shared memory pressure
   - Different `num_warps` values will balance occupancy and resource utilization

The autotune configurations follow all optimization guidelines while maximizing the chance of finding the fastest kernel variant for the target GPU architecture.