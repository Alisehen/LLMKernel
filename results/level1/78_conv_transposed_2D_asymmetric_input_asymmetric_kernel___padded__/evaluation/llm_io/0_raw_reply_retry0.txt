```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.jit
def conv_transpose2d_kernel(
    x_ptr,
    w_ptr,
    b_ptr,
    out_ptr,
    B,
    H_in,
    W_in,
    H_out,
    W_out,
    total_out,
    Cin: tl.constexpr,
    Cout: tl.constexpr,
    Kh: tl.constexpr,
    Kw: tl.constexpr,
    stride_h: tl.constexpr,
    stride_w: tl.constexpr,
    pad_h: tl.constexpr,
    pad_w: tl.constexpr,
    HAS_BIAS: tl.constexpr,
    BLOCK_SIZE: tl.constexpr,
):
    pid = tl.program_id(axis=0)
    block_start = pid * BLOCK_SIZE
    offsets = block_start + tl.arange(0, BLOCK_SIZE)
    mask = offsets < total_out

    ow = offsets % W_out
    tmp = offsets // W_out
    oh = tmp % H_out
    tmp = tmp // H_out
    co = tmp % Cout
    b = tmp // Cout

    acc = tl.zeros([BLOCK_SIZE], dtype=tl.float32)

    for ci in range(Cin):
        bc = b * Cin + ci
        for kh in range(Kh):
            oh_k = oh + pad_h - kh
            cond_h = (oh_k % stride_h) == 0
            ih = oh_k // stride_h
            cond_h = cond_h & (ih >= 0) & (ih < H_in)
            ih_val = tl.where(cond_h, ih, 0)
            for kw in range(Kw):
                ow_k = ow + pad_w - kw
                cond_w = (ow_k % stride_w) == 0
                iw = ow_k // stride_w
                cond_w = cond_w & (iw >= 0) & (iw < W_in)
                iw_val = tl.where(cond_w, iw, 0)
                cond = mask & cond_h & cond_w

                in_idx = (((bc * H_in) + ih_val) * W_in) + iw_val
                inp = tl.load(x_ptr + in_idx, mask=cond, other=0.0)

                w_idx = (((ci * Cout) + co) * Kh + kh) * Kw + kw
                weight = tl.load(w_ptr + w_idx, mask=mask, other=0.0)

                acc += inp * weight

    if HAS_BIAS:
        bias = tl.load(b_ptr + co, mask=mask, other=0.0)
        acc += bias

    tl.store(out_ptr + offsets, acc, mask=mask)


def triton_conv_transpose2d(x, weight, bias, stride, padding):
    B, Cin, H_in, W_in = x.shape
    Cout = weight.shape[1]
    Kh, Kw = weight.shape[2], weight.shape[3]
    stride_h, stride_w = stride
    pad_h, pad_w = padding

    H_out = (H_in - 1) * stride_h - 2 * pad_h + Kh
    W_out = (W_in - 1) * stride_w - 2 * pad_w + Kw

    out = torch.empty((B, Cout, H_out, W_out), device=x.device, dtype=x.dtype)

    total_out = B * Cout * H_out * W_out
    BLOCK_SIZE = 256
    grid = lambda meta: (triton.cdiv(total_out, meta['BLOCK_SIZE']),)

    conv_transpose2d_kernel[grid](
        x,
        weight,
        bias if bias is not None else out,
        out,
        B,
        H_in,
        W_in,
        H_out,
        W_out,
        total_out,
        Cin=Cin,
        Cout=Cout,
        Kh=Kh,
        Kw=Kw,
        stride_h=stride_h,
        stride_w=stride_w,
        pad_h=pad_h,
        pad_w=pad_w,
        HAS_BIAS=bias is not None,
        BLOCK_SIZE=BLOCK_SIZE,
    )

    return out


class ModelNew(nn.Module):
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: tuple,
        stride: tuple = (1, 1),
        padding: tuple = (0, 0),
        bias: bool = False,
    ):
        super().__init__()
        self.conv_transpose2d = nn.ConvTranspose2d(
            in_channels,
            out_channels,
            kernel_size,
            stride=stride,
            padding=padding,
            bias=bias,
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return triton_conv_transpose2d(
            x,
            self.conv_transpose2d.weight,
            self.conv_transpose2d.bias,
            self.conv_transpose2d.stride,
            self.conv_transpose2d.padding,
        )
```