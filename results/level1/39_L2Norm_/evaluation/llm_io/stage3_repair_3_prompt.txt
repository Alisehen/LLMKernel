Fix the Triton kernel errors. Generate correct, high-performance code.

Current Error Log:
Traceback (most recent call last):
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 615, in compare_and_bench
    ref_t  = _bench(ref_model,  inp, dev, warmup, repeat)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 146, in _bench
    model(*inp)
  File "/home/hyc/miniconda3/envs/hyc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/hyc/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/KernelBench/level1/39_L2Norm_.py", line 27, in forward
    return x / torch.norm(x, p=2, dim=1, keepdim=True)
           ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 47.50 GiB of which 1.24 GiB is free. Process 3342606 has 21.50 GiB memory in use. Including non-PyTorch memory, this process has 24.69 GiB memory in use. Of the allocated memory 24.00 GiB is allocated by PyTorch, and 1.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

History Error:
Previous Repair Attempts (avoid repeating these errors):
Attempt 1:

        if tl.program_id(1) == 0:
            x_chunk = tl.load(x_ptrs, mask=batch_mask[:, None] & d_mask[None, :], other=0.0)
                      ^
Cannot make_shape_compatible: incompatible dimensions at index 1: 256 and 32

Attempt 2:
Traceback (most recent call last):
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 609, in compare_and_bench
    raise ValueError(
ValueError: Outputs are not close (atol=0.001, rtol=0.001). max_abs_err=5.994e-03, mean_abs_err=2.913e-03



PyTorch Reference:
```python
import torch
import torch.nn as nn

class Model(nn.Module):
    """
    Simple model that performs L2 normalization.
    """
    def __init__(self):
        """
        Initializes the L2Norm layer.

        Args:
            dim (int): Dimension along which to normalize.
        """
        super(Model, self).__init__()

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Applies L2 normalization to the input tensor.

        Args:
            x (torch.Tensor): Input tensor of shape (*, dim, *).

        Returns:
            torch.Tensor: Output tensor with L2 normalization applied, same shape as input.
        """
        return x / torch.norm(x, p=2, dim=1, keepdim=True)

batch_size = 32768
# choose dim so total <2^31
dim = 65535

def get_inputs():
    x = torch.rand(batch_size, dim)
    return [x]

def get_init_inputs():
    return []
```

Broken Code:
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl

@triton.jit
def l2_norm_kernel(
    x_ptr,
    norm_ptr,
    batch_size,
    dim,
    stride_x_batch,
    stride_x_dim,
    stride_norm_batch,
    BLOCK_B: tl.constexpr,
    BLOCK_D: tl.constexpr,
):
    """Compute L2 norm by summing squared values across dimension."""
    # 1D launch grid
    pid = tl.program_id(0)
    
    # Calculate batch and dimension indices from single pid
    num_batch_blocks = tl.cdiv(batch_size, BLOCK_B)
    batch_block_idx = pid // num_batch_blocks
    dim_block_idx = pid % num_batch_blocks
    
    # Batch offsets for this block
    batch_start = batch_block_idx * BLOCK_B
    batch_offsets = batch_start + tl.arange(0, BLOCK_B)
    batch_mask = batch_offsets < batch_size
    
    # Dimension offsets for this block
    dim_start = dim_block_idx * BLOCK_D
    dim_offsets = dim_start + tl.arange(0, BLOCK_D)
    dim_mask = dim_offsets < dim
    
    # Initialize local sum
    local_sum = tl.zeros((BLOCK_B,), dtype=tl.float32)
    
    if tl.sum(dim_mask) > 0:
        # Create pointers for this block
        x_ptrs = x_ptr + (
            batch_offsets[:, None] * stride_x_batch +
            dim_offsets[None, :] * stride_x_dim
        )
        
        # Load with proper masking
        mask = batch_mask[:, None] & dim_mask[None, :]
        x_block = tl.load(x_ptrs, mask=mask, other=0.0)
        
        # Accumulate sum of squares
        local_sum = tl.sum(x_block * x_block, axis=1)
    
    # Atomic add to global norm tensor with proper masking
    if tl.sum(batch_mask) > 0:
        norm_ptrs = norm_ptr + batch_offsets * stride_norm_batch
        tl.atomic_add(norm_ptrs, local_sum, mask=batch_mask)

@triton.jit
def normalize_kernel(
    x_ptr,
    norm_ptr,
    output_ptr,
    batch_size,
    dim,
    epsilon,
    stride_x_batch,
    stride_x_dim,
    stride_norm_batch,
    stride_out_batch,
    stride_out_dim,
    BLOCK_B: tl.constexpr,
    BLOCK_D: tl.constexpr,
):
    """Normalize input by computed L2 norms."""
    # 1D launch grid
    pid = tl.program_id(0)
    
    # Calculate batch and dimension indices from single pid
    num_batch_blocks = tl.cdiv(batch_size, BLOCK_B)
    batch_block_idx = pid // num_batch_blocks
    dim_block_idx = pid % num_batch_blocks
    
    # Batch offsets for this block
    batch_start = batch_block_idx * BLOCK_B
    batch_offsets = batch_start + tl.arange(0, BLOCK_B)
    batch_mask = batch_offsets < batch_size
    
    # Dimension offsets for this block
    dim_start = dim_block_idx * BLOCK_D
    dim_offsets = dim_start + tl.arange(0, BLOCK_D)
    dim_mask = dim_offsets < dim
    
    # Load and compute inverse norm
    norm_ptrs = norm_ptr + batch_offsets * stride_norm_batch
    norm_values = tl.load(norm_ptrs, mask=batch_mask, other=0.0)
    inv_norm = 1.0 / (tl.sqrt(norm_values + epsilon))
    
    # Input pointers
    x_ptrs = x_ptr + (
        batch_offsets[:, None] * stride_x_batch +
        dim_offsets[None, :] * stride_x_dim
    )
    
    # Output pointers
    out_ptrs = output_ptr + (
        batch_offsets[:, None] * stride_out_batch +
        dim_offsets[None, :] * stride_out_dim
    )
    
    # Load, normalize, and store
    mask = batch_mask[:, None] & dim_mask[None, :]
    x_block = tl.load(x_ptrs, mask=mask, other=0.0)
    normalized = x_block * inv_norm[:, None]
    tl.store(out_ptrs, normalized, mask=mask)

def triton_l2_norm(x: torch.Tensor, epsilon: float = 1e-8) -> torch.Tensor:
    assert x.is_cuda, "Input must be on CUDA device"
    assert x.dim() == 2, "Input must have exactly 2 dimensions (batch, dim)"
    
    batch_size, dim = x.shape
    output = torch.empty_like(x)
    
    # Ensure contiguous memory layout
    x = x.contiguous()
    output = output.contiguous()
    
    stride_x_batch = x.stride(0)
    stride_x_dim = x.stride(1)
    stride_out_batch = output.stride(0)
    stride_out_dim = output.stride(1)
    
    # Allocate norm tensor for accumulation
    norm_sums = torch.zeros(batch_size, device=x.device, dtype=torch.float32)
    
    # Optimized block sizes
    BLOCK_B = 128
    BLOCK_D = 256
    
    # Calculate grid dimensions - 1D grid
    grid = (triton.cdiv(batch_size, BLOCK_B) * triton.cdiv(dim, BLOCK_D),)
    
    # Launch norm computation kernel
    l2_norm_kernel[grid](
        x,
        norm_sums,
        batch_size,
        dim,
        stride_x_batch,
        stride_x_dim,
        norm_sums.stride(0),
        BLOCK_B=BLOCK_B,
        BLOCK_D=BLOCK_D,
    )
    
    # Launch normalization kernel with same grid
    normalize_kernel[grid](
        x,
        norm_sums,
        output,
        batch_size,
        dim,
        epsilon,
        stride_x_batch,
        stride_x_dim,
        norm_sums.stride(0),
        stride_out_batch,
        stride_out_dim,
        BLOCK_B=BLOCK_B,
        BLOCK_D=BLOCK_D,
    )
    
    return output

class ModelNew(nn.Module):
    """L2 normalization layer with optimized Triton kernels."""
    def __init__(self, epsilon: float = 1e-8):
        super(ModelNew, self).__init__()
        self.epsilon = epsilon

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Handle multi-dimensional tensors by flattening to 2D
        if x.dim() > 2:
            original_shape = x.shape
            x = x.view(-1, original_shape[-1])
            result = triton_l2_norm(x, self.epsilon)
            return result.view(original_shape)
        return triton_l2_norm(x, self.epsilon)
```

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs
3. Learn from previous repair attempts to avoid repeating the same mistakes

```python
# <corrected code>
```
