```python
# <optimized Triton code>
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.autotune(
    configs=[
        # Balanced, good for many shapes
        triton.Config(
            {'BLOCK_CO': 64, 'BLOCK_OW': 64, 'BLOCK_CI': 32},
            num_warps=4,
            num_stages=2,
        ),
        # Larger spatial tile, more warps – better latency hiding
        triton.Config(
            {'BLOCK_CO': 64, 'BLOCK_OW': 128, 'BLOCK_CI': 32},
            num_warps=8,
            num_stages=2,
        ),
        # Larger channel tiles – more compute per tile
        triton.Config(
            {'BLOCK_CO': 128, 'BLOCK_OW': 64, 'BLOCK_CI': 64},
            num_warps=8,
            num_stages=3,
        ),
        # More but thinner CO tiles – can help small channel counts
        triton.Config(
            {'BLOCK_CO': 32, 'BLOCK_OW': 128, 'BLOCK_CI': 32},
            num_warps=4,
            num_stages=2,
        ),
    ],
    key=['C_out_per_group', 'D_out', 'H_out', 'W_out'],
)
@triton.jit
def conv_transpose3d_kernel(
    x_ptr,       # *f32, [N, C_in, D_in, H_in, W_in]
    w_ptr,       # *f32, [C_in, C_out_per_group, KD, KH, KW]
    out_ptr,     # *f32, [N, C_out, D_out, H_out, W_out]
    N, C_in,
    D_in, H_in, W_in,
    C_out,
    groups,
    C_in_per_group,
    C_out_per_group,
    stride_d, stride_h, stride_w,
    pad_d, pad_h, pad_w,
    dil_d, dil_h, dil_w,
    D_out, H_out, W_out,
    BLOCK_CO: tl.constexpr,
    BLOCK_OW: tl.constexpr,
    BLOCK_CI: tl.constexpr,
    KD: tl.constexpr,
    KH: tl.constexpr,
    KW: tl.constexpr,
):
    # Program IDs:
    # axis 0: (n, group) combined
    # axis 1: output channel tiles within a group
    # axis 2: output spatial tiles (flattened D_out*H_out*W_out)
    pid_ng = tl.program_id(0)
    pid_co = tl.program_id(1)
    pid_ow = tl.program_id(2)

    # Decode batch and group
    g = pid_ng % groups
    n = pid_ng // groups

    # Output-channel offsets within this group
    co_in_group = pid_co * BLOCK_CO + tl.arange(0, BLOCK_CO)
    mask_co = co_in_group < C_out_per_group
    co = g * C_out_per_group + co_in_group  # global output channels

    # Output spatial offsets (flattened D_out * H_out * W_out)
    DHW_out = D_out * H_out * W_out
    ow_offsets = pid_ow * BLOCK_OW + tl.arange(0, BLOCK_OW)
    mask_ow = ow_offsets < DHW_out

    # Decode flattened spatial offsets into (d_out, h_out, w_out)
    w_out = ow_offsets % W_out
    tmp = ow_offsets // W_out
    h_out = tmp % H_out
    d_out = tmp // H_out

    # Initialize accumulator for this tile: [BLOCK_CO, BLOCK_OW]
    acc = tl.zeros((BLOCK_CO, BLOCK_OW), dtype=tl.float32)

    # Input strides for [N, C_in, D_in, H_in, W_in]
    x_stride_w = 1
    x_stride_h = W_in
    x_stride_d = H_in * W_in
    x_stride_c = D_in * H_in * W_in
    x_stride_n = C_in * x_stride_c

    # Weight strides for [C_in, C_out_per_group, KD, KH, KW]
    w_stride_kw = 1
    w_stride_kh = KW
    w_stride_kd = KH * KW
    w_stride_cout = KD * KH * KW
    w_stride_cin = C_out_per_group * w_stride_cout

    # Base offsets for this (n, group)
    base_x_n = n * x_stride_n
    base_group_cin = g * C_in_per_group

    # Loop over kernel volume (compile-time unrolled)
    for kd in range(KD):
        kd_dil = kd * dil_d
        kd_offset = kd * w_stride_kd
        for kh in range(KH):
            kh_dil = kh * dil_h
            kh_offset = kh * w_stride_kh + kd_offset
            for kw in range(KW):
                kw_dil = kw * dil_w
                weight_k_offset = kw * w_stride_kw + kh_offset

                # Compute candidate input coordinates that contribute to (d_out, h_out, w_out)
                id_unscaled = d_out + pad_d - kd_dil
                ih_unscaled = h_out + pad_h - kh_dil
                iw_unscaled = w_out + pad_w - kw_dil

                # Check stride divisibility
                mod_d = id_unscaled % stride_d
                mod_h = ih_unscaled % stride_h
                mod_w = iw_unscaled % stride_w

                id = id_unscaled // stride_d
                ih = ih_unscaled // stride_h
                iw = iw_unscaled // stride_w

                # Spatial validity mask
                sp_mask = (
                    mask_ow &
                    (mod_d == 0) & (mod_h == 0) & (mod_w == 0) &
                    (id >= 0) & (id < D_in) &
                    (ih >= 0) & (ih < H_in) &
                    (iw >= 0) & (iw < W_in)
                )

                # Flattened spatial index for input tensor
                spatial_idx = id * x_stride_d + ih * x_stride_h + iw * x_stride_w  # [BLOCK_OW]

                # Loop over input channels in this group in tiles of BLOCK_CI
                ci_start = 0
                while ci_start < C_in_per_group:
                    ci_offsets = ci_start + tl.arange(0, BLOCK_CI)
                    mask_ci = ci_offsets < C_in_per_group

                    c_in = base_group_cin + ci_offsets  # global input channels [BLOCK_CI]

                    # Base indices for input channels (n fixed)
                    base_x_cin = base_x_n + c_in * x_stride_c  # [BLOCK_CI]

                    # 2D input indices: [BLOCK_CI, BLOCK_OW]
                    x_idx = base_x_cin[:, None] + spatial_idx[None, :]  # broadcast

                    mask_x = mask_ci[:, None] & sp_mask[None, :]

                    x_vals = tl.load(x_ptr + x_idx, mask=mask_x, other=0.0)

                    # Weight indices: [C_in, C_out_per_group, KD, KH, KW]
                    base_w_cin = c_in * w_stride_cin  # [BLOCK_CI]
                    w_idx = base_w_cin[:, None] + weight_k_offset + co_in_group[None, :] * w_stride_cout

                    mask_w = mask_ci[:, None] & mask_co[None, :]

                    w_vals = tl.load(w_ptr + w_idx, mask=mask_w, other=0.0)

                    # GEMM: (CO, CI) @ (CI, OW) -> (CO, OW)
                    a = tl.trans(w_vals)  # [BLOCK_CO, BLOCK_CI]
                    b = x_vals            # [BLOCK_CI, BLOCK_OW]
                    acc += tl.dot(a, b)

                    ci_start += BLOCK_CI

    # Write back accumulated outputs
    out_DHW = D_out * H_out * W_out
    out_stride_spatial = 1
    out_stride_c = out_DHW
    out_stride_n = C_out * out_stride_c

    base_out_n = n * out_stride_n
    base_group_co = g * C_out_per_group

    co_global = base_group_co + co_in_group  # [BLOCK_CO]
    out_idx = base_out_n + co_global[:, None] * out_stride_c + ow_offsets[None, :] * out_stride_spatial

    store_mask = mask_co[:, None] & mask_ow[None, :]
    tl.store(out_ptr + out_idx, acc, mask=store_mask)


def conv_transpose3d_triton(
    x: torch.Tensor,
    weight: torch.Tensor,
    bias: torch.Tensor,
    stride,
    padding,
    output_padding,
    dilation,
    groups: int,
) -> torch.Tensor:
    """
    x:       [N, C_in, D_in, H_in, W_in]
    weight:  [C_in, C_out_per_group, KD, KH, KW] (ConvTranspose3d layout)
    bias:    [C_out] or None
    """
    assert x.is_cuda and weight.is_cuda, "Triton kernel requires CUDA tensors"
    assert x.dtype == weight.dtype == torch.float32, "Kernel currently supports float32 only"

    x = x.contiguous()
    weight = weight.contiguous()

    N, C_in, D_in, H_in, W_in = x.shape
    C_in_w, C_out_per_group, KD, KH, KW = weight.shape
    assert C_in_w == C_in, "Input channels mismatch between input and weight"

    # Normalize parameters to 3D tuples
    if isinstance(stride, int):
        stride = (stride, stride, stride)
    if isinstance(padding, int):
        padding = (padding, padding, padding)
    if isinstance(output_padding, int):
        output_padding = (output_padding, output_padding, output_padding)
    if isinstance(dilation, int):
        dilation = (dilation, dilation, dilation)

    stride_d, stride_h, stride_w = stride
    pad_d, pad_h, pad_w = padding
    out_pad_d, out_pad_h, out_pad_w = output_padding
    dil_d, dil_h, dil_w = dilation

    C_out = C_out_per_group * groups

    # Output shape (PyTorch ConvTranspose3d formula)
    D_out = (D_in - 1) * stride_d - 2 * pad_d + dil_d * (KD - 1) + out_pad_d + 1
    H_out = (H_in - 1) * stride_h - 2 * pad_h + dil_h * (KH - 1) + out_pad_h + 1
    W_out = (W_in - 1) * stride_w - 2 * pad_w + dil_w * (KW - 1) + out_pad_w + 1

    # Allocate output
    out = torch.empty(
        (N, C_out, D_out, H_out, W_out),
        device=x.device,
        dtype=x.dtype,
    )

    C_in_per_group = C_in // groups
    C_out_per_group = C_out // groups
    DHW_out = D_out * H_out * W_out

    # Grid: (N * groups, cdiv(C_out_per_group, BLOCK_CO), cdiv(DHW_out, BLOCK_OW))
    def grid(meta):
        return (
            N * groups,
            triton.cdiv(C_out_per_group, meta['BLOCK_CO']),
            triton.cdiv(DHW_out, meta['BLOCK_OW']),
        )

    conv_transpose3d_kernel[grid](
        x, weight, out,
        N, C_in,
        D_in, H_in, W_in,
        C_out,
        groups,
        C_in_per_group,
        C_out_per_group,
        stride_d, stride_h, stride_w,
        pad_d, pad_h, pad_w,
        dil_d, dil_h, dil_w,
        D_out, H_out, W_out,
        KD=KD,
        KH=KH,
        KW=KW,
    )

    # Add bias (if any)
    if bias is not None:
        out += bias.view(1, C_out, 1, 1, 1)

    return out


class ModelNew(nn.Module):
    """
    Triton-accelerated replacement for ConvTranspose3d using a high-performance kernel.
    """
    def __init__(
        self,
        in_channels: int,
        out_channels: int,
        kernel_size: int,
        stride: int = 1,
        padding: int = 0,
        output_padding: int = 0,
        dilation: int = 1,
        groups: int = 1,
        bias: bool = False,
    ) -> None:
        super().__init__()
        self.conv_transpose3d = nn.ConvTranspose3d(
            in_channels,
            out_channels,
            (kernel_size, kernel_size, kernel_size),
            stride=stride,
            padding=padding,
            output_padding=output_padding,
            dilation=dilation,
            groups=groups,
            bias=bias,
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        w = self.conv_transpose3d.weight
        b = self.conv_transpose3d.bias
        stride = self.conv_transpose3d.stride
        padding = self.conv_transpose3d.padding
        output_padding = self.conv_transpose3d.output_padding
        dilation = self.conv_transpose3d.dilation
        groups = self.conv_transpose3d.groups

        return conv_transpose3d_triton(
            x,
            w,
            b,
            stride=stride,
            padding=padding,
            output_padding=output_padding,
            dilation=dilation,
            groups=groups,
        )
```