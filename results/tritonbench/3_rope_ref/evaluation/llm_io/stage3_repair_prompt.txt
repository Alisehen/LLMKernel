Fix the Triton kernel errors. Generate correct code.

## ERROR LOG
```
Traceback (most recent call last):
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 644, in compare_and_bench
    raise ValueError(
ValueError: Outputs are not close (atol=1, rtol=1). max_abs_err=nan, mean_abs_err=nan
```

## Broken Code
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.autotune(
    configs=[
        # Baseline, conservative
        triton.Config({"BLOCK_D": 64}, num_warps=4, num_stages=2),
        # Larger tile, still conservative
        triton.Config({"BLOCK_D": 128}, num_warps=4, num_stages=2),
        # More warps for better latency hiding when registers allow
        triton.Config({"BLOCK_D": 128}, num_warps=8, num_stages=2),
        # For small D or very light register pressure
        triton.Config({"BLOCK_D": 64}, num_warps=8, num_stages=2),
    ],
    key=["HALF_D"],  # RoPE cost is dominated by the head dimension
)
@triton.jit
def rope_kernel_inplace(
    q_ptr, k_ptr, cos_ptr, sin_ptr,
    BH, S, D, HALF_D,
    stride_q0, stride_q1, stride_q2,
    stride_k0, stride_k1, stride_k2,
    stride_cos0, stride_cos1,
    stride_sin0, stride_sin1,
    BLOCK_D: tl.constexpr,
):
    """
    In-place RoPE kernel.

    Layouts:
      q, k:    (BH, S, D)      strides (stride_q0, stride_q1, stride_q2)
      cos/sin: (S, HALF_D)     strides (stride_cos0, stride_cos1)

    Grid:
      pid_bh      in [0, BH)
      pid_s       in [0, S)
      pid_block_d in [0, ceil_div(HALF_D, BLOCK_D))

    All fused ops share:
      offs_d  = pid_block_d * BLOCK_D + tl.arange(0, BLOCK_D)
      mask_d  = offs_d < HALF_D

    Fusion rules respected:
      - Multiple tl.load() from q/k/cos/sin
      - Only final tl.store() to q/k (no intermediate stores)
    """
    pid_bh = tl.program_id(0)
    pid_s = tl.program_id(1)
    pid_block_d = tl.program_id(2)

    # Offsets along HALF_D dimension
    offs_d = pid_block_d * BLOCK_D + tl.arange(0, BLOCK_D)
    mask = offs_d < HALF_D

    # Help the compiler generate better vectorized memory ops
    tl.multiple_of(offs_d, BLOCK_D)

    # Base offsets for q/k for this (bh, s)
    q_base = pid_bh * stride_q0 + pid_s * stride_q1
    k_base = pid_bh * stride_k0 + pid_s * stride_k1

    # q/k pointers: first and second halves along D
    q1_ptrs = q_ptr + q_base + offs_d * stride_q2
    q2_ptrs = q1_ptrs + HALF_D * stride_q2

    k1_ptrs = k_ptr + k_base + offs_d * stride_k2
    k2_ptrs = k1_ptrs + HALF_D * stride_k2

    # cos/sin pointers: shared across BH, vary only with (s, d)
    cos_ptrs = cos_ptr + pid_s * stride_cos0 + offs_d * stride_cos1
    sin_ptrs = sin_ptr + pid_s * stride_sin0 + offs_d * stride_sin1

    # Loads (all into registers, no intermediate stores)
    q1 = tl.load(q1_ptrs, mask=mask, other=0.0)
    q2 = tl.load(q2_ptrs, mask=mask, other=0.0)
    k1 = tl.load(k1_ptrs, mask=mask, other=0.0)
    k2 = tl.load(k2_ptrs, mask=mask, other=0.0)

    cos_vals = tl.load(cos_ptrs, mask=mask, other=0.0)
    sin_vals = tl.load(sin_ptrs, mask=mask, other=0.0)

    # RoPE rotation in registers
    # [x1, x2] -> [x1*cos - x2*sin, x2*cos + x1*sin]
    q_rot1 = q1 * cos_vals - q2 * sin_vals
    q_rot2 = q2 * cos_vals + q1 * sin_vals

    k_rot1 = k1 * cos_vals - k2 * sin_vals
    k_rot2 = k2 * cos_vals + k1 * sin_vals

    # Final stores only (no store-then-load patterns)
    tl.store(q1_ptrs, q_rot1, mask=mask)
    tl.store(q2_ptrs, q_rot2, mask=mask)
    tl.store(k1_ptrs, k_rot1, mask=mask)
    tl.store(k2_ptrs, k_rot2, mask=mask)


def rope_triton(q: torch.Tensor, k: torch.Tensor,
                cos: torch.Tensor, sin: torch.Tensor):
    """
    High-performance Triton implementation of RoPE.

    Inputs:
      q, k:      (B, H, S, D)
      cos, sin:  (S, D//2)

    Returns:
      q_rot, k_rot: (B, H, S, D)
      cos_trunc, sin_trunc: (S, D//2)
    """
    assert q.is_cuda and k.is_cuda and cos.is_cuda and sin.is_cuda
    assert q.dtype == k.dtype == cos.dtype == sin.dtype
    assert q.ndim == 4 and k.ndim == 4

    B, H, S, D = q.shape
    assert D % 2 == 0
    HALF_D = D // 2

    # Flatten (B, H, S, D) -> (BH, S, D) and enforce contiguous for stride assumptions
    BH = B * H
    assert BH > 0 and S > 0

    q_flat = q.contiguous().view(BH, S, D)
    k_flat = k.contiguous().view(BH, S, D)

    # Match PyTorch reference truncation/broadcast semantics
    cos_trunc = cos[:S, :HALF_D].contiguous()
    sin_trunc = sin[:S, :HALF_D].contiguous()

    # Grid:
    #   axis 0: BH
    #   axis 1: S
    #   axis 2: HALF_D / BLOCK_D (decided by autotune config)
    def grid(meta):
        block_d = meta["BLOCK_D"]
        return (
            BH,
            S,
            triton.cdiv(HALF_D, block_d),
        )

    # Launch autotuned kernel, no manual num_warps/num_stages needed
    rope_kernel_inplace[grid](
        q_flat, k_flat, cos_trunc, sin_trunc,
        BH, S, D, HALF_D,
        q_flat.stride(0), q_flat.stride(1), q_flat.stride(2),
        k_flat.stride(0), k_flat.stride(1), k_flat.stride(2),
        cos_trunc.stride(0), cos_trunc.stride(1),
        sin_trunc.stride(0), sin_trunc.stride(1),
    )

    # q_flat / k_flat have been rotated in-place
    q_rot = q_flat.view(B, H, S, D)
    k_rot = k_flat.view(B, H, S, D)

    return q_rot, k_rot, cos_trunc, sin_trunc


class ModelNew(nn.Module):
    """
    Triton-optimized RoPE module (autotuned for RTX 4090).

    forward(q, k, cos, sin) -> (q_rotated, k_rotated, cos_out, sin_out)

    Shapes:
      q, k:      (B, H, S, D)
      cos, sin:  (S, D//2)
    """
    def __init__(self):
        super(ModelNew, self).__init__()

    def forward(self, q, k, cos, sin):
        # Ensure q/k are on the same device as cos/sin
        dev = cos.device
        if q.device != dev:
            q = q.to(device=dev, non_blocking=True)
        if k.device != dev:
            k = k.to(device=dev, non_blocking=True)

        q_rot, k_rot, cos_out, sin_out = rope_triton(q, k, cos, sin)
        return q_rot, k_rot, cos_out, sin_out
```

## CRITICAL — These cause 60%+ of failures:
1. EVERY kernel function MUST have `@triton.jit` decorator — MANDATORY
2. Grid size MUST be > 0: use `triton.cdiv(N, BLOCK)` or `max(1, N // BLOCK)`
3. BLOCK sizes MUST be power-of-2: 16, 32, 64, 128, 256
4. `tl.program_id(axis)` only supports axis = 0, 1, 2
5. No `continue`, `break`, `return` inside loops — use masking
6. No tensor indexing with loop vars: `x[:, i]` is INVALID
7. mask shape MUST match data shape in tl.load/tl.store

## Missing Triton Functions (implement manually):
- tl.tanh, tl.sigmoid, tl.gelu, tl.silu, tl.softmax, tl.mish

## OUTPUT FORMAT (STRICT):
1. Imports: torch, torch.nn, triton, triton.language as tl (and math if needed)
2. @triton.jit decorated kernel function(s)
3. Wrapper function(s) for grid calculation and kernel launch
4. class ModelNew(nn.Module) — REQUIRED

Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <corrected code>
```
