You are optimizing a Triton kernel based on algorithmic analysis.

# PyTorch Reference (Target Behavior)

```python
import torch
import torch.nn as nn

class Model(nn.Module):
    """
    RoPE (Rotary Position Embedding) - PyTorch Reference Implementation

    Rotary Position Embedding applies a rotation to the query and key vectors
    based on their position in the sequence. This allows the model to naturally
    encode relative positions.

    Formula:
        For each position, split the embedding into two halves [x1, x2]
        Apply rotation: [x1*cos - x2*sin, x2*cos + x1*sin]

    Used in: LLaMA, GPT-J, GPT-NeoX, PaLM, and many modern LLMs
    """
    def __init__(self):
        super(Model, self).__init__()

    def forward(self, q, k, cos, sin):
        """
        Apply RoPE to query and key tensors.

        Args:
            q (torch.Tensor): Query tensor of shape (batch, n_heads, seq_len, head_dim)
            k (torch.Tensor): Key tensor of shape (batch, n_heads, seq_len, head_dim)
            cos (torch.Tensor): Cosine values of shape (seq_len, head_dim//2)
            sin (torch.Tensor): Sine values of shape (seq_len, head_dim//2)

        Returns:
            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
                - q_rotated: Rotated query (batch, n_heads, seq_len, head_dim)
                - k_rotated: Rotated key (batch, n_heads, seq_len, head_dim)
                - cos: Cosine values (unchanged)
                - sin: Sine values (unchanged)
        """
        # Transpose to (batch, seq_len, n_heads, head_dim) for easier position-wise operation
        q = q.transpose(1, 2)
        k = k.transpose(1, 2)

        batch_size, seq_len, n_heads, head_dim = q.shape
        half_dim = head_dim // 2

        # Split into two halves along head_dim
        q1 = q[..., :half_dim]  # First half
        q2 = q[..., half_dim:]  # Second half
        k1 = k[..., :half_dim]
        k2 = k[..., half_dim:]

        # Reshape cos/sin for broadcasting: (seq_len, head_dim//2) -> (1, seq_len, 1, head_dim//2)
        cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(2)
        sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(2)

        # Apply rotation transformation
        # RoPE formula: rotate_half([x1, x2]) = [x1*cos - x2*sin, x2*cos + x1*sin]
        q_rotated = torch.cat([
            q1 * cos - q2 * sin,  # New first half
            q2 * cos + q1 * sin   # New second half
        ], dim=-1)

        k_rotated = torch.cat([
            k1 * cos - k2 * sin,
            k2 * cos + k1 * sin
        ], dim=-1)

        # Transpose back to (batch, n_heads, seq_len, head_dim)
        q_rotated = q_rotated.transpose(1, 2)
        k_rotated = k_rotated.transpose(1, 2)

        # Return cos/sin as well to match Triton interface
        return q_rotated, k_rotated, cos.squeeze(0).squeeze(1), sin.squeeze(0).squeeze(1)


BATCH_SIZE = 2
N_HEADS = 8
SEQ_LEN = 4
HEAD_DIM = 16

def get_inputs():
    """
    Generate test inputs for RoPE.

    Returns:
        List containing [q, k, cos, sin]:
            - q: Query tensor (batch, n_heads, seq_len, head_dim)
            - k: Key tensor (batch, n_heads, seq_len, head_dim)
            - cos: Cosine values (seq_len, head_dim//2)
            - sin: Sine values (seq_len, head_dim//2)
    """
    q = torch.randn(BATCH_SIZE, N_HEADS, SEQ_LEN, HEAD_DIM, dtype=torch.float32)
    k = torch.randn(BATCH_SIZE, N_HEADS, SEQ_LEN, HEAD_DIM, dtype=torch.float32)
    cos = torch.randn(SEQ_LEN, HEAD_DIM // 2, dtype=torch.float32)
    sin = torch.randn(SEQ_LEN, HEAD_DIM // 2, dtype=torch.float32)
    return [q, k, cos, sin]

def get_init_inputs():
    """
    Get initialization parameters for Model.

    Returns:
        Empty list (no initialization parameters needed)
    """
    return []
```

**CRITICAL**: Study the PyTorch code carefully to understand:
- What does `forward()` return? (full output sequence vs final hidden state only)
- What is the computational pattern?
- What are the input/output shapes?

Your optimized kernel MUST match this exact behavior.

---

# Analysis Results

**Bottleneck**: The current Triton kernel materializes rotated Q/K in global memory, causing an additional pass over all Q/K data (loads of q/k + stores of q_rot/k_rot) and a separate launch, even though the rotation could be done on-the-fly where Q/K are actually consumed.

**Optimization Strategy**: Operator fusion: fuse the RoPE rotation directly into the QK^T attention kernel (or the Q/K projection + attention kernel), computing the rotation in registers as you load Q/K tiles, instead of having a dedicated RoPE kernel that produces q_rot/k_rot tensors.

**Implementation Plan**: Refactor the attention implementation so that the main attention matmul Triton kernel takes raw q, k, cos, sin as inputs. Inside that kernel, when loading a tile of q/k from global memory, immediately split into halves, apply the RoPE rotation using cos/sin for the current sequence positions, and use the rotated values directly in the QK^T dot-products without writing them back to global memory. Remove the standalone rope_triton/rope_kernel and adjust the Python side to no longer materialize intermediate q_rot/k_rot tensors.

**Expected Speedup**: 50-80% reduction of RoPE-specific overhead (roughly 2-4x vs the current standalone RoPE kernel), translating to around 10-20% speedup for the combined RoPE+attention block depending on model size and sequence length.

---

# Current Kernel (needs optimization)

```python
import torch, torch.nn as nn, triton, triton.language as tl


@triton.jit
def rope_kernel(
    q_ptr, k_ptr, cos_ptr, sin_ptr,
    q_out_ptr, k_out_ptr,
    BH, S, D, HALF_D,
    stride_q0, stride_q1, stride_q2,
    stride_k0, stride_k1, stride_k2,
    stride_qo0, stride_qo1, stride_qo2,
    stride_ko0, stride_ko1, stride_ko2,
    stride_cos0, stride_cos1,
    stride_sin0, stride_sin1,
    BLOCK_D: tl.constexpr,
):
    pid_bh = tl.program_id(0)
    pid_s = tl.program_id(1)
    pid_block_d = tl.program_id(2)

    offs_d = pid_block_d * BLOCK_D + tl.arange(0, BLOCK_D)

    mask_d = offs_d < HALF_D
    valid = (pid_bh < BH) & (pid_s < S)
    mask = mask_d & valid

    # Pointers for q halves
    q1_ptrs = q_ptr + pid_bh * stride_q0 + pid_s * stride_q1 + offs_d * stride_q2
    q2_ptrs = q_ptr + pid_bh * stride_q0 + pid_s * stride_q1 + (offs_d + HALF_D) * stride_q2

    # Pointers for k halves
    k1_ptrs = k_ptr + pid_bh * stride_k0 + pid_s * stride_k1 + offs_d * stride_k2
    k2_ptrs = k_ptr + pid_bh * stride_k0 + pid_s * stride_k1 + (offs_d + HALF_D) * stride_k2

    # Pointers for cos/sin
    cos_ptrs = cos_ptr + pid_s * stride_cos0 + offs_d * stride_cos1
    sin_ptrs = sin_ptr + pid_s * stride_sin0 + offs_d * stride_sin1

    # Load data
    q1 = tl.load(q1_ptrs, mask=mask, other=0.0)
    q2 = tl.load(q2_ptrs, mask=mask, other=0.0)
    k1 = tl.load(k1_ptrs, mask=mask, other=0.0)
    k2 = tl.load(k2_ptrs, mask=mask, other=0.0)

    cos_vals = tl.load(cos_ptrs, mask=mask, other=0.0)
    sin_vals = tl.load(sin_ptrs, mask=mask, other=0.0)

    # RoPE rotation
    q_rot1 = q1 * cos_vals - q2 * sin_vals
    q_rot2 = q2 * cos_vals + q1 * sin_vals

    k_rot1 = k1 * cos_vals - k2 * sin_vals
    k_rot2 = k2 * cos_vals + k1 * sin_vals

    # Pointers for output q halves
    qo1_ptrs = q_out_ptr + pid_bh * stride_qo0 + pid_s * stride_qo1 + offs_d * stride_qo2
    qo2_ptrs = q_out_ptr + pid_bh * stride_qo0 + pid_s * stride_qo1 + (offs_d + HALF_D) * stride_qo2

    # Pointers for output k halves
    ko1_ptrs = k_out_ptr + pid_bh * stride_ko0 + pid_s * stride_ko1 + offs_d * stride_ko2
    ko2_ptrs = k_out_ptr + pid_bh * stride_ko0 + pid_s * stride_ko1 + (offs_d + HALF_D) * stride_ko2

    # Store results
    tl.store(qo1_ptrs, q_rot1, mask=mask)
    tl.store(qo2_ptrs, q_rot2, mask=mask)
    tl.store(ko1_ptrs, k_rot1, mask=mask)
    tl.store(ko2_ptrs, k_rot2, mask=mask)


def rope_triton(q: torch.Tensor, k: torch.Tensor,
                cos: torch.Tensor, sin: torch.Tensor):
    """
    High-performance Triton implementation of RoPE.

    q, k: (B, H, S, D)
    cos, sin: (S, D//2)
    """
    assert q.is_cuda and k.is_cuda and cos.is_cuda and sin.is_cuda
    assert q.dtype == k.dtype == cos.dtype == sin.dtype
    assert q.ndim == 4 and k.ndim == 4
    B, H, S, D = q.shape
    assert D % 2 == 0
    HALF_D = D // 2

    # Flatten (B, H, S, D) -> (BH, S, D) for simpler indexing
    BH = B * H
    q_flat = q.contiguous().view(BH, S, D)
    k_flat = k.contiguous().view(BH, S, D)

    # Outputs
    q_out_flat = torch.empty_like(q_flat)
    k_out_flat = torch.empty_like(k_flat)

    # Truncate/broadcast cos/sin exactly like reference
    cos_trunc = cos[:S, :HALF_D].contiguous()
    sin_trunc = sin[:S, :HALF_D].contiguous()

    grid = lambda META: (
        BH,
        S,
        triton.cdiv(HALF_D, META["BLOCK_D"]),
    )

    rope_kernel[grid](
        q_flat, k_flat, cos_trunc, sin_trunc,
        q_out_flat, k_out_flat,
        BH, S, D, HALF_D,
        q_flat.stride(0), q_flat.stride(1), q_flat.stride(2),
        k_flat.stride(0), k_flat.stride(1), k_flat.stride(2),
        q_out_flat.stride(0), q_out_flat.stride(1), q_out_flat.stride(2),
        k_out_flat.stride(0), k_out_flat.stride(1), k_out_flat.stride(2),
        cos_trunc.stride(0), cos_trunc.stride(1),
        sin_trunc.stride(0), sin_trunc.stride(1),
        BLOCK_D=64,
    )

    # Restore original shape (B, H, S, D)
    q_rot = q_out_flat.view(B, H, S, D)
    k_rot = k_out_flat.view(B, H, S, D)

    return q_rot, k_rot, cos_trunc, sin_trunc


class ModelNew(nn.Module):
    """
    Triton-optimized RoPE module: replaces the PyTorch RoPE in Model.
    """
    def __init__(self):
        super(ModelNew, self).__init__()

    def forward(self, q, k, cos, sin):
        # Inputs are expected in shape (batch, n_heads, seq_len, head_dim)
        # and cos/sin in (seq_len, head_dim//2), matching the reference.
        q_rot, k_rot, cos_out, sin_out = rope_triton(
            q.to(device=cos.device),
            k.to(device=cos.device),
            cos,
            sin,
        )
        return q_rot, k_rot, cos_out, sin_out
```

---

# Your Task

Implement the optimization strategy above. Focus on the specific bottleneck identified.

## Key Requirements

1. **Preserve correctness**: Maintain the same input/output behavior
2. **Apply the optimization**: Follow the implementation plan exactly
3. **Use valid Triton syntax**:
   - Every kernel MUST have `@triton.jit` decorator
   - Grid size MUST be > 0: use `triton.cdiv(N, BLOCK)` or `max(1, N // BLOCK)`
   - BLOCK sizes MUST be power-of-2: 16, 32, 64, 128, 256
   - No `continue`, `break`, `return` inside kernels (use masking)
   - Prefer `tl.dot(a, b, allow_tf32=True)` for matmul operations

4. **CRITICAL for RNN/GRU/LSTM Persistent Kernels**:
   - Time loop MUST be inside @triton.jit kernel, NOT in Python forward()
   - **HYBRID computation strategy** (CRITICAL for performance):
     * Precompute input-side gates OUTSIDE kernel: `gates_x = (T*B, In) @ W_ih` (ONE large GEMM)
     * INSIDE kernel: only recurrent-side: `for t: gates_h = h @ W_hh` (T small GEMMs)
   - CORRECT (FAST - use this):
     ```python
     # Python forward():
     gates_x_all = x.reshape(T*B, In) @ W_ih + b_ih  # ONE large GEMM
     gates_x_all = gates_x_all.view(T, B, 3*H)
     gru_persistent_kernel[grid](gates_x_all, h0, W_hh, ...)  # Launch ONCE

     @triton.jit
     def gru_persistent_kernel(gates_x_ptr, h_ptr, W_hh_ptr, ...):
         for t in range(T):  # Inside kernel
             gates_x_t = tl.load(gates_x_ptr + t*...)  # Precomputed
             gates_h = h @ W_hh  # Only recurrent GEMM
             h = (1-z)*n + z*h   # Fuse and update
     ```

5. **Output format**:
   - Imports: `import torch, torch.nn as nn, triton, triton.language as tl`
   - `@triton.jit` kernel(s)
   - Wrapper function(s)
   - `class ModelNew(nn.Module)` â€” REQUIRED
   - NO testing code, NO `if __name__ == "__main__"`

---

Generate the optimized kernel now. Output ONLY the complete Python code.
