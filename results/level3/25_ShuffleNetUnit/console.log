[Seed] Generating seed kernel...
[Seed 1/2] Generating...
[92mFinish reason: stop[0m
Usage: In=2258, Out=18107, Total=20365
[seed_0] score=1.3445 (baseline=21.3571ms)
[seed_0] metrics saved to: /home/hyc/LLMKernel/run/20251224_025836_25_ShuffleNetUnit_openai_deepseek/25_ShuffleNetUnit/evaluation/eval_0000.json
[Seed 1] Final score: 1.3445 âœ“
[Seed] Early stop: seed 1 already beats PyTorch (1.3445 >= 1.0)
[Seed] Skipping remaining 1 seed(s)
[Seed] Will proceed to algorithm analysis to attempt further optimization

================================================================================
[Hybrid Strategy] Analyzing all seeds for algorithmic optimization...
[Hybrid Strategy] - 1 seed(s) with score >= 1.0 (further optimization)
================================================================================

[Hybrid] Seed 1: score=1.3445 >= 1.0
[Hybrid] Attempting algorithm analysis for further optimization...
[Hybrid] Requesting LLM analysis for seed 1...
[92mFinish reason: stop[0m
Usage: In=5733, Out=1079, Total=6812
[Hybrid] Worth optimizing: yes
[Hybrid] Reason: A full-tensor channel_shuffle kernel sits between depthwise and 1x1 group conv, adding an extra global read/write and launch that can be eliminated algebraically.
[Hybrid] Analysis complete for seed 1, generating optimized kernel...
[Hybrid] Bottleneck: The current pipeline does `depthwise_conv3x3 -> channel_shuffle -> 1x1 group con...
[Hybrid] Optimization: Eliminate the explicit ChannelShuffle kernel by folding the shuffle permutation ...
[Hybrid] Expected speedup: 20-25%
[92mFinish reason: stop[0m
Usage: In=6115, Out=19936, Total=26051
[algorithm_optimized_seed0] score=1.3014 (baseline=21.3571ms)
[algorithm_optimized_seed0] metrics saved to: /home/hyc/LLMKernel/run/20251224_025836_25_ShuffleNetUnit_openai_deepseek/25_ShuffleNetUnit/evaluation/eval_0001.json
[Hybrid] âœ“ Rescue successful: 1.3445 â†’ 1.3014

================================================================================
[Hybrid] Candidate Selection
================================================================================
[Hybrid] Total candidates: 2
  [1] seed 1: 1.3445
  [2] algo-optimized (from seed 1): 1.3014

[Hybrid] â˜… Selected best candidate: score=1.3445

[Optimization] Starting 3-stage optimization...

================================================================================
[Stage 1/3] grid_and_parallel
Description: Optimize grid layout and parallel work distribution across SMs.
Current candidates: 1, best score: 1.3445
================================================================================
[Stage 1] Profiling best candidate...
[Stage 1] Generating optimized kernel...
[92mFinish reason: stop[0m
Usage: In=4867, Out=9597, Total=14464
[91mTest Error (RuntimeError):[0m Traceback (most recent call last):
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py", line 43, in wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py", line 2126, in load
    return _semantic.load(pointer, mask, other, boundary_check, padding_option, cache_modifier, eviction_policy,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/semantic.py", line 1089, in load
    return self._load_legacy(ptr, mask, other, boundary_check, padding, cache, eviction, is_volatile)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/semantic.py", line 1020, in _load_legacy
    raise ValueError(f"Unsupported ptr type {ptr.type.__repr__()} in `tl.load`")
ValueError: Unsupported ptr type <['32', '64'], int32> in `tl.load`

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 554, in compare_and_bench
    test_out, _ = _run_once(test_model, inp, dev)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/utils/compile_and_run.py", line 132, in _run_once
    out = model(*inp)
          ^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/run/20251224_025836_25_ShuffleNetUnit_openai_deepseek/25_ShuffleNetUnit/code/kernel_20251224_030418.py", line 590, in forward
    out = depthwise_conv3x3_bn_triton(out, self.conv2, self.bn2)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/LLMKernel/run/20251224_025836_25_ShuffleNetUnit_openai_deepseek/25_ShuffleNetUnit/code/kernel_20251224_030418.py", line 368, in depthwise_conv3x3_bn_triton
    depthwise_conv3x3_bn_kernel[grid](
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 419, in <lambda>
    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 733, in run
    kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py", line 861, in _do_compile
    kernel = self.compile(src, target=target, options=options.__dict__)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py", line 300, in compile
    module = src.make_ir(target, options, codegen_fns, module_map, context)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py", line 80, in make_ir
    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
triton.compiler.errors.CompilationError: at 77:20:
        row_offset = dh * stride_xh

        for dw in range(-1, 2):
            iw = w_idx[None, :] + dw
            mask_w = (iw >= 0) & (iw < W)

            m = out_mask & mask_h & mask_w

            col_offset = dw * stride_xw
            x_ptrs = x_center + row_offset + col_offset

            x_val = tl.load(x_ptrs, mask=m, other=0.0)
                    ^
Unsupported ptr type <['32', '64'], int32> in `tl.load`

[stage1_grid_and_parallel] failed. See metrics.message for details.
[stage1_grid_and_parallel] metrics saved to: /home/hyc/LLMKernel/run/20251224_025836_25_ShuffleNetUnit_openai_deepseek/25_ShuffleNetUnit/evaluation/eval_0002.json
  Optimization failed, attempting repair...
[92mFinish reason: stop[0m
Usage: In=6948, Out=8424, Total=15372
[stage1_grid_and_parallel_repair] score=1.3452 (baseline=21.3571ms)
[stage1_grid_and_parallel_repair] metrics saved to: /home/hyc/LLMKernel/run/20251224_025836_25_ShuffleNetUnit_openai_deepseek/25_ShuffleNetUnit/evaluation/eval_0003.json
  Optimized kernel score: 1.3452 âœ“
[Stage 1] â˜… New best score: 1.3452

================================================================================
[Stage 2/3] block_tiling
Description: Tune BLOCK_M/N/K sizes for optimal register/memory balance.
Current candidates: 1, best score: 1.3452
================================================================================
[Stage 2] Profiling best candidate...
[Stage 2] Generating optimized kernel...
[92mFinish reason: stop[0m
Usage: In=6027, Out=8495, Total=14522
[stage2_block_tiling] score=1.3443 (baseline=21.3571ms)
[stage2_block_tiling] metrics saved to: /home/hyc/LLMKernel/run/20251224_025836_25_ShuffleNetUnit_openai_deepseek/25_ShuffleNetUnit/evaluation/eval_0004.json
  Optimized kernel score: 1.3443 âœ“
[Stage 2] Current: 1.3443 (global best: 1.3452)

================================================================================
[Stage 3/3] memory_and_tuning
Description: Optimize memory access patterns and fine-tune num_stages/num_warps.
Current candidates: 1, best score: 1.3452
================================================================================
[Stage 3] Profiling best candidate...
[Stage 3] Generating optimized kernel...
