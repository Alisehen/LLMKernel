```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


# -----------------------------
# 1x1 Group Convolution + BatchNorm (+ optional ReLU)
# -----------------------------
@triton.jit
def conv1x1_group_bn_relu_kernel(
    x_ptr, w_ptr,
    running_mean_ptr, running_var_ptr,
    bn_weight_ptr, bn_bias_ptr,
    y_ptr,
    B, H, W,
    Cin_g, Cout_g,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_yn, stride_yc, stride_yh, stride_yw,
    eps,
    RELU: tl.constexpr,
    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,
):
    pid_m = tl.program_id(0)  # over B*H*W
    pid_n = tl.program_id(1)  # over Cout/group
    pid_g = tl.program_id(2)  # group index

    BHW = B * H * W
    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    mask_m = offs_m < BHW

    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
    mask_n = offs_n < Cout_g

    # Map linear position -> (b, h, w)
    bhw = H * W
    b = offs_m // bhw
    rem = offs_m % bhw
    h_idx = rem // W
    w_idx = rem % W

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    # Loop over Cin/group in tiles of BLOCK_K
    for k in range(0, Cin_g, BLOCK_K):
        offs_k = k + tl.arange(0, BLOCK_K)
        mask_k = offs_k < Cin_g

        # Input pointers: x[b, g*Cin_g + k, h, w]
        bc_base = (b * stride_xn) + (h_idx * stride_xh) + (w_idx * stride_xw) + (pid_g * Cin_g) * stride_xc
        a_ptrs = x_ptr + bc_base[:, None] + offs_k[None, :] * stride_xc
        a = tl.load(a_ptrs, mask=mask_m[:, None] & mask_k[None, :], other=0.0)

        # Weight pointers: w[g, k, n] -> flatten as [(g*Cin_g + k)*Cout_g + n]
        w_ptrs = w_ptr + (pid_g * Cin_g + offs_k[:, None]) * Cout_g + offs_n[None, :]
        b_mat = tl.load(w_ptrs, mask=mask_k[:, None] & mask_n[None, :], other=0.0)

        acc += tl.dot(a, b_mat, allow_tf32=True)

    # BatchNorm per output channel
    oc = pid_g * Cout_g + offs_n  # global out-channel indices
    mean = tl.load(running_mean_ptr + oc, mask=mask_n, other=0.0)
    var = tl.load(running_var_ptr + oc, mask=mask_n, other=0.0)
    gamma = tl.load(bn_weight_ptr + oc, mask=mask_n, other=1.0)
    beta = tl.load(bn_bias_ptr + oc, mask=mask_n, other=0.0)

    inv_std = 1.0 / tl.sqrt(var + eps)
    scale = gamma * inv_std

    acc = (acc - mean[None, :]) * scale[None, :] + beta[None, :]

    if RELU:
        acc = tl.maximum(acc, 0.0)

    # Store: y[b, oc, h, w]
    bc_base_out = (b * stride_yn) + (h_idx * stride_yh) + (w_idx * stride_yw)
    y_ptrs = y_ptr + bc_base_out[:, None] + (pid_g * Cout_g + offs_n[None, :]) * stride_yc
    tl.store(y_ptrs, acc, mask=mask_m[:, None] & mask_n[None, :])


def conv1x1_group_bn_relu_triton(x: torch.Tensor,
                                 conv: nn.Conv2d,
                                 bn: nn.BatchNorm2d,
                                 relu: bool = True) -> torch.Tensor:
    """
    Fused 1x1 group convolution + BatchNorm (+ optional ReLU).
    conv: Conv2d with kernel_size=1, padding=0, stride=1, arbitrary groups.
    bn:   BatchNorm2d applied after conv (inference-mode semantics).
    """
    assert x.is_cuda, "Triton kernels require CUDA tensors"
    assert x.dim() == 4
    B, Cin, H, W = x.shape
    weight = conv.weight  # [Cout, Cin_g, 1, 1]
    Cout, Cin_g, kh, kw = weight.shape
    assert kh == 1 and kw == 1
    groups = conv.groups
    assert Cin % groups == 0
    assert Cout % groups == 0
    Cout_g = Cout // groups

    # Re-layout weight as [groups, Cin_g, Cout_g] contiguous, then use [K, N] per group.
    w_mat = weight.view(groups, Cout_g, Cin_g).permute(0, 2, 1).contiguous()

    running_mean = bn.running_mean
    running_var = bn.running_var
    if bn.weight is not None:
        bn_weight = bn.weight
    else:
        bn_weight = torch.ones_like(running_mean)
    if bn.bias is not None:
        bn_bias = bn.bias
    else:
        bn_bias = torch.zeros_like(running_mean)

    y = torch.empty((B, Cout, H, W), device=x.device, dtype=x.dtype)

    BLOCK_M = 64
    BLOCK_N = 64
    BLOCK_K = 32

    grid = (
        triton.cdiv(B * H * W, BLOCK_M),
        triton.cdiv(Cout_g, BLOCK_N),
        groups,
    )

    conv1x1_group_bn_relu_kernel[grid](
        x, w_mat,
        running_mean, running_var,
        bn_weight, bn_bias,
        y,
        B, H, W,
        Cin_g, Cout_g,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        bn.eps,
        RELU=relu,
        BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K,
    )
    return y


# -----------------------------
# 1x1 Dense Convolution (Shuffle folded) + BatchNorm (+ optional ReLU)
# -----------------------------
@triton.jit
def conv1x1_dense_bn_relu_kernel(
    x_ptr, w_ptr,
    running_mean_ptr, running_var_ptr,
    bn_weight_ptr, bn_bias_ptr,
    y_ptr,
    B, H, W,
    Cin, Cout,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_yn, stride_yc, stride_yh, stride_yw,
    eps,
    RELU: tl.constexpr,
    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,
):
    pid_m = tl.program_id(0)  # over B*H*W
    pid_n = tl.program_id(1)  # over Cout

    BHW = B * H * W
    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    mask_m = offs_m < BHW

    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)
    mask_n = offs_n < Cout

    # Map linear position -> (b, h, w)
    bhw = H * W
    b = offs_m // bhw
    rem = offs_m % bhw
    h_idx = rem // W
    w_idx = rem % W

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    # GEMM over Cin
    for k in range(0, Cin, BLOCK_K):
        offs_k = k + tl.arange(0, BLOCK_K)
        mask_k = offs_k < Cin

        # Input tile: x[b, k, h, w]
        bc_base = (b * stride_xn) + (h_idx * stride_xh) + (w_idx * stride_xw)
        a_ptrs = x_ptr + bc_base[:, None] + offs_k[None, :] * stride_xc
        a = tl.load(a_ptrs, mask=mask_m[:, None] & mask_k[None, :], other=0.0)

        # Weight tile: w[k, n] ; w_ptr is [Cin, Cout] with Cout contiguous
        w_ptrs = w_ptr + offs_k[:, None] * Cout + offs_n[None, :]
        b_mat = tl.load(w_ptrs, mask=mask_k[:, None] & mask_n[None, :], other=0.0)

        acc += tl.dot(a, b_mat, allow_tf32=True)

    # BatchNorm per output channel
    mean = tl.load(running_mean_ptr + offs_n, mask=mask_n, other=0.0)
    var = tl.load(running_var_ptr + offs_n, mask=mask_n, other=0.0)
    gamma = tl.load(bn_weight_ptr + offs_n, mask=mask_n, other=1.0)
    beta = tl.load(bn_bias_ptr + offs_n, mask=mask_n, other=0.0)

    inv_std = 1.0 / tl.sqrt(var + eps)
    scale = gamma * inv_std

    acc = (acc - mean[None, :]) * scale[None, :] + beta[None, :]

    if RELU:
        acc = tl.maximum(acc, 0.0)

    # Store y[b, oc, h, w]
    bc_base_out = (b * stride_yn) + (h_idx * stride_yh) + (w_idx * stride_yw)
    y_ptrs = y_ptr + bc_base_out[:, None] + offs_n[None, :] * stride_yc
    tl.store(y_ptrs, acc, mask=mask_m[:, None] & mask_n[None, :])


def conv1x1_dense_from_shuffled_triton(
    x: torch.Tensor,
    conv: nn.Conv2d,
    bn: nn.BatchNorm2d,
    groups: int,
    relu: bool = True,
) -> torch.Tensor:
    """
    Fused 1x1 convolution that is equivalent to:
        out = conv(shuffle(x))
    where `conv` is a 1x1 group convolution and `shuffle` is ChannelShuffle(groups).

    We form a dense weight matrix W' that folds the channel shuffle into the
    input dimension of conv's weights, then apply a single dense 1x1 conv + BN (+ReLU).

    This avoids materializing the shuffled tensor and removes an extra kernel.
    """
    assert x.is_cuda, "Triton kernels require CUDA tensors"
    assert x.dim() == 4
    B, Cin, H, W = x.shape

    weight = conv.weight  # [Cout, Cin_g, 1, 1]
    Cout, Cin_g, kh, kw = weight.shape
    assert kh == 1 and kw == 1
    assert Cin == Cin_g * groups, "Input channels must equal conv.in_channels"
    assert conv.groups == groups
    assert Cout % groups == 0
    Cout_g = Cout // groups

    device = weight.device
    dtype = weight.dtype

    # Build full [Cout, Cin] matrix for the group conv (block-diagonal)
    W_full = weight.new_zeros((Cout, Cin))
    for g in range(groups):
        oc_start = g * Cout_g
        ic_start = g * Cin_g
        W_full[oc_start:oc_start + Cout_g, ic_start:ic_start + Cin_g] = \
            weight[oc_start:oc_start + Cout_g, :, 0, 0]

    # ChannelShuffle permutation P: given original channel i, its shuffled index is:
    #   g_in = i // Cg, k = i % Cg, P(i) = k * groups + g_in
    Cg = Cin // groups
    idx = torch.arange(Cin, device=device)
    g_in = idx // Cg
    k = idx % Cg
    perm = k * groups + g_in  # [Cin]

    # Fold shuffle into columns of W_full: W_perm[:, i] = W_full[:, P(i)]
    W_perm = W_full[:, perm]              # [Cout, Cin]
    w_mat = W_perm.transpose(0, 1).contiguous()  # [Cin, Cout], Cout contiguous

    running_mean = bn.running_mean
    running_var = bn.running_var
    if bn.weight is not None:
        bn_weight = bn.weight
    else:
        bn_weight = torch.ones_like(running_mean)
    if bn.bias is not None:
        bn_bias = bn.bias
    else:
        bn_bias = torch.zeros_like(running_mean)

    y = torch.empty((B, Cout, H, W), device=x.device, dtype=x.dtype)

    BLOCK_M = 64
    BLOCK_N = 64
    BLOCK_K = 32

    grid = (
        triton.cdiv(B * H * W, BLOCK_M),
        triton.cdiv(Cout, BLOCK_N),
    )

    conv1x1_dense_bn_relu_kernel[grid](
        x, w_mat,
        running_mean, running_var,
        bn_weight, bn_bias,
        y,
        B, H, W,
        Cin, Cout,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        bn.eps,
        RELU=relu,
        BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N, BLOCK_K=BLOCK_K,
    )
    return y


# -----------------------------
# Depthwise 3x3 Convolution + BatchNorm (groups = channels)
# -----------------------------
@triton.jit
def depthwise_conv3x3_bn_kernel(
    x_ptr, w_ptr,
    running_mean_ptr, running_var_ptr,
    bn_weight_ptr, bn_bias_ptr,
    y_ptr,
    B, C, H, W,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_yn, stride_yc, stride_yh, stride_yw,
    eps,
    BLOCK_BC: tl.constexpr, BLOCK_HW: tl.constexpr,
):
    pid_bc = tl.program_id(0)  # over B*C
    pid_hw = tl.program_id(1)  # over H*W

    BC = B * C
    offs_bc = pid_bc * BLOCK_BC + tl.arange(0, BLOCK_BC)
    mask_bc = offs_bc < BC

    HW = H * W
    offs_hw = pid_hw * BLOCK_HW + tl.arange(0, BLOCK_HW)
    mask_hw = offs_hw < HW

    # Map offs_bc -> (b, c)
    b = offs_bc // C
    c = offs_bc % C

    # Map offs_hw -> (h, w)
    h_idx = offs_hw // W
    w_idx = offs_hw % W

    mask_all = mask_bc[:, None] & mask_hw[None, :]

    acc = tl.zeros((BLOCK_BC, BLOCK_HW), dtype=tl.float32)

    # 3x3 filter with padding=1, stride=1
    for dh in range(-1, 2):
        ih = h_idx[None, :] + dh
        mask_h = (ih >= 0) & (ih < H)
        for dw in range(-1, 2):
            iw = w_idx[None, :] + dw
            mask_w = (iw >= 0) & (iw < W)
            m = mask_all & mask_h & mask_w

            base_in = x_ptr + (b * stride_xn + c * stride_xc)[:, None] + ih * stride_xh + iw * stride_xw
            x_val = tl.load(base_in, mask=m, other=0.0)

            k_index = (dh + 1) * 3 + (dw + 1)
            w_base = w_ptr + c * 9 + k_index
            w_val = tl.load(w_base, mask=mask_bc, other=0.0)
            acc += w_val[:, None] * x_val

    # BatchNorm per channel
    mean = tl.load(running_mean_ptr + c, mask=mask_bc, other=0.0)
    var = tl.load(running_var_ptr + c, mask=mask_bc, other=0.0)
    gamma = tl.load(bn_weight_ptr + c, mask=mask_bc, other=1.0)
    beta = tl.load(bn_bias_ptr + c, mask=mask_bc, other=0.0)

    inv_std = 1.0 / tl.sqrt(var + eps)
    scale = gamma * inv_std

    acc = (acc - mean[:, None]) * scale[:, None] + beta[:, None]

    base_out = y_ptr + (b * stride_yn + c * stride_yc)[:, None] + h_idx[None, :] * stride_yh + w_idx[None, :] * stride_yw
    tl.store(base_out, acc, mask=mask_all)


def depthwise_conv3x3_bn_triton(x: torch.Tensor,
                                conv: nn.Conv2d,
                                bn: nn.BatchNorm2d) -> torch.Tensor:
    """
    Fused depthwise 3x3 convolution + BatchNorm (stride=1, padding=1).
    conv: Conv2d with groups = in_channels = out_channels, kernel_size=3.
    """
    assert x.is_cuda, "Triton kernels require CUDA tensors"
    assert x.dim() == 4
    B, C, H, W = x.shape
    weight = conv.weight  # [C, 1, 3, 3]
    assert conv.groups == C
    assert weight.shape[0] == C and weight.shape[2] == 3 and weight.shape[3] == 3
    # Compact layout [C, 3, 3]
    w_mat = weight.view(C, 3, 3).contiguous()

    running_mean = bn.running_mean
    running_var = bn.running_var
    if bn.weight is not None:
        bn_weight = bn.weight
    else:
        bn_weight = torch.ones_like(running_mean)
    if bn.bias is not None:
        bn_bias = bn.bias
    else:
        bn_bias = torch.zeros_like(running_mean)

    y = torch.empty_like(x)

    BLOCK_BC = 32
    BLOCK_HW = 64

    grid = (
        triton.cdiv(B * C, BLOCK_BC),
        triton.cdiv(H * W, BLOCK_HW),
    )

    depthwise_conv3x3_bn_kernel[grid](
        x, w_mat,
        running_mean, running_var,
        bn_weight, bn_bias,
        y,
        B, C, H, W,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        bn.eps,
        BLOCK_BC=BLOCK_BC, BLOCK_HW=BLOCK_HW,
    )
    return y


# -----------------------------
# Fused Add + ReLU
# -----------------------------
@triton.jit
def add_relu_kernel(
    a_ptr, b_ptr, out_ptr,
    N,
    BLOCK: tl.constexpr,
):
    pid = tl.program_id(0)
    offs = pid * BLOCK + tl.arange(0, BLOCK)
    mask = offs < N

    a = tl.load(a_ptr + offs, mask=mask, other=0.0)
    b = tl.load(b_ptr + offs, mask=mask, other=0.0)
    c = a + b
    c = tl.maximum(c, 0.0)
    tl.store(out_ptr + offs, c, mask=mask)


def add_relu_triton(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:
    """
    Fused elementwise add + ReLU: out = relu(a + b)
    """
    assert a.is_cuda and b.is_cuda
    assert a.shape == b.shape
    out = torch.empty_like(a)
    N = a.numel()
    BLOCK = 256
    grid = (triton.cdiv(N, BLOCK),)
    add_relu_kernel[grid](a, b, out, N, BLOCK=BLOCK)
    return out


# -----------------------------
# ModelNew: ShuffleNet Unit with Triton Kernels
# -----------------------------
class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, groups=3):
        """
        ShuffleNet unit using Triton-fused kernels:
        - 1x1 group conv + BN + ReLU
        - depthwise 3x3 conv + BN
        - (channel shuffle folded into conv3)
        - 1x1 conv (equivalent to group conv after shuffle) + BN + ReLU
        - optional shortcut 1x1 conv + BN
        - fused add + ReLU
        """
        super(ModelNew, self).__init__()

        assert out_channels % 4 == 0
        mid_channels = out_channels // 4
        self.groups = groups

        # First 1x1 group convolution
        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=1, stride=1,
                               padding=0, groups=groups, bias=False)
        self.bn1 = nn.BatchNorm2d(mid_channels)

        # Depthwise 3x3 convolution
        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, stride=1,
                               padding=1, groups=mid_channels, bias=False)
        self.bn2 = nn.BatchNorm2d(mid_channels)

        # Second 1x1 group convolution (weights will be used to build dense conv with folded shuffle)
        self.conv3 = nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1,
                               padding=0, groups=groups, bias=False)
        self.bn3 = nn.BatchNorm2d(out_channels)

        # Shortcut connection
        self.in_channels = in_channels
        self.out_channels = out_channels
        if in_channels == out_channels:
            self.shortcut_conv = None
            self.shortcut_bn = None
        else:
            self.shortcut_conv = nn.Conv2d(in_channels, out_channels,
                                           kernel_size=1, stride=1,
                                           padding=0, bias=False)
            self.shortcut_bn = nn.BatchNorm2d(out_channels)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Main branch
        out = conv1x1_group_bn_relu_triton(x, self.conv1, self.bn1, relu=True)
        out = depthwise_conv3x3_bn_triton(out, self.conv2, self.bn2)

        # Channel shuffle + 1x1 group conv fused into a single dense 1x1 conv
        out = conv1x1_dense_from_shuffled_triton(
            out, self.conv3, self.bn3, groups=self.groups, relu=True
        )

        # Shortcut branch
        if self.shortcut_conv is None:
            residual = x
        else:
            residual = conv1x1_group_bn_relu_triton(
                x, self.shortcut_conv, self.shortcut_bn, relu=False
            )

        # Fused add + ReLU
        out = add_relu_triton(out, residual)
        return out
```