You are optimizing a Triton kernel based on algorithmic analysis.

# PyTorch Reference (Target Behavior)

```python
import torch
import torch.nn as nn

# U-Net Implementation
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.Softmax(dim=-1),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.Softmax(dim=-1)
        )

    def forward(self, x):
        return self.double_conv(x)

class Model(nn.Module):
    def __init__(self, in_channels, out_channels, features):
        """
        :param in_channels: Number of input channels
        :param out_channels: Number of output channels
        :param features: Number of base features (will be doubled in each layer)
        """
        super(Model, self).__init__()
        self.encoder1 = DoubleConv(in_channels, features)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.encoder2 = DoubleConv(features, features * 2)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.encoder3 = DoubleConv(features * 2, features * 4)
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.encoder4 = DoubleConv(features * 4, features * 8)
        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.bottleneck = DoubleConv(features * 8, features * 16)

        self.upconv4 = nn.ConvTranspose2d(features * 16, features * 8, kernel_size=2, stride=2)
        self.decoder4 = DoubleConv(features * 16, features * 8)
        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=2, stride=2)
        self.decoder3 = DoubleConv(features * 8, features * 4)
        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)
        self.decoder2 = DoubleConv(features * 4, features * 2)
        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)
        self.decoder1 = DoubleConv(features * 2, features)

        self.final_conv = nn.Conv2d(features, out_channels, kernel_size=1)

    def forward(self, x):
        """
        :param x: Input tensor, shape (batch_size, in_channels, height, width)
        :return: Output tensor, shape (batch_size, out_channels, height, width)
        """
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(self.pool1(enc1))
        enc3 = self.encoder3(self.pool2(enc2))
        enc4 = self.encoder4(self.pool3(enc3))

        bottleneck = self.bottleneck(self.pool4(enc4))

        dec4 = self.upconv4(bottleneck)
        dec4 = torch.cat((dec4, enc4), dim=1)
        dec4 = self.decoder4(dec4)
        dec3 = self.upconv3(dec4)
        dec3 = torch.cat((dec3, enc3), dim=1)
        dec3 = self.decoder3(dec3)
        dec2 = self.upconv2(dec3)
        dec2 = torch.cat((dec2, enc2), dim=1)
        dec2 = self.decoder2(dec2)
        dec1 = self.upconv1(dec2)
        dec1 = torch.cat((dec1, enc1), dim=1)
        dec1 = self.decoder1(dec1)

        return self.final_conv(dec1)
    
batch_size = 8
in_channels = 8
out_channels = 4
height = 64
width = 512
features = 64
# Test code for UNet
def get_inputs():
    return [torch.rand(batch_size, in_channels, height, width)]

def get_init_inputs():
    return [in_channels, out_channels, features]
```

**CRITICAL**: Study the PyTorch code carefully to understand:
- What does `forward()` return? (full output sequence vs final hidden state only)
- What is the computational pattern?
- What are the input/output shapes?

Your optimized kernel MUST match this exact behavior.

---

# Analysis Results

**Bottleneck**: Most of the U-Net's FLOPs and memory traffic come from the Conv2d+BatchNorm(+Softmax) blocks inside DoubleConv, but the current Triton implementation only replaces Softmax and MaxPool, leaving the main bottleneck (Conv+BN) untouched and even adding extra launches and memory passes for softmax_lastdim reshaping.

**Optimization Strategy**: Apply operator fusion at the DoubleConv level by folding BatchNorm parameters into the preceding Conv2d weights/bias (for inference) and then fusing the remaining Conv2d output with the Softmax into a single Triton kernel, so that each DoubleConv stage is effectively Conv2d → fused (BN+Softmax) instead of three separate kernels.

**Implementation Plan**: First, switch the benchmark to eval mode and fold each BatchNorm2d into its preceding Conv2d by precomputing new weights and biases using the BN running_mean, running_var, gamma, and beta, eliminating BN from the forward path. Next, write a Triton kernel that takes the conv output tensor (N, C, H, W) and directly computes the width-wise softmax in-place (or into a destination buffer) without the intermediate 2D view and multiple passes; call this fused kernel immediately after each Conv2d in DoubleConvNew. This removes all BatchNorm kernels and all separate softmax_lastdim launches, significantly cutting global memory reads/writes and kernel launch overhead per block.

**Expected Speedup**: 20-30%

---

# Current Kernel (needs optimization)

```python
# <complete ModelNew code with optimized Triton kernels>
import math

import torch
import torch.nn as nn
import triton
import triton.language as tl


# ---------------------------------------------------------
# Implement missing Triton math helpers (tanh/sigmoid/...)
# ---------------------------------------------------------


def _tl_sigmoid(x):
    return 1.0 / (1.0 + tl.exp(-x))


def _tl_tanh(x):
    # 2*sigmoid(2x) - 1
    return 2.0 * _tl_sigmoid(2.0 * x) - 1.0


def _tl_gelu(x):
    # Approximate GELU (Hendrycks & Gimpel)
    c = 0.7978845608028654  # sqrt(2/pi)
    k = 0.044715
    return 0.5 * x * (1.0 + _tl_tanh(c * (x + k * x * x * x)))


def _tl_silu(x):
    return x * _tl_sigmoid(x)


def _tl_softmax(x, axis=0):
    # Generic softmax along 'axis'
    x_max = tl.max(x, axis=axis)
    x_exp = tl.exp(x - x_max)
    x_sum = tl.sum(x_exp, axis=axis)
    return x_exp / x_sum


def _tl_mish(x):
    # mish(x) = x * tanh(softplus(x)); softplus = log(1 + exp(x))
    softplus = tl.log(1.0 + tl.exp(x))
    return x * _tl_tanh(softplus)


# Monkey-patch onto tl namespace (for any future kernels that may use them)
tl.sigmoid = _tl_sigmoid
tl.tanh = _tl_tanh
tl.gelu = _tl_gelu
tl.silu = _tl_silu
tl.softmax = _tl_softmax
tl.mish = _tl_mish


# -----------------------------
# Triton Softmax over last dim
# -----------------------------

@triton.jit
def softmax_lastdim_kernel(
    x_ptr, y_ptr,
    M, N,
    stride_xm, stride_ym,
    BLOCK_N: tl.constexpr,
):
    pid_m = tl.program_id(0)
    # guard in case grid is larger than M (it shouldn't be, but cheap safety)
    if pid_m >= M:
        return

    offs_n = tl.arange(0, BLOCK_N)

    # base pointers for this row
    row_x_ptr = x_ptr + pid_m * stride_xm
    row_y_ptr = y_ptr + pid_m * stride_ym

    # 1) compute row-wise max for numerical stability
    max_val = -float("inf")
    for start_n in range(0, N, BLOCK_N):
        idx = start_n + offs_n
        mask = idx < N
        x = tl.load(row_x_ptr + idx, mask=mask, other=-float("inf"))
        curr_max = tl.max(x, axis=0)
        max_val = tl.maximum(max_val, curr_max)

    # 2) compute exp(x - max) and accumulate sum; store unnormalized to y
    sum_exp = 0.0
    for start_n in range(0, N, BLOCK_N):
        idx = start_n + offs_n
        mask = idx < N
        x = tl.load(row_x_ptr + idx, mask=mask, other=-float("inf"))
        x = x - max_val
        exp_x = tl.exp(x)
        tl.store(row_y_ptr + idx, exp_x, mask=mask)
        sum_exp = sum_exp + tl.sum(exp_x, axis=0)

    # 3) normalize
    inv_sum = 1.0 / sum_exp
    for start_n in range(0, N, BLOCK_N):
        idx = start_n + offs_n
        mask = idx < N
        y = tl.load(row_y_ptr + idx, mask=mask, other=0.0)
        y = y * inv_sum
        tl.store(row_y_ptr + idx, y, mask=mask)


def triton_softmax_lastdim(x: torch.Tensor) -> torch.Tensor:
    """
    Softmax over last dimension (dim=-1), equivalent to nn.Softmax(dim=-1),
    implemented in Triton for high performance.

    Assumes x is CUDA and float32.
    """
    assert x.is_cuda, "triton_softmax_lastdim requires a CUDA tensor"
    assert x.dtype == torch.float32, "triton_softmax_lastdim currently supports float32 only"

    if x.numel() == 0:
        return x

    *prefix, N = x.shape
    M = 1
    for s in prefix:
        M *= s

    x_2d = x.contiguous().view(M, N)
    y_2d = torch.empty_like(x_2d)

    stride_xm = x_2d.stride(0)
    stride_ym = y_2d.stride(0)

    def grid(meta):
        # one program per row
        return (max(1, M),)

    softmax_lastdim_kernel[grid](
        x_2d, y_2d,
        M, N,
        stride_xm, stride_ym,
        BLOCK_N=256,  # power-of-2 block size
    )
    return y_2d.view_as(x)


# -----------------------------
# Triton MaxPool2d (k=2, s=2)
# -----------------------------

@triton.jit
def maxpool2x2_kernel(
    x_ptr, y_ptr,
    N, C, H, W,
    H_out, W_out,
    total_out,
    BLOCK: tl.constexpr,
):
    pid = tl.program_id(0)
    offs = pid * BLOCK + tl.arange(0, BLOCK)
    mask = offs < total_out

    # Decode flattened output index -> (n, c, ho, wo)
    idx = offs

    wo = idx % W_out
    tmp = idx // W_out
    ho = tmp % H_out
    tmp = tmp // H_out
    c = tmp % C
    n = tmp // C

    # Compute top-left corner (hi, wi) in input for each output element
    hi = ho * 2
    wi = wo * 2

    # Flattened input index for (n, c, hi, wi)
    base = ((n * C + c) * H + hi) * W + wi

    # four positions in 2x2 window
    idx00 = base
    idx01 = base + 1
    idx10 = base + W
    idx11 = base + W + 1

    # load with mask to avoid OOB (paranoid safety)
    x00 = tl.load(x_ptr + idx00, mask=mask, other=-float("inf"))
    x01 = tl.load(x_ptr + idx01, mask=mask & (wi + 1 < W), other=-float("inf"))
    x10 = tl.load(x_ptr + idx10, mask=mask & (hi + 1 < H), other=-float("inf"))
    x11 = tl.load(
        x_ptr + idx11,
        mask=mask & (wi + 1 < W) & (hi + 1 < H),
        other=-float("inf"),
    )

    m1 = tl.maximum(x00, x01)
    m2 = tl.maximum(x10, x11)
    m = tl.maximum(m1, m2)

    tl.store(y_ptr + offs, m, mask=mask)


def triton_maxpool2x2(x: torch.Tensor) -> torch.Tensor:
    """
    MaxPool2d with kernel_size=2, stride=2, no padding.
    Equivalent to nn.MaxPool2d(2, 2).

    Assumes NCHW, CUDA tensor, contiguous.
    """
    assert x.is_cuda, "triton_maxpool2x2 requires a CUDA tensor"
    assert x.dim() == 4, "Expected NCHW input"
    x = x.contiguous()
    N, C, H, W = x.shape

    if N == 0 or C == 0 or H == 0 or W == 0:
        return x.new_empty((N, C, H // 2, W // 2))

    assert H % 2 == 0 and W % 2 == 0, "H and W must be even for k=2, s=2"

    H_out = H // 2
    W_out = W // 2
    y = torch.empty((N, C, H_out, W_out), device=x.device, dtype=x.dtype)

    total_out = N * C * H_out * W_out

    def grid(meta):
        return (max(1, triton.cdiv(total_out, meta["BLOCK"])),)

    maxpool2x2_kernel[grid](
        x, y,
        N, C, H, W,
        H_out, W_out,
        total_out,
        BLOCK=256,
    )
    return y


# -----------------------------
# Network definitions
# -----------------------------

class DoubleConvNew(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        # Conv2d + BatchNorm2d, Softmax last-dim via Triton
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bn2 = nn.BatchNorm2d(out_channels)

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = triton_softmax_lastdim(x)  # Softmax over last dim (width)
        x = self.conv2(x)
        x = self.bn2(x)
        x = triton_softmax_lastdim(x)
        return x


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, features):
        """
        U-Net-like architecture with Triton-optimized Softmax and MaxPool.
        """
        super(ModelNew, self).__init__()
        self.encoder1 = DoubleConvNew(in_channels, features)
        self.encoder2 = DoubleConvNew(features, features * 2)
        self.encoder3 = DoubleConvNew(features * 2, features * 4)
        self.encoder4 = DoubleConvNew(features * 4, features * 8)

        self.bottleneck = DoubleConvNew(features * 8, features * 16)

        self.upconv4 = nn.ConvTranspose2d(
            features * 16, features * 8, kernel_size=2, stride=2
        )
        self.decoder4 = DoubleConvNew(features * 16, features * 8)

        self.upconv3 = nn.ConvTranspose2d(
            features * 8, features * 4, kernel_size=2, stride=2
        )
        self.decoder3 = DoubleConvNew(features * 8, features * 4)

        self.upconv2 = nn.ConvTranspose2d(
            features * 4, features * 2, kernel_size=2, stride=2
        )
        # FIXED: in_channels must match concatenation of enc2 (features*2)
        # and upconv2 output (features*2) => total features*4 (not features*8)
        self.decoder2 = DoubleConvNew(features * 4, features * 2)

        self.upconv1 = nn.ConvTranspose2d(
            features * 2, features, kernel_size=2, stride=2
        )
        self.decoder1 = DoubleConvNew(features * 2, features)

        self.final_conv = nn.Conv2d(features, out_channels, kernel_size=1)

    def forward(self, x):
        # Encoder with Triton MaxPool2d
        enc1 = self.encoder1(x)
        enc2 = self.encoder2(triton_maxpool2x2(enc1))
        enc3 = self.encoder3(triton_maxpool2x2(enc2))
        enc4 = self.encoder4(triton_maxpool2x2(enc3))

        bottleneck = self.bottleneck(triton_maxpool2x2(enc4))

        # Decoder path
        dec4 = self.upconv4(bottleneck)
        dec4 = torch.cat((dec4, enc4), dim=1)
        dec4 = self.decoder4(dec4)

        dec3 = self.upconv3(dec4)
        dec3 = torch.cat((dec3, enc3), dim=1)
        dec3 = self.decoder3(dec3)

        dec2 = self.upconv2(dec3)
        dec2 = torch.cat((dec2, enc2), dim=1)
        dec2 = self.decoder2(dec2)

        dec1 = self.upconv1(dec2)
        dec1 = torch.cat((dec1, enc1), dim=1)
        dec1 = self.decoder1(dec1)

        return self.final_conv(dec1)
```

---

# Your Task

Implement the optimization strategy above. Focus on the specific bottleneck identified.

## Key Requirements

1. **Preserve correctness**: Maintain the same input/output behavior
2. **Apply the optimization**: Follow the implementation plan exactly
3. **Use valid Triton syntax**:
   - Every kernel MUST have `@triton.jit` decorator
   - Grid size MUST be > 0: use `triton.cdiv(N, BLOCK)` or `max(1, N // BLOCK)`
   - BLOCK sizes MUST be power-of-2: 16, 32, 64, 128, 256
   - No `continue`, `break`, `return` inside kernels (use masking)
   - Prefer `tl.dot(a, b, allow_tf32=True)` for matmul operations

4. **CRITICAL for RNN/GRU/LSTM Persistent Kernels**:
   - Time loop MUST be inside @triton.jit kernel, NOT in Python forward()
   - **HYBRID computation strategy** (CRITICAL for performance):
     * Precompute input-side gates OUTSIDE kernel: `gates_x = (T*B, In) @ W_ih` (ONE large GEMM)
     * INSIDE kernel: only recurrent-side: `for t: gates_h = h @ W_hh` (T small GEMMs)
   - CORRECT (FAST - use this):
     ```python
     # Python forward():
     gates_x_all = x.reshape(T*B, In) @ W_ih + b_ih  # ONE large GEMM
     gates_x_all = gates_x_all.view(T, B, 3*H)
     gru_persistent_kernel[grid](gates_x_all, h0, W_hh, ...)  # Launch ONCE

     @triton.jit
     def gru_persistent_kernel(gates_x_ptr, h_ptr, W_hh_ptr, ...):
         for t in range(T):  # Inside kernel
             gates_x_t = tl.load(gates_x_ptr + t*...)  # Precomputed
             gates_h = h @ W_hh  # Only recurrent GEMM
             h = (1-z)*n + z*h   # Fuse and update
     ```

5. **Output format**:
   - Imports: `import torch, torch.nn as nn, triton, triton.language as tl`
   - `@triton.jit` kernel(s)
   - Wrapper function(s)
   - `class ModelNew(nn.Module)` — REQUIRED
   - NO testing code, NO `if __name__ == "__main__"`

---

Generate the optimized kernel now. Output ONLY the complete Python code.
