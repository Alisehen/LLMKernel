You are a Triton kernel optimization specialist. Generate the FASTEST possible kernel.

# Target GPU
GPU Name: 4090
Architecture: Ada Lovelace
• Compute Capability: 8.9
• Number of SMs: 128
• Memory Bandwidth: 1008 GB/s
• TF32 Tensor Core TFLOPS: 82.6 with dense
• BFLOAT16 Tensor Core TFLOPS: 165.2 with dense
• FP16 Tensor Core TFLOPS: 165.2 with dense
• Maximum number of registers per thread: 255
• Maximum threads per block: 1024
• Maximum threads per SM: 1536
• Warp size: 32
• Maximum concurrent warps per SM: 48
• Shared memory capacity per SM: 100 KB
• Maximum shared memory per thread block: 99 KB
• L2 cache (global, all SM shared): 72 MB

[OPTIMIZATION STAGE]f

## Current Optimization Stage

Focus: BLOCK_SIZE with register pressure awareness.

Key Principle:
- Fusion increases register usage (intermediates stay in registers)
- Spill to local memory kills fusion benefit

Register Pressure Signals (from NCU):
- launch__registers_per_thread > 128 → likely spilling
- launch__occupancy_limit_registers < other limits → register-bound

Rules:
- Start conservative: BLOCK_SIZE ∈ {256, 512} for element-wise
- For matmul fusion: BLOCK_M/N ∈ {32, 64}, BLOCK_K ∈ {32}
- If registers > 128: reduce BLOCK_* by half
- Trade-off: recompute cheap ops (e.g., x*0.5) vs store intermediate

When to Recompute vs Keep:
- Keep: expensive ops (exp, log, div, sqrt)
- Recompute: cheap ops (add, mul, max) if register pressure high
- Example: `y = relu(x); z = y * scale` → keep y
- Example: `y = x * 0.5; z = y + bias` → can recompute y if needed

Autotune:
- 2-3 BLOCK_SIZE configs, always include smaller fallback



[CURRENT CODE]
```python
import torch
import torch.nn as nn
import triton
import triton.language as tl

@triton.jit
def fused_i2h_tanh_kernel(
    x_ptr, h_prev_ptr, w_i2h_ptr, b_i2h_ptr, h_next_ptr,
    batch_size, input_size, hidden_size,
    stride_x_batch, stride_x_feat,
    stride_h_batch, stride_h_feat,
    stride_w_hidden, stride_w_feat,
    stride_b,
    BLOCK_BATCH: tl.constexpr, BLOCK_HIDDEN: tl.constexpr, BLOCK_FEAT: tl.constexpr,
):
    pid_batch = tl.program_id(0)
    pid_hidden = tl.program_id(1)
    
    batch_offsets = pid_batch * BLOCK_BATCH + tl.arange(0, BLOCK_BATCH)
    hidden_offsets = pid_hidden * BLOCK_HIDDEN + tl.arange(0, BLOCK_HIDDEN)
    
    acc = tl.zeros((BLOCK_BATCH, BLOCK_HIDDEN), dtype=tl.float32)
    
    total_features = input_size + hidden_size
    
    for k in range(0, total_features, BLOCK_FEAT):
        k_offsets = k + tl.arange(0, BLOCK_FEAT)
        
        # Load weight block - single weight matrix covering both input and hidden
        w_mask = (hidden_offsets[:, None] < hidden_size) & (k_offsets[None, :] < total_features)
        w_ptrs = w_i2h_ptr + hidden_offsets[:, None] * stride_w_hidden + k_offsets[None, :] * stride_w_feat
        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)
        
        # Load data from either x or h_prev based on the feature index
        data_block = tl.zeros((BLOCK_BATCH, BLOCK_FEAT), dtype=tl.float32)
        
        # Load input features (first input_size columns)
        input_mask = (batch_offsets[:, None] < batch_size) & (k_offsets[None, :] < input_size)
        input_data_ptrs = x_ptr + batch_offsets[:, None] * stride_x_batch + k_offsets[None, :] * stride_x_feat
        input_data = tl.load(input_data_ptrs, mask=input_mask, other=0.0)
        
        # Load hidden features (remaining hidden_size columns)
        # Calculate hidden feature index: k_offsets - input_size
        hidden_k_offsets = k_offsets - input_size
        hidden_data_mask = (batch_offsets[:, None] < batch_size) & (k_offsets[None, :] >= input_size) & (hidden_k_offsets[None, :] < hidden_size)
        hidden_data_ptrs = h_prev_ptr + batch_offsets[:, None] * stride_h_batch + hidden_k_offsets[None, :] * stride_h_feat
        hidden_data = tl.load(hidden_data_ptrs, mask=hidden_data_mask, other=0.0)
        
        # Combine input and hidden data
        data_block = tl.where(k_offsets[None, :] < input_size, input_data, data_block)
        data_block = tl.where((k_offsets[None, :] >= input_size) & (hidden_k_offsets[None, :] < hidden_size), hidden_data, data_block)
        
        acc += tl.dot(data_block, w_block.T, allow_tf32=True)
    
    # Add bias
    bias = tl.load(b_i2h_ptr + hidden_offsets, mask=hidden_offsets < hidden_size, other=0.0)
    acc += bias[None, :]
    
    # Apply tanh using stable implementation
    # For large positive values: approx 1 - 2*exp(-2x)
    # For large negative values: approx -1 + 2*exp(2x)
    # For moderate values: use (exp(2x)-1)/(exp(2x)+1)
    
    # Clip values to avoid overflow
    acc_clipped = tl.minimum(tl.maximum(acc, -20.0), 20.0)
    
    # Compute exp(2x) for moderate values
    exp_2x = tl.exp(2.0 * acc_clipped)
    
    # tanh(x) = (exp(2x)-1)/(exp(2x)+1)
    result = (exp_2x - 1.0) / (exp_2x + 1.0)
    
    # Store new hidden state
    h_next_ptrs = h_next_ptr + batch_offsets[:, None] * stride_h_batch + hidden_offsets[None, :] * stride_h_feat
    store_mask = (batch_offsets[:, None] < batch_size) & (hidden_offsets[None, :] < hidden_size)
    tl.store(h_next_ptrs, result, mask=store_mask)

@triton.jit
def fused_h2o_kernel(
    h_ptr, w_h2o_ptr, b_h2o_ptr, o_ptr,
    batch_size, hidden_size, output_size,
    stride_h_batch, stride_h_feat,
    stride_w_output, stride_w_feat,
    stride_b,
    stride_o_batch, stride_o_feat,
    BLOCK_BATCH: tl.constexpr, BLOCK_OUTPUT: tl.constexpr, BLOCK_HIDDEN: tl.constexpr,
):
    pid_batch = tl.program_id(0)
    pid_output = tl.program_id(1)
    
    batch_offsets = pid_batch * BLOCK_BATCH + tl.arange(0, BLOCK_BATCH)
    output_offsets = pid_output * BLOCK_OUTPUT + tl.arange(0, BLOCK_OUTPUT)
    
    acc = tl.zeros((BLOCK_BATCH, BLOCK_OUTPUT), dtype=tl.float32)
    
    for k in range(0, hidden_size, BLOCK_HIDDEN):
        k_offsets = k + tl.arange(0, BLOCK_HIDDEN)
        
        h_mask = (batch_offsets[:, None] < batch_size) & (k_offsets[None, :] < hidden_size)
        h_ptrs = h_ptr + batch_offsets[:, None] * stride_h_batch + k_offsets[None, :] * stride_h_feat
        h_block = tl.load(h_ptrs, mask=h_mask, other=0.0)
        
        w_mask = (output_offsets[:, None] < output_size) & (k_offsets[None, :] < hidden_size)
        w_ptrs = w_h2o_ptr + output_offsets[:, None] * stride_w_output + k_offsets[None, :] * stride_w_feat
        w_block = tl.load(w_ptrs, mask=w_mask, other=0.0)
        
        acc += tl.dot(h_block, w_block.T, allow_tf32=True)
    
    bias = tl.load(b_h2o_ptr + output_offsets, mask=output_offsets < output_size, other=0.0)
    acc += bias[None, :]
    
    o_ptrs = o_ptr + batch_offsets[:, None] * stride_o_batch + output_offsets[None, :] * stride_o_feat
    store_mask = (batch_offsets[:, None] < batch_size) & (output_offsets[None, :] < output_size)
    tl.store(o_ptrs, acc, mask=store_mask)

def fused_i2h_tanh(x, h_prev, weight_i2h, bias_i2h):
    batch_size, input_size = x.shape
    hidden_size = weight_i2h.shape[0]
    
    h_next = torch.empty((batch_size, hidden_size), device=x.device, dtype=x.dtype)
    
    grid = lambda META: (
        triton.cdiv(batch_size, META['BLOCK_BATCH']),
        triton.cdiv(hidden_size, META['BLOCK_HIDDEN'])
    )
    
    fused_i2h_tanh_kernel[grid](
        x, h_prev, weight_i2h, bias_i2h, h_next,
        batch_size, input_size, hidden_size,
        x.stride(0), x.stride(1),
        h_prev.stride(0), h_prev.stride(1),
        weight_i2h.stride(0), weight_i2h.stride(1),
        bias_i2h.stride(0),
        BLOCK_BATCH=32, BLOCK_HIDDEN=64, BLOCK_FEAT=64
    )
    
    return h_next

def fused_h2o(h, weight_h2o, bias_h2o):
    batch_size, hidden_size = h.shape
    output_size = weight_h2o.shape[0]
    
    output = torch.empty((batch_size, output_size), device=h.device, dtype=h.dtype)
    
    grid = lambda META: (
        triton.cdiv(batch_size, META['BLOCK_BATCH']),
        triton.cdiv(output_size, META['BLOCK_OUTPUT'])
    )
    
    fused_h2o_kernel[grid](
        h, weight_h2o, bias_h2o, output,
        batch_size, hidden_size, output_size,
        h.stride(0), h.stride(1),
        weight_h2o.stride(0), weight_h2o.stride(1),
        bias_h2o.stride(0),
        output.stride(0), output.stride(1),
        BLOCK_BATCH=32, BLOCK_OUTPUT=64, BLOCK_HIDDEN=64
    )
    
    return output

class ModelNew(nn.Module):
    def __init__(self, input_size: int, hidden_size: int, output_size: int):
        super(ModelNew, self).__init__()
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        
        self.weight_i2h = nn.Parameter(torch.randn(hidden_size, input_size + hidden_size))
        self.bias_i2h = nn.Parameter(torch.randn(hidden_size))
        self.weight_h2o = nn.Parameter(torch.randn(output_size, hidden_size))
        self.bias_h2o = nn.Parameter(torch.randn(output_size))
    
    def forward(self, x: torch.Tensor, h0: torch.Tensor) -> torch.Tensor:
        seq_len, batch_size, _ = x.size()
        hidden = h0.to(x.device)
        outputs = []
        
        for t in range(seq_len):
            x_t = x[t]
            hidden = fused_i2h_tanh(x_t, hidden, self.weight_i2h, self.bias_i2h)
            output_t = fused_h2o(hidden, self.weight_h2o, self.bias_h2o)
            outputs.append(output_t)
        
        return torch.stack(outputs, dim=0)
```

[NCU PROFILING METRICS]
{
  "fused_i2h_tanh_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 0.76,
    "launch__grid_size": 4.0,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 8.33,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 7.43,
    "lts__t_sector_hit_rate.pct": 21.24
  },
  "fused_h2o_kernel": {
    "sm__throughput.avg.pct_of_peak_sustained_elapsed": 0.26,
    "launch__grid_size": 2.0,
    "sm__warps_active.avg.pct_of_peak_sustained_active": 8.32,
    "dram__throughput.avg.pct_of_peak_sustained_elapsed": 2.82,
    "lts__t_sector_hit_rate.pct": 47.48
  }
}

**Task**: Analyze the NCU metrics and current code, then generate optimized code that maximizes performance.

TRITON API CONSTRAINTS (CRITICAL):
- Triton has NO: tl.tanh, tl.sigmoid, tl.gelu, tl.silu, tl.softmax, tl.mish

OUTPUT RULES (STRICT):
1. Follow this exact order:
   1. Imports: torch, torch.nn, triton, triton.language as tl
   2. @triton.jit decorated kernel function(s)
   3. Wrapper function(s) for grid calculation and kernel launch
   4. class ModelNew(nn.Module) that calls your kernels
2. Do NOT include: testing code, if __name__, get_inputs, get_init_inputs

```python
# <optimized Triton code>
```
