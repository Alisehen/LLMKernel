```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


@triton.autotune(
    configs=[
        triton.Config({'BLOCK_K': 64}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_K': 128}, num_warps=4, num_stages=3),
        triton.Config({'BLOCK_K': 256}, num_warps=8, num_stages=3),
        triton.Config({'BLOCK_K': 512}, num_warps=8, num_stages=3),
    ],
    key=['K']
)
@triton.jit
def fused_gemm_last_step_kernel(
    # Input pointers
    x_ptr,  # [B, T, K]
    weight_ptr,  # [N, K] (transposed: K, N layout)
    bias_ptr,  # [N] or None
    # Output pointer
    out_ptr,  # [B, N]
    # Shapes
    B, T, K, N,
    # Strides
    stride_xb, stride_xt, stride_xk,
    stride_wk, stride_wn,
    stride_ob, stride_on,
    # Block constants
    BLOCK_K: tl.constexpr,
):
    """
    Optimized fused kernel: x[:, -1, :] @ weight.t() + bias
    Each thread block computes one output element (b, n).
    """
    # Calculate output position (b, n)
    pid = tl.program_id(0)
    b_idx = pid // N
    n_idx = pid % N
    
    # Boundary checks
    if b_idx >= B or n_idx >= N:
        return
    
    # Precompute last timestep offset
    last_timestep_offset = (T - 1) * stride_xt + b_idx * stride_xb
    
    # Initialize accumulator
    acc = 0.0
    
    # Blocked K dimension for efficiency
    for k_start in range(0, K, BLOCK_K):
        k_offsets = tl.arange(0, BLOCK_K)
        k_mask = k_offsets < K - k_start
        
        # Load x slice from last timestep
        x_ptrs = x_ptr + last_timestep_offset + (k_start + k_offsets) * stride_xk
        x_block = tl.load(x_ptrs, mask=k_mask, other=0.0)
        
        # Load weight slice
        w_ptrs = weight_ptr + (k_start + k_offsets) * stride_wk + n_idx * stride_wn
        w_block = tl.load(w_ptrs, mask=k_mask, other=0.0)
        
        # Accumulate dot product
        acc += tl.sum(x_block * w_block)
    
    # Add bias if provided
    if bias_ptr is not None:
        bias = tl.load(bias_ptr + n_idx)
        acc += bias
    
    # Store result
    out_ptr = out_ptr + b_idx * stride_ob + n_idx * stride_on
    tl.store(out_ptr, acc)


def fused_gemm_last_step(x, weight, bias):
    """
    Fused operation: x[:, -1, :] @ weight.t() + bias
    """
    B, T, K = x.shape
    N = weight.shape[0]
    
    # Output tensor
    out = torch.empty((B, N), device=x.device, dtype=x.dtype)
    
    # Prepare weight for kernel (need K,N layout)
    weight_t = weight.t().contiguous()
    
    # Grid: one thread block per output element (B*N total)
    total_elements = B * N
    
    # Launch kernel
    grid = lambda META: (total_elements,)
    fused_gemm_last_step_kernel[grid](
        x, weight_t, bias, out,
        B, T, K, N,
        x.stride(0), x.stride(1), x.stride(2),
        weight_t.stride(0), weight_t.stride(1),
        out.stride(0), out.stride(1),
    )
    
    return out


class ModelNew(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.0):
        super(ModelNew, self).__init__()
        self.lstm = nn.LSTM(
            input_size, hidden_size, num_layers,
            batch_first=True, dropout=dropout, bidirectional=True
        )
        
        # Parameters for fused kernel
        self.weight = nn.Parameter(torch.randn(output_size, hidden_size * 2))
        self.bias = nn.Parameter(torch.randn(output_size))
    
    def forward(self, x, h0, c0):
        # LSTM forward
        out, hn = self.lstm(x, (h0, c0))
        
        # Fused: take last timestep and linear transformation
        return fused_gemm_last_step(out, self.weight, self.bias)
```