{
  "runnable": false,
  "phase": "stage1_grid_and_parallel",
  "error_type": "RuntimeError",
  "message": "Traceback (most recent call last):\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py\", line 43, in wrapper\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py\", line 1094, in __getitem__\n    for dim, sl in enumerate(slices):\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/language/core.py\", line 41, in wrapper\n    raise ValueError(\"Did you forget to add @triton.jit ? \"\nValueError: Did you forget to add @triton.jit ? (`_semantic` argument must be provided outside of JIT functions.)\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/home/hyc/LLMKernel/utils/compile_and_run.py\", line 538, in compare_and_bench\n    test_out, _ = _run_once(test_model, inp, dev)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/utils/compile_and_run.py\", line 132, in _run_once\n    out = model(*inp)\n          ^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/run/20251215_151615_batch_range17to33_deepseek_deepseek/23_EfficientNetB1/code/kernel_20251215_191912.py\", line 375, in forward\n    x = self.mbconv2(x)\n        ^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/run/20251215_151615_batch_range17to33_deepseek_deepseek/23_EfficientNetB1/code/kernel_20251215_191912.py\", line 319, in forward\n    x = fused_pointwise_conv_bn_relu6(\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/LLMKernel/run/20251215_151615_batch_range17to33_deepseek_deepseek/23_EfficientNetB1/code/kernel_20251215_191912.py\", line 170, in fused_pointwise_conv_bn_relu6\n    fused_pointwise_conv_bn_relu6_kernel[grid](\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py\", line 419, in <lambda>\n    return lambda *args, **kwargs: self.run(grid=grid, warmup=False, *args, **kwargs)\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py\", line 733, in run\n    kernel = self._do_compile(key, signature, device, constexprs, options, attrs, warmup)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/runtime/jit.py\", line 861, in _do_compile\n    kernel = self.compile(src, target=target, options=options.__dict__)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py\", line 300, in compile\n    module = src.make_ir(target, options, codegen_fns, module_map, context)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/hyc/miniconda3/envs/sglang/lib/python3.11/site-packages/triton/compiler/compiler.py\", line 80, in make_ir\n    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntriton.compiler.errors.CompilationError: at 91:24:\n        # Optimized matrix multiplication using tensor cores when possible\n        # Reshape for proper broadcasting and use fp16 for tensor core acceleration\n        x_fp16 = x.to(tl.float16)\n        w_fp16 = w.to(tl.float16)\n\n        # Manual tiled multiplication for better register usage\n        # Unroll the computation for better performance\n        for i in range(BLOCK_SIZE_N):\n            for j in range(BLOCK_SIZE_C):\n                for k in range(BLOCK_SIZE_HW):\n                    if (i < BLOCK_SIZE_N and j < BLOCK_SIZE_C and k < BLOCK_SIZE_HW and\n                        n_mask[i] and oc_mask[j] and spatial_mask[0, 0, k] and c_mask[0]):\n                        ^\nDid you forget to add @triton.jit ? (`_semantic` argument must be provided outside of JIT functions.)\n"
}