```python
import torch
import torch.nn as nn
import triton
import triton.language as tl


# -----------------------------------------------------------------------------
# Optimized GEMM kernel for Linear layer (with optional fused bias add)
#  - Autotuned for 4090
#  - Single tl.store (final output), no intermediate stores
# Grid: 2D over output (M, N)
# -----------------------------------------------------------------------------
@triton.autotune(
    configs=[
        triton.Config(
            {
                "BLOCK_M": 128,
                "BLOCK_N": 128,
                "BLOCK_K": 32,
            },
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {
                "BLOCK_M": 64,
                "BLOCK_N": 128,
                "BLOCK_K": 32,
            },
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {
                "BLOCK_M": 128,
                "BLOCK_N": 64,
                "BLOCK_K": 32,
            },
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {
                "BLOCK_M": 128,
                "BLOCK_N": 128,
                "BLOCK_K": 32,
            },
            num_warps=8,
            num_stages=2,
        ),
    ],
    key=["M", "N", "K"],
)
@triton.jit
def linear_gemm_bias_kernel(
    a_ptr, b_ptr, bias_ptr, c_ptr,
    M, N, K,
    stride_am, stride_ak,       # A: (M, K)
    stride_bk, stride_bn,       # B: (K, N)
    stride_cm, stride_cn,       # C: (M, N)
    HAS_BIAS: tl.constexpr,
    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,
):
    pid_m = tl.program_id(0)  # program id along M dimension
    pid_n = tl.program_id(1)  # program id along N dimension

    # Offsets for the C tile
    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    # Output mask: shared by all ops on the C tile (fused bias, etc.)
    c_mask = (offs_m[:, None] < M) & (offs_n[None, :] < N)

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    # Reduction loop over K
    offs_k = tl.arange(0, BLOCK_K)
    for k in range(0, K, BLOCK_K):
        k_offs = k + offs_k

        a_ptrs = a_ptr + offs_m[:, None] * stride_am + k_offs[None, :] * stride_ak
        b_ptrs = b_ptr + k_offs[:, None] * stride_bk + offs_n[None, :] * stride_bn

        a_mask = (offs_m[:, None] < M) & (k_offs[None, :] < K)
        b_mask = (k_offs[:, None] < K) & (offs_n[None, :] < N)

        a = tl.load(a_ptrs, mask=a_mask, other=0.0)
        b = tl.load(b_ptrs, mask=b_mask, other=0.0)

        acc += tl.dot(a, b, allow_tf32=True)

    # Fused bias add
    if HAS_BIAS:
        bias_ptrs = bias_ptr + offs_n
        bias = tl.load(bias_ptrs, mask=offs_n < N, other=0.0)
        acc += bias[None, :]

    # Store result
    c_ptrs = c_ptr + offs_m[:, None] * stride_cm + offs_n[None, :] * stride_cn
    tl.store(c_ptrs, acc, mask=c_mask)


def linear_triton(x: torch.Tensor, weight: torch.Tensor, bias: torch.Tensor = None) -> torch.Tensor:
    """
    x: (M, K)
    weight: (N, K)  -- same as nn.Linear(out_features=N, in_features=K).weight
    bias: (N,) or None
    returns: (M, N)
    """
    assert x.is_cuda and weight.is_cuda
    M, K = x.shape
    N = weight.shape[0]
    assert weight.shape[1] == K

    # B matrix is (K, N) = weight.t() for optimal memory layout
    b = weight.t().contiguous()

    c = torch.empty((M, N), device=x.device, dtype=x.dtype)

    def grid(META):
        return (
            triton.cdiv(M, META["BLOCK_M"]),
            triton.cdiv(N, META["BLOCK_N"]),
        )

    linear_gemm_bias_kernel[grid](
        x, b, bias, c,
        M, N, K,
        x.stride(0), x.stride(1),
        b.stride(0), b.stride(1),
        c.stride(0), c.stride(1),
        HAS_BIAS=bias is not None,
    )
    return c


# -----------------------------------------------------------------------------
# Optimized 1x1 Conv2d NCHW kernel (groups=1, stride=1, padding=0)
# Implemented as GEMM over (N*H*W, C_in) x (C_in, C_out)
#  - Autotuned for 4090
#  - Single tl.store for final output
# Grid: 2D over (M=N*H*W, C_out)
# -----------------------------------------------------------------------------
@triton.autotune(
    configs=[
        triton.Config(
            {
                "BLOCK_M": 128,
                "BLOCK_N": 64,
                "BLOCK_K": 32,
            },
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {
                "BLOCK_M": 64,
                "BLOCK_N": 128,
                "BLOCK_K": 32,
            },
            num_warps=4,
            num_stages=2,
        ),
        triton.Config(
            {
                "BLOCK_M": 128,
                "BLOCK_N": 128,
                "BLOCK_K": 32,
            },
            num_warps=8,
            num_stages=2,
        ),
    ],
    key=["C_in", "C_out"],
)
@triton.jit
def conv1x1_nchw_kernel(
    x_ptr, w_ptr, y_ptr,
    N, C_in, H, W, C_out,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_wn, stride_wc,
    stride_yn, stride_yc, stride_yh, stride_yw,
    BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr, BLOCK_K: tl.constexpr,
):
    # M dimension is spatial locations across batch: M = N * H * W
    M = N * H * W

    pid_m = tl.program_id(0)  # over M (N*H*W)
    pid_n = tl.program_id(1)  # over output channels

    offs_m = pid_m * BLOCK_M + tl.arange(0, BLOCK_M)
    offs_n = pid_n * BLOCK_N + tl.arange(0, BLOCK_N)

    # Output mask: shared by all ops on the output tile
    y_mask = (offs_m[:, None] < M) & (offs_n[None, :] < C_out)

    # Decode (n, h, w) for each m in offs_m ONCE per program
    HW = H * W
    offs_m_b = offs_m[:, None]
    n = offs_m_b // HW
    rem = offs_m_b - n * HW
    h = rem // W
    w = rem - h * W

    acc = tl.zeros((BLOCK_M, BLOCK_N), dtype=tl.float32)

    offs_k = tl.arange(0, BLOCK_K)
    for k in range(0, C_in, BLOCK_K):
        k_offs = k + offs_k

        # A matrix: x[n, c_in, h, w]
        a_ptrs = (
            x_ptr
            + n * stride_xn
            + k_offs[None, :] * stride_xc
            + h * stride_xh
            + w * stride_xw
        )
        a_mask = (offs_m_b < M) & (k_offs[None, :] < C_in)
        a = tl.load(a_ptrs, mask=a_mask, other=0.0)

        # B matrix: w[c_out, c_in, 1, 1] -> logical layout (C_in, C_out)
        b_ptrs = w_ptr + offs_n[None, :] * stride_wn + k_offs[:, None] * stride_wc
        b_mask = (k_offs[:, None] < C_in) & (offs_n[None, :] < C_out)
        b = tl.load(b_ptrs, mask=b_mask, other=0.0)

        acc += tl.dot(a, b, allow_tf32=True)

    # Store results: y[n, c_out, h, w]
    y_ptrs = (
        y_ptr
        + n * stride_yn
        + offs_n[None, :] * stride_yc
        + h * stride_yh
        + w * stride_yw
    )
    tl.store(y_ptrs, acc, mask=y_mask)


def conv1x1_nchw_triton(x: torch.Tensor, weight: torch.Tensor) -> torch.Tensor:
    """
    x: (N, C_in, H, W)
    weight: (C_out, C_in, 1, 1), groups=1, stride=1, padding=0, bias=False
    returns: (N, C_out, H, W)
    """
    assert x.is_cuda and weight.is_cuda
    assert x.ndim == 4 and weight.ndim == 4
    N, C_in, H, W = x.shape
    C_out = weight.shape[0]
    assert weight.shape[1] == C_in and weight.shape[2] == 1 and weight.shape[3] == 1

    y = torch.empty((N, C_out, H, W), device=x.device, dtype=x.dtype)

    def grid(META):
        return (
            triton.cdiv(N * H * W, META["BLOCK_M"]),
            triton.cdiv(C_out, META["BLOCK_N"]),
        )

    conv1x1_nchw_kernel[grid](
        x, weight, y,
        N, C_in, H, W, C_out,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        weight.stride(0), weight.stride(1),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
    )
    return y


# -----------------------------------------------------------------------------
# Depthwise Conv2d NCHW kernel
# weight: (C, 1, K, K), groups=C
# stride = 1 or 2, padding = (K-1)//2  ("same")
# Grid: 2D over (N*C, H_out*W_out)
# Each program handles one (n, c) and a 1D tile of HW_out.
#  - Single tl.store for final output
# -----------------------------------------------------------------------------
@triton.jit
def depthwise_conv2d_nchw_kernel(
    x_ptr, w_ptr, y_ptr,
    N, C, H_in, W_in,
    H_out, W_out,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_wn, stride_wh, stride_ww,
    stride_yn, stride_yc, stride_yh, stride_yw,
    KERNEL_SIZE: tl.constexpr,
    STRIDE: tl.constexpr,
    BLOCK_HW: tl.constexpr,
):
    pid_nc = tl.program_id(0)  # over N*C
    pid_hw = tl.program_id(1)  # over HW_out

    offs_hw = pid_hw * BLOCK_HW + tl.arange(0, BLOCK_HW)
    HW_out = H_out * W_out
    hw_mask = offs_hw < HW_out

    # Decode (n, c)
    n = pid_nc // C
    c = pid_nc % C

    h_out = offs_hw // W_out
    w_out = offs_hw - h_out * W_out

    pad = (KERNEL_SIZE - 1) // 2
    h_in0 = h_out * STRIDE - pad
    w_in0 = w_out * STRIDE - pad

    acc = tl.zeros((BLOCK_HW,), dtype=tl.float32)

    # Kernel loops are constexpr, unrolled by Triton
    for ky in range(0, KERNEL_SIZE):
        for kx in range(0, KERNEL_SIZE):
            h_in = h_in0 + ky
            w_in = w_in0 + kx

            in_bounds = (
                (h_in >= 0)
                & (h_in < H_in)
                & (w_in >= 0)
                & (w_in < W_in)
            )
            mask = hw_mask & in_bounds

            x_ptrs = (
                x_ptr
                + n * stride_xn
                + c * stride_xc
                + h_in * stride_xh
                + w_in * stride_xw
            )
            x_vals = tl.load(x_ptrs, mask=mask, other=0.0)

            w_val = tl.load(
                w_ptr
                + c * stride_wn
                + ky * stride_wh
                + kx * stride_ww
            ).to(tl.float32)

            acc += x_vals.to(tl.float32) * w_val

    y_ptrs = (
        y_ptr
        + n * stride_yn
        + c * stride_yc
        + h_out * stride_yh
        + w_out * stride_yw
    )
    tl.store(y_ptrs, acc, mask=hw_mask)


def depthwise_conv2d_triton(x: torch.Tensor, weight: torch.Tensor, stride: int, kernel_size: int) -> torch.Tensor:
    """
    Depthwise conv2d NCHW with groups=C, padding=(kernel_size-1)//2.
    x: (N, C, H, W)
    weight: (C, 1, K, K)
    stride: 1 or 2
    kernel_size: K
    """
    assert x.is_cuda and weight.is_cuda
    assert x.ndim == 4 and weight.ndim == 4
    N, C, H_in, W_in = x.shape
    C_w, G, K, K2 = weight.shape
    assert C_w == C and G == 1 and K == kernel_size and K2 == kernel_size

    pad = (kernel_size - 1) // 2
    H_out = (H_in + 2 * pad - kernel_size) // stride + 1
    W_out = (W_in + 2 * pad - kernel_size) // stride + 1

    y = torch.empty((N, C, H_out, W_out), device=x.device, dtype=x.dtype)

    def grid(META):
        return (
            N * C,
            triton.cdiv(H_out * W_out, META["BLOCK_HW"]),
        )

    depthwise_conv2d_nchw_kernel[grid](
        x, weight, y,
        N, C, H_in, W_in,
        H_out, W_out,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        weight.stride(0), weight.stride(2), weight.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        KERNEL_SIZE=kernel_size,
        STRIDE=stride,
        BLOCK_HW=128,
        num_warps=4,
        num_stages=2,
    )
    return y


# -----------------------------------------------------------------------------
# Small Conv2d NCHW kernel (general, groups=1, small C_in constexpr)
# Used for stem conv: 3x3, stride=2, C_in=3
# Grid: 2D over (N*C_out, H_out*W_out)
#  - Single tl.store for final output
# -----------------------------------------------------------------------------
@triton.jit
def conv2d_small_nchw_kernel(
    x_ptr, w_ptr, y_ptr,
    N, C_in, H_in, W_in, C_out,
    H_out, W_out,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_wn, stride_wc, stride_wh, stride_ww,
    stride_yn, stride_yc, stride_yh, stride_yw,
    C_IN: tl.constexpr,
    KERNEL_SIZE: tl.constexpr,
    STRIDE: tl.constexpr,
    BLOCK_HW: tl.constexpr,
):
    pid_nc = tl.program_id(0)  # over (N * C_out)
    pid_hw = tl.program_id(1)  # over HW_out

    offs_hw = pid_hw * BLOCK_HW + tl.arange(0, BLOCK_HW)
    HW_out = H_out * W_out
    hw_mask = offs_hw < HW_out

    n = pid_nc // C_out
    co = pid_nc % C_out

    h_out = offs_hw // W_out
    w_out = offs_hw - h_out * W_out

    pad = (KERNEL_SIZE - 1) // 2
    h_in0 = h_out * STRIDE - pad
    w_in0 = w_out * STRIDE - pad

    acc = tl.zeros((BLOCK_HW,), dtype=tl.float32)

    # Small C_IN and KERNEL_SIZE => fully unrolled loops
    for ci in range(0, C_IN):
        for ky in range(0, KERNEL_SIZE):
            for kx in range(0, KERNEL_SIZE):
                h_in = h_in0 + ky
                w_in = w_in0 + kx

                in_bounds = (
                    (h_in >= 0)
                    & (h_in < H_in)
                    & (w_in >= 0)
                    & (w_in < W_in)
                )
                mask = hw_mask & in_bounds

                x_ptrs = (
                    x_ptr
                    + n * stride_xn
                    + ci * stride_xc
                    + h_in * stride_xh
                    + w_in * stride_xw
                )
                x_vals = tl.load(x_ptrs, mask=mask, other=0.0)

                w_val = tl.load(
                    w_ptr
                    + co * stride_wn
                    + ci * stride_wc
                    + ky * stride_wh
                    + kx * stride_ww
                ).to(tl.float32)

                acc += x_vals.to(tl.float32) * w_val

    y_ptrs = (
        y_ptr
        + n * stride_yn
        + co * stride_yc
        + h_out * stride_yh
        + w_out * stride_yw
    )
    tl.store(y_ptrs, acc, mask=hw_mask)


def conv2d_small_triton(
    x: torch.Tensor,
    weight: torch.Tensor,
    stride: int,
    padding: int,
) -> torch.Tensor:
    """
    Small conv2d NCHW, groups=1, used for stem conv.
    x: (N, C_in, H_in, W_in)
    weight: (C_out, C_in, K, K)
    stride: int
    padding: int
    """
    assert x.is_cuda and weight.is_cuda
    assert x.ndim == 4 and weight.ndim == 4
    N, C_in, H_in, W_in = x.shape
    C_out, C_in_w, K, K2 = weight.shape
    assert C_in_w == C_in and K == K2
    kernel_size = K
    assert padding == (kernel_size - 1) // 2  # same as EfficientNet stem

    pad = padding
    H_out = (H_in + 2 * pad - kernel_size) // stride + 1
    W_out = (W_in + 2 * pad - kernel_size) // stride + 1

    y = torch.empty((N, C_out, H_out, W_out), device=x.device, dtype=x.dtype)

    def grid(META):
        return (
            N * C_out,
            triton.cdiv(H_out * W_out, META["BLOCK_HW"]),
        )

    conv2d_small_nchw_kernel[grid](
        x, weight, y,
        N, C_in, H_in, W_in, C_out,
        H_out, W_out,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        weight.stride(0), weight.stride(1), weight.stride(2), weight.stride(3),
        y.stride(0), y.stride(1), y.stride(2), y.stride(3),
        C_IN=C_in,
        KERNEL_SIZE=kernel_size,
        STRIDE=stride,
        BLOCK_HW=128,
        num_warps=4,
        num_stages=2,
    )
    return y


# -----------------------------------------------------------------------------
# Global Average Pool 2D (AdaptiveAvgPool2d to 1x1) NCHW kernel
# Grid: 1D over N*C
#  - Single tl.store for final scalar per (n,c)
# -----------------------------------------------------------------------------
@triton.jit
def global_avg_pool2d_nchw_kernel(
    x_ptr, y_ptr,
    N, C, H, W,
    stride_xn, stride_xc, stride_xh, stride_xw,
    stride_yn, stride_yc,
    BLOCK_HW: tl.constexpr,
):
    pid = tl.program_id(0)  # over N*C
    nc = pid
    n = nc // C
    c = nc % C

    HW = H * W
    acc = tl.zeros((), dtype=tl.float32)

    for hw_start in range(0, HW, BLOCK_HW):
        offs_hw = hw_start + tl.arange(0, BLOCK_HW)
        mask = offs_hw < HW

        h = offs_hw // W
        w = offs_hw - h * W

        x_ptrs = (
            x_ptr
            + n * stride_xn
            + c * stride_xc
            + h * stride_xh
            + w * stride_xw
        )
        vals = tl.load(x_ptrs, mask=mask, other=0.0)
        acc += tl.sum(vals.to(tl.float32), axis=0)

    mean = acc / HW

    y_ptrs = y_ptr + n * stride_yn + c * stride_yc
    tl.store(y_ptrs, mean)


def adaptive_avg_pool2d_1x1_triton(x: torch.Tensor) -> torch.Tensor:
    """
    AdaptiveAvgPool2d to output size (1,1) for NCHW.
    x: (N, C, H, W)
    returns: (N, C, 1, 1)
    """
    assert x.is_cuda
    N, C, H, W = x.shape
    y = torch.empty((N, C, 1, 1), device=x.device, dtype=x.dtype)

    def grid(META):
        return (N * C,)

    global_avg_pool2d_nchw_kernel[grid](
        x, y,
        N, C, H, W,
        x.stride(0), x.stride(1), x.stride(2), x.stride(3),
        y.stride(0), y.stride(1),
        BLOCK_HW=256,
        num_warps=2,
        num_stages=1,
    )
    return y.view(N, C, 1, 1)


# -----------------------------------------------------------------------------
# MBConv block using Triton kernels
# -----------------------------------------------------------------------------
class MBConvNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, expand_ratio):
        """
        MBConv block using Triton kernels for convolutions.
        """
        super(MBConvNew, self).__init__()

        self.use_residual = (stride == 1 and in_channels == out_channels)
        self.expand_ratio = expand_ratio
        hidden_dim = in_channels * expand_ratio

        if expand_ratio != 1:
            # 1x1 pointwise expansion conv
            self.expand_weight = nn.Parameter(
                torch.randn(hidden_dim, in_channels, 1, 1)
                * (2.0 / (in_channels * 1 * 1)) ** 0.5
            )
            self.expand_bn = nn.BatchNorm2d(hidden_dim)
            self.expand_act = nn.ReLU6(inplace=True)

        # Depthwise conv (groups = hidden_dim)
        self.kernel_size = kernel_size
        self.stride = stride
        self.dw_weight = nn.Parameter(
            torch.randn(hidden_dim, 1, kernel_size, kernel_size)
            * (2.0 / (kernel_size * kernel_size)) ** 0.5
        )
        self.dw_bn = nn.BatchNorm2d(hidden_dim)
        self.dw_act = nn.ReLU6(inplace=True)

        # 1x1 pointwise projection conv
        self.project_weight = nn.Parameter(
            torch.randn(out_channels, hidden_dim, 1, 1)
            * (2.0 / (hidden_dim * 1 * 1)) ** 0.5
        )
        self.project_bn = nn.BatchNorm2d(out_channels)

    def forward(self, x):
        identity = x

        out = x
        if self.expand_ratio != 1:
            out = conv1x1_nchw_triton(out, self.expand_weight)
            out = self.expand_bn(out)
            out = self.expand_act(out)

        out = depthwise_conv2d_triton(out, self.dw_weight, stride=self.stride, kernel_size=self.kernel_size)
        out = self.dw_bn(out)
        out = self.dw_act(out)

        out = conv1x1_nchw_triton(out, self.project_weight)
        out = self.project_bn(out)

        if self.use_residual:
            out = out + identity

        return out


# -----------------------------------------------------------------------------
# EfficientNetB0-like model using Triton kernels
# -----------------------------------------------------------------------------
class ModelNew(nn.Module):
    def __init__(self, num_classes=1000):
        super(ModelNew, self).__init__()

        # Stem conv: Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False)
        self.stem_weight = nn.Parameter(
            torch.randn(32, 3, 3, 3) * (2.0 / (3 * 3 * 3)) ** 0.5
        )
        self.bn1 = nn.BatchNorm2d(32)

        # MBConv blocks
        self.blocks = nn.Sequential(
            # MBConv1 (32, 16, 1, 1)
            MBConvNew(32, 16, kernel_size=3, stride=1, expand_ratio=1),
            # MBConv6 (16, 24, 2, 6)
            MBConvNew(16, 24, kernel_size=3, stride=2, expand_ratio=6),
            # MBConv6 (24, 24, 1, 6)
            MBConvNew(24, 24, kernel_size=3, stride=1, expand_ratio=6),
            # MBConv6 (24, 40, 2, 6)
            MBConvNew(24, 40, kernel_size=5, stride=2, expand_ratio=6),
            # MBConv6 (40, 40, 1, 6)
            MBConvNew(40, 40, kernel_size=5, stride=1, expand_ratio=6),
            # MBConv6 (40, 80, 2, 6)
            MBConvNew(40, 80, kernel_size=3, stride=2, expand_ratio=6),
            # MBConv6 (80, 80, 1, 6)
            MBConvNew(80, 80, kernel_size=3, stride=1, expand_ratio=6),
            # MBConv6 (80, 112, 1, 6)
            MBConvNew(80, 112, kernel_size=5, stride=1, expand_ratio=6),
            # MBConv6 (112, 112, 1, 6)
            MBConvNew(112, 112, kernel_size=5, stride=1, expand_ratio=6),
            # MBConv6 (112, 192, 2, 6)
            MBConvNew(112, 192, kernel_size=5, stride=2, expand_ratio=6),
            # MBConv6 (192, 192, 1, 6)
            MBConvNew(192, 192, kernel_size=5, stride=1, expand_ratio=6),
            # MBConv6 (192, 192, 1, 6)
            MBConvNew(192, 192, kernel_size=5, stride=1, expand_ratio=6),
            # MBConv6 (192, 320, 1, 6)
            MBConvNew(192, 320, kernel_size=3, stride=1, expand_ratio=6),
        )

        # Final 1x1 conv: Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)
        self.head_weight = nn.Parameter(
            torch.randn(1280, 320, 1, 1) * (2.0 / (320 * 1 * 1)) ** 0.5
        )
        self.bn2 = nn.BatchNorm2d(1280)

        # Fully connected layer: Linear(1280, num_classes)
        self.fc_weight = nn.Parameter(
            torch.randn(num_classes, 1280) * (2.0 / 1280) ** 0.5
        )
        self.fc_bias = nn.Parameter(torch.zeros(num_classes))

    def forward(self, x):
        # Stem: 3x3 conv (stride=2, padding=1) + BN + ReLU
        x = conv2d_small_triton(x, self.stem_weight, stride=2, padding=1)
        x = self.bn1(x)
        x = torch.relu(x)

        # MBConv blocks
        x = self.blocks(x)

        # Head 1x1 conv + BN + ReLU
        x = conv1x1_nchw_triton(x, self.head_weight)
        x = self.bn2(x)
        x = torch.relu(x)

        # Global average pooling to (1,1)
        x = adaptive_avg_pool2d_1x1_triton(x)

        # Flatten and FC
        x = x.view(x.size(0), -1)  # (N, 1280)
        x = linear_triton(x, self.fc_weight, self.fc_bias)

        return x
```