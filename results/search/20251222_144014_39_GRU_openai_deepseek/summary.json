{
  "avg_speedup": 0.14885863142304342,
  "accuracy": 1.0,
  "total_tokens_sum": 75438,
  "num_tasks": 1,
  "successful_tasks": 1,
  "failed_tasks": 0,
  "tasks": [
    {
      "task": "KernelBench/level3/39_GRU.py",
      "best_score": 0.14885863142304342,
      "best_runnable": true,
      "task_dir": "/home/hyc/LLMKernel/run/20251222_144014_39_GRU_openai_deepseek/39_GRU",
      "figure": "/home/hyc/LLMKernel/run/20251222_144014_39_GRU_openai_deepseek/39_GRU/figures/39_GRU_score.png",
      "input_tokens_sum": 19358,
      "output_tokens_sum": 56080,
      "total_tokens_sum": 75438
    }
  ],
  "timestamp": "2025-12-22 14:50:06"
}